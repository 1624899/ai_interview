# ğŸš€ å¿«é€Ÿå¯åŠ¨æŒ‡å—

æœ¬æŒ‡å—å¸®åŠ©ä½ å¿«é€Ÿåœ¨æœ¬åœ°è¿è¡Œ AI é¢è¯•æ™ºèƒ½ä½“é¡¹ç›®ã€‚

---

## å‰ç½®è¦æ±‚

- **Python 3.11+**
- **Node.js 20+**
- **PostgreSQL 16** (æœ¬åœ°å®‰è£…æˆ– Docker)
- **OpenAI API Key** (æˆ–å…¼å®¹ API)

---

## ç¬¬ä¸€æ­¥ï¼šæ•°æ®åº“å‡†å¤‡

### æ–¹å¼ä¸€ï¼šä½¿ç”¨ Docker (æ¨è)

```bash
# å¯åŠ¨ PostgreSQL å®¹å™¨
docker run -d \
  --name ai_interview_db \
  -e POSTGRES_USER=ai_interview \
  -e POSTGRES_PASSWORD=your_password \
  -e POSTGRES_DB=ai_interview \
  -p 5432:5432 \
  postgres:16-alpine
```

### æ–¹å¼äºŒï¼šæœ¬åœ° PostgreSQL

ç¡®ä¿ PostgreSQL å·²å®‰è£…å¹¶è¿è¡Œï¼Œåˆ›å»ºæ•°æ®åº“ï¼š

```sql
CREATE DATABASE ai_interview;
CREATE USER ai_interview WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE ai_interview TO ai_interview;
```

---

## ç¬¬äºŒæ­¥ï¼šé…ç½®ç¯å¢ƒå˜é‡

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# .env æ–‡ä»¶å†…å®¹

# === æ•°æ®åº“ ===
DATABASE_URL=postgresql://ai_interview:your_password@localhost:5432/ai_interview

# === LLM é…ç½® ===
OPENAI_API_KEY=sk-your-api-key
OPENAI_BASE_URL=https://api.openai.com/v1
SMART_MODEL=gpt-4
FAST_MODEL=gpt-3.5-turbo
```

---

## ç¬¬ä¸‰æ­¥ï¼šå¯åŠ¨åç«¯æœåŠ¡

```bash
# 1. è¿›å…¥åç«¯ç›®å½•
cd backend

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨è)
python -m venv venv
# Windows:
.\venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. åˆå§‹åŒ–æ•°æ®åº“
python -m app.database.init_db

# 5. å¯åŠ¨æœåŠ¡
python main.py
```

âœ… çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºè¡¨ç¤ºå¯åŠ¨æˆåŠŸï¼š

```
AI é¢è¯•åŠ©æ‰‹åç«¯æœåŠ¡å¯åŠ¨ä¸­...
æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ
å¯åŠ¨æœåŠ¡å™¨: http://0.0.0.0:8000
API æ–‡æ¡£: http://localhost:8000/docs
```

---

## ç¬¬å››æ­¥ï¼šå¯åŠ¨å‰ç«¯æœåŠ¡

```bash
# æ–°å¼€ä¸€ä¸ªç»ˆç«¯çª—å£

# 1. è¿›å…¥å‰ç«¯ç›®å½•
cd web

# 2. å®‰è£…ä¾èµ–
npm install

# 3. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev
```

âœ… å‰ç«¯å°†åœ¨ `http://localhost:3000` å¯åŠ¨

---

## ç¬¬äº”æ­¥ï¼šè®¿é—®åº”ç”¨

æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—® `http://localhost:3000`

### é¦–æ¬¡ä½¿ç”¨æµç¨‹

1. **é…ç½® API** (å¯é€‰)
   - ç‚¹å‡»å³ä¸Šè§’è®¾ç½®å›¾æ ‡
   - é…ç½®ä½ çš„ OpenAI API Key å’Œæ¨¡å‹

2. **å¼€å§‹é¢è¯•**
   - ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ "+" æŒ‰é’®åˆ›å»ºæ–°ä¼šè¯
   - è¾“å…¥èŒä½æè¿° (JD)
   - å¯é€‰ï¼šä¸Šä¼ ç®€å† PDF
   - é€‰æ‹©é¢è¯•æ¨¡å¼ (è¾…å¯¼/æ¨¡æ‹Ÿ)
   - ç‚¹å‡»å¼€å§‹é¢è¯•

3. **è¿›è¡Œé¢è¯•**
   - ä¸ AI é¢è¯•å®˜è¿›è¡Œå¯¹è¯
   - å›ç­”é—®é¢˜
   - æŸ¥çœ‹èƒ½åŠ›åˆ†ææŠ¥å‘Š

---

## éªŒè¯ API å¯ç”¨æ€§

### æ–¹æ³•ä¸€ï¼šAPI æ–‡æ¡£

è®¿é—® `http://localhost:8000/docs` æŸ¥çœ‹äº¤äº’å¼ API æ–‡æ¡£

### æ–¹æ³•äºŒï¼šå‘½ä»¤è¡Œæµ‹è¯•

```bash
# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# è·å–ä¼šè¯åˆ—è¡¨
curl http://localhost:8000/api/sessions/

# åˆ›å»ºä¼šè¯
curl -X POST "http://localhost:8000/api/sessions/" \
  -H "Content-Type: application/json" \
  -d '{
    "mode": "coach",
    "title": "æµ‹è¯•é¢è¯•ä¼šè¯",
    "max_questions": 5
  }'
```

---

## å¸¸è§é—®é¢˜

### Q1: æ•°æ®åº“è¿æ¥å¤±è´¥

**ç—‡çŠ¶**: `Connection refused` æˆ– `could not connect to server`

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®è®¤ PostgreSQL æ­£åœ¨è¿è¡Œ
2. æ£€æŸ¥ `DATABASE_URL` é…ç½®æ˜¯å¦æ­£ç¡®
3. ç¡®è®¤æ•°æ®åº“ç”¨æˆ·æƒé™

```bash
# æµ‹è¯•æ•°æ®åº“è¿æ¥
psql -h localhost -U ai_interview -d ai_interview
```

### Q2: åç«¯ä¾èµ–å®‰è£…å¤±è´¥

**ç—‡çŠ¶**: `pip install` æŠ¥é”™

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å‡çº§ pip
pip install --upgrade pip

# å•ç‹¬å®‰è£…é—®é¢˜ä¾èµ–
pip install asyncpg
pip install langgraph-checkpoint-postgres
```

### Q3: å‰ç«¯æ— æ³•è¿æ¥åç«¯

**ç—‡çŠ¶**: API è¯·æ±‚å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®è®¤åç«¯åœ¨ 8000 ç«¯å£è¿è¡Œ
2. æ£€æŸ¥ `web/.env.local` é…ç½®ï¼š
   ```
   NEXT_PUBLIC_API_URL=http://localhost:8000
   ```

### Q4: LLM API è°ƒç”¨å¤±è´¥

**ç—‡çŠ¶**: `OPENAI_API_KEY` ç›¸å…³é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®è®¤ API Key æœ‰æ•ˆ
2. å¦‚ä½¿ç”¨ä»£ç†ï¼Œæ£€æŸ¥ `OPENAI_BASE_URL` é…ç½®
3. åœ¨å‰ç«¯è®¾ç½®å¯¹è¯æ¡†ä¸­é…ç½® API

---

## å¼€å‘è°ƒè¯•

### æŸ¥çœ‹åç«¯æ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹è¾“å‡º
python main.py 2>&1 | tee backend.log
```

### æŸ¥çœ‹æ•°æ®åº“å†…å®¹

```bash
# è¿æ¥æ•°æ®åº“
docker exec -it ai_interview_db psql -U ai_interview

# æˆ–æœ¬åœ°è¿æ¥
psql -h localhost -U ai_interview -d ai_interview

# å¸¸ç”¨ SQL
\dt                           # æŸ¥çœ‹æ‰€æœ‰è¡¨
SELECT * FROM sessions;       # æŸ¥çœ‹ä¼šè¯
SELECT * FROM messages LIMIT 10; # æŸ¥çœ‹æ¶ˆæ¯
```

### é‡ç½®æ•°æ®åº“

```bash
# åˆ é™¤æ‰€æœ‰æ•°æ®å¹¶é‡æ–°åˆå§‹åŒ–
cd backend
python -c "
from app.database.init_db import reset_database
import asyncio
asyncio.run(reset_database())
"
```

---

## Docker Compose å¿«é€Ÿå¯åŠ¨

å¦‚æœä½ æƒ³ä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼š

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
cp .env.production.example .env.production

# ç¼–è¾‘é…ç½®
vim .env.production

# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose --env-file .env.production up -d --build

# åˆå§‹åŒ–æ•°æ®åº“
docker-compose exec backend python -m app.database.init_db

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

è®¿é—®:
- å‰ç«¯: `http://localhost` (é€šè¿‡ Nginx)
- API æ–‡æ¡£: `http://localhost/api/docs`

---

## ä¸‹ä¸€æ­¥

- ğŸ“– é˜…è¯» [é¡¹ç›®å¼€å‘è·¯çº¿](./é¢è¯•æ™ºèƒ½ä½“é¡¹ç›®å¼€å‘è·¯çº¿.md) äº†è§£ç³»ç»Ÿæ¶æ„
- ğŸ“– é˜…è¯» [éƒ¨ç½²æŒ‡å—](../DEPLOYMENT.md) éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
- ğŸ“– è®¿é—® [API æ–‡æ¡£](http://localhost:8000/docs) æ¢ç´¢æ¥å£

---

**éœ€è¦å¸®åŠ©ï¼Ÿ** æŸ¥çœ‹æ§åˆ¶å°æ—¥å¿—æˆ–æ£€æŸ¥æµè§ˆå™¨å¼€å‘è€…å·¥å…·çš„ç½‘ç»œè¯·æ±‚ã€‚

*æœ€åæ›´æ–°: 2025-12-05*
