"""
èŠå¤©ç›¸å…³çš„ API è·¯ç”±
æ”¯æŒ Server-Sent Events (SSE) æµå¼è¾“å‡º
"""

import json
import logging
import uuid
from typing import AsyncGenerator
from typing import Optional
from fastapi import APIRouter, HTTPException, Header
from fastapi.responses import StreamingResponse
from langchain_core.messages import HumanMessage

from app.core.graph import build_interview_graph
from app.models.schemas import ChatRequest, ChatStreamResponse, InterviewStartRequest, ErrorResponse, RollbackRequest
from app.database.session_service import SessionService

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/chat", tags=["èŠå¤©"])

# å®ä¾‹åŒ–ä¼šè¯æœåŠ¡
session_service = SessionService()


@router.post("/start")
async def start_interview(
    request: InterviewStartRequest,
    x_user_id: Optional[str] = Header(None, alias="X-User-ID")
):
    """
    å¼€å§‹æ–°çš„é¢è¯•ä¼šè¯
    
    Args:
        request: é¢è¯•å¼€å§‹è¯·æ±‚
        
    Returns:
        dict: ä¼šè¯å¼€å§‹ç»“æœ
    """
    print("=" * 80)
    print("ğŸ“¥ æ”¶åˆ° start_interview è¯·æ±‚")
    print(f"thread_id: {request.thread_id}")
    print(f"mode: {request.mode}")
    print(f"max_questions: {request.max_questions}")
    print(f"resume_filename: {request.resume_filename}")
    print(f"job_description: {request.job_description[:100]}..." if len(request.job_description) > 100 else f"job_description: {request.job_description}")
    print(f"company_info: {request.company_info}")
    print(f"api_config: {request.api_config}")
    print("=" * 80)
    
    try:
        # åˆå§‹åŒ–å›¾è°±ï¼ˆå¼‚æ­¥ï¼‰
        graph = await build_interview_graph(request.mode)
        
        # é…ç½®çº¿ç¨‹ ID
        config = {"configurable": {"thread_id": request.thread_id}}
        
        # æ„å»ºåˆå§‹çŠ¶æ€ï¼ˆæ–°æ¶æ„ï¼‰
        # è§£æç”¨æˆ·çš„ API é…ç½®
        api_config = None
        if request.api_config:
            api_config = {
                "smart": {
                    "api_key": request.api_config.smart.api_key,
                    "base_url": request.api_config.smart.base_url,
                    "model": request.api_config.smart.model
                },
                "fast": {
                    "api_key": request.api_config.fast.api_key,
                    "base_url": request.api_config.fast.base_url,
                    "model": request.api_config.fast.model
                }
            }
        
        inputs = {
            "messages": [],
            "resume_context": request.resume_context,
            "job_description": request.job_description,
            "company_info": getattr(request, "company_info", "æœªçŸ¥"),
            "mode": request.mode,
            "session_id": request.thread_id,  # æ·»åŠ  session_id
            "interview_plan": [],  # å°†ç”± planner èŠ‚ç‚¹å¡«å……
            "current_question_index": 0,
            "max_questions": request.max_questions,
            "question_count": 0,
            "api_config": api_config  # æ·»åŠ ç”¨æˆ· API é…ç½®
        }
        
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        session = await session_service.get_session(request.thread_id)
        if session is None:
            await session_service.create_session(
                session_id=request.thread_id,
                mode=request.mode,
                resume_filename=request.resume_filename,
                resume_content=request.resume_context,
                job_description=request.job_description,
                company_info=getattr(request, "company_info", "æœªçŸ¥"),
                max_questions=request.max_questions,
                user_id=x_user_id or "default_user"
            )
        
        # ç”Ÿæˆå¹¶æ›´æ–°ä¼šè¯æ ‡é¢˜
        mode_str = "è¾…å¯¼æ¨¡å¼" if request.mode == "coach" else "æ¨¡æ‹Ÿé¢è¯•"
        # æˆªå–å‰20ä¸ªå­—ç¬¦ä½œä¸ºæ‘˜è¦ï¼Œé˜²æ­¢è¿‡é•¿
        summary = request.job_description[:20] + "..." if len(request.job_description) > 20 else request.job_description
        title = f"{mode_str}-{summary}"
        
        # æ›´æ–°æ•°æ®åº“ä¸­çš„ä¼šè¯æ ‡é¢˜
        await session_service.update_session(request.thread_id, title=title)

        # æ‰§è¡Œå›¾ä»¥ç”Ÿæˆç¬¬ä¸€é¢˜
        first_question = ""
        async for event in graph.astream_events(inputs, config=config, version="v1"):
            kind = event["event"]
            
            # æ”¶é›† responder èŠ‚ç‚¹çš„è¾“å‡º
            if kind == "on_chat_model_stream":
                node_name = event.get("metadata", {}).get("langgraph_node", "")
                if node_name == "responder":
                    content = event["data"]["chunk"].content
                    if content:
                        first_question += content
        
        # ä¿å­˜ç¬¬ä¸€é¢˜åˆ°ä¼šè¯
        if first_question:
            await session_service.add_message(
                session_id=request.thread_id,
                role="ai",
                content=first_question,
                question_index=0
            )

        # è¿”å›ä¼šè¯ä¿¡æ¯
        return {
            "success": True,
            "message": "é¢è¯•ä¼šè¯å·²åˆå§‹åŒ–",
            "thread_id": request.thread_id,
            "mode": request.mode,
            "max_questions": request.max_questions,
            "session_title": title,
            "first_question": first_question  # è¿”å›ç¬¬ä¸€é¢˜
        }
        
    except Exception as e:
        logger.error(f"å¼€å§‹é¢è¯•ä¼šè¯å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={
                "error": "InternalServerError",
                "message": f"å¼€å§‹é¢è¯•ä¼šè¯å¤±è´¥: {str(e)}"
            }
        )


@router.post("/stream")
async def stream_chat(request: ChatRequest):
    """
    SSE ç«¯ç‚¹ï¼šæµå¼èŠå¤©æ¥å£
    å‰ç«¯å»ºç«‹è¿æ¥åï¼ŒæœåŠ¡å™¨ä¸æ–­æ¨é€ chunk
    
    Args:
        request: èŠå¤©è¯·æ±‚
        
    Returns:
        StreamingResponse: SSE æµå¼å“åº”
    """
    try:
        # åˆå§‹åŒ–å›¾è°±ï¼ˆå¼‚æ­¥ï¼‰
        graph = await build_interview_graph(request.mode)
        
        # é…ç½®çº¿ç¨‹ ID
        config = {"configurable": {"thread_id": request.thread_id}}
        
        # æ ¡éªŒæ¶ˆæ¯éç©º
        if not request.message or not request.message.strip():
            raise HTTPException(status_code=400, detail="Message cannot be empty")
            
        # 1. è·å–ä¼šè¯å®Œæ•´ä¿¡æ¯ï¼ˆç”¨äºçŠ¶æ€æ³¨æ°´ï¼‰
        # å³ä½¿ Checkpoint ä¸¢å¤±ï¼Œä¹Ÿèƒ½é€šè¿‡æ•°æ®åº“æ¢å¤ä¸Šä¸‹æ–‡
        session = await session_service.get_session(request.thread_id)
        interview_plan = await session_service.get_interview_plan(request.thread_id)
        
        # 2. æ„å»ºè¾“å…¥çŠ¶æ€ï¼ˆæ–°æ¶æ„ - çŠ¶æ€æ³¨æ°´æ¨¡å¼ï¼‰
        # æ€»æ˜¯ä¼ å…¥æœ€æ–°çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç¡®ä¿ Graph çŠ¶æ€ä¸æ•°æ®åº“ä¸€è‡´
        
        # è§£æç”¨æˆ·çš„ API é…ç½®
        api_config = None
        if request.api_config:
            api_config = {
                "smart": {
                    "api_key": request.api_config.smart.api_key,
                    "base_url": request.api_config.smart.base_url,
                    "model": request.api_config.smart.model
                },
                "fast": {
                    "api_key": request.api_config.fast.api_key,
                    "base_url": request.api_config.fast.base_url,
                    "model": request.api_config.fast.model
                }
            }
        
        inputs = {
            "messages": [HumanMessage(content=request.message)],
            "resume_context": request.resume_context,
            "job_description": request.job_description,
            "company_info": getattr(request, "company_info", "æœªçŸ¥"),
            "mode": request.mode,
            "session_id": request.thread_id,
            "max_questions": request.max_questions,
            
            # ğŸ”¥ çŠ¶æ€æ³¨æ°´ï¼šä»æ•°æ®åº“æ¢å¤å…³é”®çŠ¶æ€
            # å¦‚æœ Checkpoint è¢«æ¸…é™¤ï¼ˆä¾‹å¦‚å›é€€åï¼‰ï¼Œè¿™äº›å­—æ®µå°†å¸®åŠ© Graph æ¢å¤è®°å¿†
            "interview_plan": interview_plan if interview_plan else [],
            
            # åŠ¨æ€è®¡ç®—è¿›åº¦ï¼šåŸºäºæœ€åä¸€æ¡æ¶ˆæ¯çš„ question_index
            "question_count": session.messages[-1].question_index if session and session.messages else 0,
            "current_question_index": session.messages[-1].question_index if session and session.messages else 0,
            
            # å› ä¸º stream æ¥å£æ€»æ˜¯å¤„ç†ç”¨æˆ·çš„å›ç­”ï¼Œæ‰€ä»¥å¿…é¡»è¿›å…¥ feedback é˜¶æ®µ
            # å¦åˆ™é»˜è®¤ä¸º opening ä¼šå¯¼è‡´ç³»ç»Ÿé‡å¤å½“å‰é—®é¢˜è€Œä¸æ˜¯æ¨è¿›åˆ°ä¸‹ä¸€é¢˜
            "turn_phase": "feedback",
            
            # æ·»åŠ ç”¨æˆ· API é…ç½®
            "api_config": api_config
        }
        
        return StreamingResponse(
            event_generator(graph, inputs, config, request.thread_id, request.message),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Headers": "*",
            }
        )
        
    except Exception as e:
        logger.error(f"æµå¼èŠå¤©åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "InternalServerError",
                "message": "æµå¼èŠå¤©åˆå§‹åŒ–å¤±è´¥"
            }
        )


async def event_generator(graph, inputs, config, thread_id: str, user_message: str) -> AsyncGenerator[str, None]:
    """
    ç”Ÿæˆå™¨ï¼šå°† LangGraph äº‹ä»¶è½¬æ¢ä¸º SSE æ ¼å¼
    
    Args:
        graph: LangGraph å®ä¾‹
        inputs: è¾“å…¥çŠ¶æ€
        config: é…ç½®å‚æ•°
        thread_id: ä¼šè¯çº¿ç¨‹ID
        user_message: ç”¨æˆ·æ¶ˆæ¯å†…å®¹
        
    Yields:
        str: SSE æ ¼å¼çš„äº‹ä»¶æ•°æ®
    """
    ai_response_content = ""
    final_question_index = inputs.get("current_question_index", 0)
    
    try:
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°ä¼šè¯
        await session_service.add_message(
            session_id=thread_id,
            role="user",
            content=user_message,
            question_index=inputs.get("current_question_index", 0)
        )
        
        async for event in graph.astream_events(inputs, config=config, version="v1"):
            kind = event["event"]
            
            # å¤„ç† LLM ç”Ÿæˆçš„ token
            if kind == "on_chat_model_stream":
                # è·å–å½“å‰èŠ‚ç‚¹åç§°
                node_name = event.get("metadata", {}).get("langgraph_node", "")
                
                # åªæµå¼ä¼ è¾“é¢å‘ç”¨æˆ·çš„èŠ‚ç‚¹è¾“å‡º (responder å’Œ summary)
                # è¿‡æ»¤æ‰ planner (ç”Ÿæˆ JSON è®¡åˆ’) å’Œ evaluator (è¯„ä¼°ç”¨æˆ·å›ç­”) çš„å†…éƒ¨æ€è€ƒè¿‡ç¨‹
                if node_name in ["responder", "summary"]:
                    content = event["data"]["chunk"].content
                    if content:
                        ai_response_content += content
                        # SSE æ ¼å¼: data: <json>\n\n
                        response = ChatStreamResponse(
                            type="token",
                            content=content
                        )
                        yield f"data: {response.model_dump_json()}\n\n"
            
            # å¤„ç†é“¾ç»“æŸï¼Œè·å–å®Œæ•´çŠ¶æ€
            elif kind == "on_chain_end":
                output = event["data"].get("output")
                if output and isinstance(output, dict):
                    if "current_question_index" in output:
                        final_question_index = output["current_question_index"]
                    
                    # å¯ä»¥åœ¨è¿™é‡Œå‘é€çŠ¶æ€æ›´æ–°äº‹ä»¶
                    if "question_count" in output:
                        # æ›´æ–°ä¼šè¯å…ƒæ•°æ®
                        await session_service.update_session(
                            session_id=thread_id,
                            metadata_updates={
                                "question_count": output["question_count"]
                            }
                        )
                        
                        response = ChatStreamResponse(
                            type="state_update",
                            content=json.dumps({
                                "question_count": output["question_count"],
                                "max_questions": output.get("max_questions", inputs.get("max_questions", 5))
                            })
                        )
                        yield f"data: {response.model_dump_json()}\n\n"
        
        # ä¿å­˜AIå“åº”åˆ°ä¼šè¯
        if ai_response_content:
            await session_service.add_message(
                session_id=thread_id,
                role="ai",
                content=ai_response_content,
                question_index=final_question_index
            )
        
        # å‘é€ç»“æŸä¿¡å·
        response = ChatStreamResponse(
            type="done",
            content="[DONE]"
        )
        yield f"data: {response.model_dump_json()}\n\n"
        
    except Exception as e:
        logger.error(f"æµå¼äº‹ä»¶ç”Ÿæˆå™¨é”™è¯¯: {str(e)}")
        # å‘é€é”™è¯¯äº‹ä»¶
        response = ChatStreamResponse(
            type="error",
            content=str(e)
        )
        yield f"data: {response.model_dump_json()}\n\n"


@router.get("/status/{thread_id}")
async def get_chat_status(thread_id: str):
    """
    è·å–èŠå¤©ä¼šè¯çŠ¶æ€
    
    Args:
        thread_id: çº¿ç¨‹ ID
        
    Returns:
        dict: ä¼šè¯çŠ¶æ€ä¿¡æ¯
    """
    try:
        # è¿™é‡Œå¯ä»¥å®ç°è·å–ä¼šè¯çŠ¶æ€çš„é€»è¾‘
        # ç›®å‰è¿”å›åŸºæœ¬ä¿¡æ¯
        return {
            "success": True,
            "thread_id": thread_id,
            "status": "active"
        }
        
    except Exception as e:
        logger.error(f"è·å–èŠå¤©çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "InternalServerError",
                "message": "è·å–èŠå¤©çŠ¶æ€å¤±è´¥"
            }
        )


@router.delete("/session/{thread_id}")
async def end_chat_session(thread_id: str):
    """
    ç»“æŸèŠå¤©ä¼šè¯
    
    Args:
        thread_id: çº¿ç¨‹ ID
        
    Returns:
        dict: ä¼šè¯ç»“æŸç»“æœ
    """
    try:
        # è¿™é‡Œå¯ä»¥å®ç°æ¸…ç†ä¼šè¯çš„é€»è¾‘
        return {
            "success": True,
            "message": f"ä¼šè¯ {thread_id} å·²ç»“æŸ",
            "thread_id": thread_id
        }
        
    except Exception as e:
        logger.error(f"ç»“æŸèŠå¤©ä¼šè¯å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "InternalServerError",
                "message": "ç»“æŸèŠå¤©ä¼šè¯å¤±è´¥"
            }
        )


@router.post("/rollback")
async def rollback_chat(
    request: RollbackRequest,
    x_user_id: Optional[str] = Header(None, alias="X-User-ID")
):
    """
    å›é€€èŠå¤©ä¼šè¯
    
    Args:
        request: å›é€€è¯·æ±‚
        x_user_id: ç”¨æˆ·IDï¼ˆä» Header ä¸­è·å–ï¼Œç”¨äºæƒé™æ ¡éªŒï¼‰
        
    Returns:
        dict: å›é€€ç»“æœ
    """
    try:
        success = await session_service.rollback_session(
            request.thread_id, 
            request.index,
            user_id=x_user_id
        )
        
        if not success:
            raise HTTPException(status_code=404, detail="Session or message not found")
            
        return {
            "success": True,
            "message": f"ä¼šè¯å·²å›é€€è‡³ç´¢å¼• {request.index}",
            "thread_id": request.thread_id
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å›é€€ä¼šè¯å¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "InternalServerError",
                "message": "å›é€€ä¼šè¯å¤±è´¥"
            }
        )


@router.post("/profile/generate")
async def generate_profile(
    x_user_id: Optional[str] = Header(None, alias="X-User-ID")
):
    """
    æ‰‹åŠ¨è§¦å‘ï¼šç”Ÿæˆç”¨æˆ·ç»¼åˆèƒ½åŠ›ç”»åƒ
    
    åŸºäºæœ€è¿‘ 5 æ¬¡é¢è¯•ï¼Œä½¿ç”¨æ—¶é—´åŠ æƒèšåˆç®—æ³•ç”Ÿæˆç»¼åˆç”»åƒ
    
    Returns:
        dict: ç”Ÿæˆç»“æœ
    """
    try:
        from app.services.ability_service import get_ability_service
        
        user_id = x_user_id or "default_user"
        service = get_ability_service()
        # æ³¨æ„ï¼šç°åœ¨è¿”å›çš„æ˜¯å­—å…¸ {"profile": CandidateProfile, "warning": str}
        result = await service.generate_overall_profile(user_id=user_id)
        
        profile = result["profile"]
        warning = result.get("warning")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç©ºç”»åƒï¼ˆæ— æ•°æ®ï¼‰
        if profile.overall_assessment == "æš‚æ— é¢è¯•è®°å½•ï¼Œè¯·å…ˆè¿›è¡Œæ¨¡æ‹Ÿé¢è¯•ã€‚":
            return {
                "success": False,
                "message": "æš‚æ— é¢è¯•è®°å½•ï¼Œæ— æ³•ç”Ÿæˆç”»åƒã€‚è¯·å…ˆå®Œæˆè‡³å°‘ä¸€æ¬¡æ¨¡æ‹Ÿé¢è¯•ã€‚"
            }
        
        response = {
            "success": True,
            "message": "ç»¼åˆèƒ½åŠ›ç”»åƒå·²ç”Ÿæˆ",
            "profile": profile.model_dump()
        }
        
        if warning:
            response["warning"] = warning
            
        return response
        
    except ValueError as e:
        # å¤„ç†å†·å´æ—¶é—´ç­‰ä¸šåŠ¡é€»è¾‘é”™è¯¯
        return {
            "success": False,
            "message": str(e)
        }
    except Exception as e:
        logger.error(f"ç”Ÿæˆç»¼åˆèƒ½åŠ›ç”»åƒå¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={
                "error": "InternalServerError",
                "message": f"ç”Ÿæˆç»¼åˆèƒ½åŠ›ç”»åƒå¤±è´¥: {str(e)}"
            }
        )


@router.get("/profile/overall")
async def get_overall_profile(
    x_user_id: Optional[str] = Header(None, alias="X-User-ID")
):
    """
    è·å–ç”¨æˆ·ç»¼åˆèƒ½åŠ›ç”»åƒï¼ˆä»æ•°æ®åº“è¯»å–å·²ç”Ÿæˆçš„ç”»åƒï¼‰
    
    å¦‚æœå°šæœªç”Ÿæˆï¼Œè¿”å›æç¤ºä¿¡æ¯
    
    Returns:
        dict: ç”»åƒæ•°æ®æˆ–æç¤ºä¿¡æ¯
    """
    try:
        from app.services.ability_service import get_ability_service
        
        user_id = x_user_id or "default_user"
        service = get_ability_service()
        result = await service.get_overall_profile(user_id=user_id)
        
        if result is None:
            return {
                "success": False,
                "message": "å°šæœªç”Ÿæˆç»¼åˆèƒ½åŠ›ç”»åƒã€‚è¯·ç‚¹å‡»ã€Œç”Ÿæˆç”»åƒã€æŒ‰é’®ã€‚"
            }
        
        return {
            "success": True,
            "profile": result["profile"],
            "generated_at": result["updated_at"]
        }
        
    except Exception as e:
        logger.error(f"è·å–ç»¼åˆèƒ½åŠ›ç”»åƒå¤±è´¥: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail={
                "error": "InternalServerError",
                "message": "è·å–ç»¼åˆèƒ½åŠ›ç”»åƒå¤±è´¥"
            }
        )