"""
ç®€å†ç”Ÿæˆ Graph - äº¤äº’å¼ç®€å†ç”Ÿæˆä¸åŒ…è£…
æµç¨‹: éœ€æ±‚åˆ†æ -> (å¯é€‰é—®è¯¢) -> åˆç¨¿ç”Ÿæˆ -> åˆç¨¿ä¼˜åŒ– -> åŒ…è£…é€‚åº¦æ€§æ ¸æŸ¥ -> æ¶¦è‰²å®¡æŸ¥ -> (å¾ªç¯ä¼˜åŒ–) -> è¾“å‡º
"""

import json
import logging
import asyncio
import uuid
from typing import List, Optional, Dict, Any, TypedDict
from langchain_core.messages import HumanMessage

from app.core import llms
from app.database.resume_generation_service import session_store, get_generation_service

logger = logging.getLogger(__name__)


# ============================================================================
# çŠ¶æ€å®šä¹‰
# ============================================================================

class ResumeGenerationState(TypedDict):
    """ç®€å†ç”ŸæˆçŠ¶æ€"""
    # è¾“å…¥
    resume_content: str
    job_description: str
    optimization_result: dict
    template_style: str
    api_config: Optional[dict]
    user_id: str
    
    # ä¸­é—´çŠ¶æ€
    missing_info_analysis: Optional[dict]
    questions: List[str]
    user_answers: Dict[str, str]
    draft_content: str
    optimized_draft: str  # æ–°å¢ï¼šä¼˜åŒ–åçš„åˆç¨¿
    optimization_notes: Optional[dict]  # æ–°å¢ï¼šä¼˜åŒ–è¯´æ˜
    fact_check_result: Optional[dict]
    review_result: Optional[dict]
    iteration_count: int
    
    # è¾“å‡º
    final_markdown: str
    title: str


# ============================================================================
# èŠ‚ç‚¹å®ç°
# ============================================================================

async def node_analyze_needs(state: ResumeGenerationState) -> dict:
    """
    éœ€æ±‚åˆ†æèŠ‚ç‚¹ï¼šåˆ†æä¼˜åŒ–ç»“æœï¼Œè¯†åˆ«éœ€è¦ç”¨æˆ·ç¡®è®¤çš„ä¿¡æ¯
    """
    resume_content = state.get("resume_content", "")
    job_description = state.get("job_description", "")
    optimization_result = state.get("optimization_result", {})
    api_config = state.get("api_config")
    
    prompt = f"""ä½ æ˜¯ä¸€ä½ã€Œç®€å†ä¿¡æ¯æ ¸æŸ¥ä¸“å®¶ã€ã€‚è¯·åˆ†æä»¥ä¸‹ä¿¡æ¯ï¼Œæ‰¾å‡ºç”Ÿæˆå®Œæ•´ç®€å†å‰éœ€è¦ç”¨æˆ·ç¡®è®¤æˆ–è¡¥å……çš„å…³é”®ä¿¡æ¯ã€‚

ã€åŸå§‹ç®€å†ã€‘ï¼š
{resume_content}

ã€ç›®æ ‡èŒä½ã€‘ï¼š
{job_description}

ã€ä¼˜åŒ–å»ºè®®è¦ç‚¹ã€‘ï¼š
{json.dumps(optimization_result.get('key_improvements', [])[:5], ensure_ascii=False)}

è¯·æ£€æŸ¥ä»¥ä¸‹æ–¹é¢æ˜¯å¦æœ‰ç¼ºå¤±æˆ–éœ€è¦ç¡®è®¤ï¼š
1. é‡åŒ–æ•°æ®ï¼ˆå¦‚ä¸šç»©æ•°å­—ã€ç”¨æˆ·è§„æ¨¡ã€æå‡æ¯”ä¾‹ï¼‰- ä»…åœ¨åŸæ–‡æåˆ°ä½†æœªç»™å‡ºå…·ä½“æ•°å­—æ—¶è¯¢é—®
2. å…·ä½“æŠ€æœ¯æ ˆæˆ–å·¥å…· - ä»…åœ¨JDè¦æ±‚ä½†ç®€å†æœªæ˜ç¡®æåŠä¸”å¯èƒ½å…·å¤‡æ—¶è¯¢é—®
3. é¡¹ç›®ä¸­çš„ä¸ªäººè´¡çŒ®å’Œè§’è‰² - ä»…åœ¨æè¿°æ¨¡ç³Šæ—¶è¯¢é—®
4. ä¸ç›®æ ‡å²—ä½é«˜åº¦ç›¸å…³çš„é¡¹ç›®ç»å† - ä»…åœ¨é¡¹ç›®ç»å†æè¿°æ¨¡ç³Šæ—¶è¯¢é—®

è¯·è¾“å‡º JSON æ ¼å¼ï¼ˆä¸è¦ä½¿ç”¨ markdown ä»£ç å—ï¼Œæ³¨æ„ JSON ç»“æ„æ¶‰åŠçš„æ ‡ç‚¹å¿…é¡»æ˜¯è‹±æ–‡ï¼‰ï¼š
{{
    "has_gaps": true/false,
    "questions": [
        "æ‚¨åœ¨é¡¹ç›®Aä¸­å¸¦æ¥çš„ç”¨æˆ·å¢é•¿å¤§çº¦æ˜¯å¤šå°‘ï¼Ÿï¼ˆå¦‚ï¼šå¢é•¿50%ï¼‰",
        ...
    ]
}}

**é‡è¦æç¤º**ï¼š

**ä»€ä¹ˆæ—¶å€™åº”è¯¥æé—®ï¼ˆhas_gaps: trueï¼‰**ï¼š
- åŸç®€å†ä¸­æ˜ç¡®æåˆ°äº†æŸé¡¹æˆæœä½†ç¼ºå°‘å…·ä½“æ•°å­—ï¼ˆå¦‚"ç”¨æˆ·å¢é•¿æ˜æ˜¾"ä½†æ²¡è¯´å¤šå°‘ï¼‰
- JD ä¸­æœ‰æ˜ç¡®çš„ç¡¬æ€§è¦æ±‚ï¼Œä½†ç®€å†ä¸­å®Œå…¨æ²¡æåŠï¼ˆéœ€ç¡®è®¤æ˜¯å¦å…·å¤‡ï¼‰
- å…³é”®é¡¹ç›®çš„ä¸ªäººè§’è‰²/è´¡çŒ®æè¿°éå¸¸æ¨¡ç³Šï¼Œæ— æ³•åˆ¤æ–­

**ä»€ä¹ˆæ—¶å€™ä¸åº”è¯¥æé—®ï¼ˆhas_gaps: falseï¼‰**ï¼š
- ä¿¡æ¯å·²ç»è¶³å¤Ÿç”Ÿæˆä¸€ä»½å®Œæ•´çš„ç®€å†
- ç¼ºå¤±çš„ä¿¡æ¯å¯ä»¥é€šè¿‡åˆç†æ¨æ–­æˆ–é€‚åº¦åŒ…è£…æ¥å¼¥è¡¥
- é—®é¢˜å¤ªçç¢æˆ–å¯¹ç®€å†è´¨é‡å½±å“ä¸å¤§

**æé—®åŸåˆ™**ï¼š
- æœ€å¤šåªé—® 1-3 ä¸ªæœ€å…³é”®çš„é—®é¢˜
- é—®é¢˜å¿…é¡»å…·ä½“ã€å®¹æ˜“å›ç­”ï¼ˆç»™å‡ºç¤ºä¾‹æ ¼å¼ï¼‰
- ä¼˜å…ˆé—®èƒ½å¸¦æ¥é‡åŒ–æ•°æ®çš„é—®é¢˜
- å¯¹äºé¡¹ç›®ç»å†ç¼ºå¤±ï¼Œè¯·å¼•å¯¼ç”¨æˆ·é‡‡ç”¨ STAR æ³•åˆ™è¡¥å……ï¼ˆå¦‚ï¼šèƒŒæ™¯ã€ä»»åŠ¡ã€è¡ŒåŠ¨ã€ç»“æœï¼‰
"""
    
    llm = llms.get_llm_for_request(api_config, channel="general")
    
    try:
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        content = _clean_json_response(response.content)
        analysis = json.loads(content)
        
        questions = analysis.get("questions", [])[:3]
        has_gaps = analysis.get("has_gaps", False) and len(questions) > 0
        
        logger.info(f"éœ€æ±‚åˆ†æå®Œæˆ: has_gaps={has_gaps}, questions={len(questions)}")
        
        return {
            "missing_info_analysis": {"has_gaps": has_gaps},
            "questions": questions
        }
    except Exception as e:
        logger.error(f"éœ€æ±‚åˆ†æèŠ‚ç‚¹å¤±è´¥: {e}")
        return {
            "missing_info_analysis": {"has_gaps": False, "error": str(e)},
            "questions": []
        }


async def node_generate_draft(state: ResumeGenerationState) -> dict:
    """
    åˆç¨¿ç”ŸæˆèŠ‚ç‚¹ï¼šæ ¹æ®æ‰€æœ‰ä¿¡æ¯ç”Ÿæˆç®€å†åˆç¨¿
    å…è®¸é€‚åº¦åŒ…è£…ï¼ˆEnhancementï¼‰ï¼Œä½†ä¸èƒ½è¿›è¡Œæ¶æ„é€ å‡
    """
    resume_content = state.get("resume_content", "")
    job_description = state.get("job_description", "")
    optimization_result = state.get("optimization_result", {})
    user_answers = state.get("user_answers", {})
    review_result = state.get("review_result")
    template_style = state.get("template_style", "professional")
    api_config = state.get("api_config")
    
    # æ„å»ºç”¨æˆ·è¡¥å……ä¿¡æ¯
    user_info_section = ""
    if user_answers:
        answers_text = "\n".join([f"- {q}: {a}" for q, a in user_answers.items()])
        user_info_section = f"\n\nã€ç”¨æˆ·è¡¥å……ä¿¡æ¯ã€‘ï¼š\n{answers_text}"
    
    # å¦‚æœæœ‰å®¡æŸ¥åé¦ˆï¼ŒåŠ å…¥æ”¹è¿›æŒ‡å¯¼
    review_guidance = ""
    if review_result and not review_result.get("passed", True):
        issues = review_result.get("issues", [])
        factual_notes = []
        for i in issues:
            if i.get('type') == 'excessive_fabrication':
                # é€‚é…æ–°çš„ç»“æ„åŒ–å­—æ®µ
                loc = i.get('location', 'æœªçŸ¥ä½ç½®')
                fab = i.get('fabricated', 'æœªçŸ¥å†…å®¹')
                reason = i.get('reason', '')
                note = f"- ã€{loc}ã€‘æ£€æµ‹åˆ°é€ å‡ï¼š{fab}ï¼ˆåŸå› ï¼š{reason}ï¼‰"
                factual_notes.append(note)
                
        if factual_notes:
            review_guidance = f"\n\nã€é‡è¦ä¿®æ­£è¦æ±‚ã€‘ä¸Šæ¬¡ç”Ÿæˆå­˜åœ¨è¿‡åº¦åŒ…è£…æˆ–é€»è¾‘æ¼æ´ï¼Œè¯·ä¿®æ­£ï¼š\n" + "\n".join(factual_notes)
    
    style_guide = {
        "professional": "ä¸“ä¸šç®€æ´ï¼Œçªå‡ºçœŸå®æˆå°±å’Œæ•°æ®ï¼Œé€‚åˆä¼ä¸šåº”è˜",
        "academic": "å­¦æœ¯é£æ ¼ï¼Œå¼ºè°ƒç ”ç©¶æˆæœå’Œå‘è¡¨ï¼Œé€‚åˆå­¦æœ¯å²—ä½",
        "creative": "åˆ›æ„è®¾è®¡ï¼Œå¯ä»¥æœ‰ä¸ªæ€§åŒ–è¡¨è¾¾ï¼Œé€‚åˆåˆ›æ„è¡Œä¸š"
    }
    
    # æå–å…³é”®è¯åˆ†æ
    keyword_analysis = optimization_result.get('keyword_analysis', {})
    jd_keywords = keyword_analysis.get('jd_keywords', [])
    missing_keywords = keyword_analysis.get('missing', [])
    keyword_recommendations = keyword_analysis.get('recommendations', [])
    
    # æ„å»ºå…³é”®è¯æŒ‡å¯¼
    keyword_section = ""
    if jd_keywords or missing_keywords or keyword_recommendations:
        keyword_section = f"""

ã€å…³é”®è¯åˆ†æ - é‡ç‚¹æ‰§è¡Œã€‘ï¼š
- JDæ ¸å¿ƒå…³é”®è¯ï¼š{json.dumps(jd_keywords[:10], ensure_ascii=False)}
- ç®€å†ä¸­ç¼ºå¤±çš„å…³é”®è¯ï¼š{json.dumps(missing_keywords[:8], ensure_ascii=False)}
- å»ºè®®æ·»åŠ çš„å…³é”®è¯ï¼š{json.dumps(keyword_recommendations[:8], ensure_ascii=False)}

è¯·åŠ¡å¿…åœ¨ç®€å†ä¸­è‡ªç„¶åœ°èå…¥ä¸Šè¿°å…³é”®è¯ï¼Œç‰¹åˆ«æ˜¯ç¼ºå¤±çš„å…³é”®è¯ï¼
"""

    prompt = f"""ä½ æ˜¯ä¸€ä½ã€Œèµ„æ·±ç®€å†åŒ…è£…ä¸“å®¶ã€ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºå€™é€‰äººæ‰“é€ ä¸€ä»½**ç²¾ç‚¼æœ‰åŠ›ã€å…·æœ‰ç«äº‰åŠ›**çš„ç®€å†ã€‚

**æ ¸å¿ƒåŸåˆ™**ï¼š
1. **ç²¾ç‚¼ä¸ºç‹**ï¼šåˆ å‡å†—ä½™è¡¨è¾¾ï¼Œæ¯ä¸ªè¦ç‚¹éƒ½è¦æœ‰ä¿¡æ¯é‡ï¼Œé¿å…ç©ºæ´çš„æè¿°ã€‚
2. **å¼ºåŒ–å²—ä½åŒ¹é…**ï¼šä¼˜å…ˆçªå‡ºä¸ç›®æ ‡èŒä½æœ€ç›¸å…³çš„ç»å†ã€æŠ€èƒ½å’Œæˆæœï¼Œå¼±åŒ–æˆ–çœç•¥ä¸ç›¸å…³å†…å®¹ã€‚
3. **é€‚åº¦åŒ…è£…**ï¼šåœ¨çœŸå®åŸºç¡€ä¸Šï¼Œå¯¹ç»å†è¿›è¡Œä¸“ä¸šåŒ–æ¶¦è‰²å’Œåˆç†å»¶ä¼¸ï¼ˆè¯¦è§ä¸‹æ–¹åŒ…è£…èŒƒç•´ï¼‰ã€‚
4. **ä¸¥ç¦æ¶æ„é€ å‡**ï¼šä¸èƒ½ç¼–é€ ä¸å­˜åœ¨çš„å…¬å¸ã€èŒä½æˆ–å®Œå…¨ä¸å…·å¤‡çš„ç¡¬æŠ€èƒ½ã€‚

ã€é€‚åº¦åŒ…è£…çš„èŒƒç•´ - å…è®¸æ‰§è¡Œã€‘ï¼š
âœ… **è¯­è¨€å‡ç»´**ï¼šå°†å£è¯­åŒ–æè¿°å‡çº§ä¸ºä¸“ä¸šè¡¨è¾¾
   - "ä¿®äº†bug" â†’ "ä¿®å¤æ ¸å¿ƒæ¨¡å—å†…å­˜æ³„æ¼é—®é¢˜ï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§"
   - "åšäº†ä¸ªç½‘ç«™" â†’ "ç‹¬ç«‹å¼€å‘ä¼ä¸šå®˜ç½‘ï¼Œæå‡å“ç‰Œçº¿ä¸Šæ›å…‰åº¦"

âœ… **åˆç†æ¨å¯¼**ï¼šåŸºäºå·²æœ‰ç»å†è¿›è¡Œé€»è¾‘å»¶ä¼¸
   - å¼€å‘äº†åå°ç³»ç»Ÿ â†’ "è®¾è®¡å¹¶å®ç°ä¼ä¸šçº§åå°ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æ’‘Nä¸ªä¸šåŠ¡éƒ¨é—¨é«˜æ•ˆè¿è¥"
   - å‚ä¸ç”¨æˆ·å¢é•¿ â†’ "å‚ä¸ç”¨æˆ·å¢é•¿ç­–ç•¥åˆ¶å®šï¼ŒåŠ©åŠ›äº§å“ç”¨æˆ·è§„æ¨¡æå‡"

âœ… **é‡åŒ–æˆæœ**ï¼šç”¨åˆç†ä¼°ç®—çš„æ•°æ®å¢å¼ºè¯´æœåŠ›
   - ä½¿ç”¨"çº¦"ã€"è¶…"ã€"è¿‘"ç­‰ä¿®é¥°è¯ï¼Œå¦‚"ç”¨æˆ·å¢é•¿çº¦30%"ã€"å“åº”æ—¶é—´ä¼˜åŒ–è¶…50%"
   - åŸºäºè¡Œä¸šæ ‡å‡†ä¼°ç®—åˆç†æ•°æ®ï¼Œå¦‚"æœåŠ¡æ—¥æ´»ç”¨æˆ·10ä¸‡+"

âœ… **å²—ä½åŒ¹é…å¼ºåŒ–**ï¼šä¸»åŠ¨å¯¹æ ‡JDå…³é”®è¯å’Œè¦æ±‚
   - å°†JDä¸­çš„æ ¸å¿ƒå…³é”®è¯è‡ªç„¶èå…¥ç»å†æè¿°
   - çªå‡ºå±•ç¤ºJDè¦æ±‚çš„æŠ€èƒ½å’Œé¡¹ç›®ç»éªŒ
   - è°ƒæ•´æè¿°è§’åº¦ï¼Œè®©ç»å†æ›´è´´åˆç›®æ ‡å²—ä½

âœ… **æˆæœæ”¾å¤§**ï¼šçªå‡ºä¸ªäººè´¡çŒ®å’Œå½±å“åŠ›
   - å¼ºè°ƒ"ä¸»å¯¼"ã€"ç‹¬ç«‹å®Œæˆ"ã€"æ ¸å¿ƒè´Ÿè´£"ç­‰è§’è‰²
   - çªå‡ºå¯¹å›¢é˜Ÿ/ä¸šåŠ¡çš„å®é™…è´¡çŒ®

---

ã€åŸå§‹ç®€å†ã€‘ï¼š
{resume_content}

{user_info_section}

ã€ç›®æ ‡èŒä½ã€‘ï¼š
{job_description}

ã€å…³é”®æ”¹è¿›ç‚¹ - é‡ç‚¹æ‰§è¡Œã€‘ï¼š
{json.dumps(optimization_result.get('key_improvements', [])[:5], ensure_ascii=False, indent=2)}

ä¸Šè¿°æ”¹è¿›ç‚¹æ˜¯ä¸“å®¶åˆ†æåç»™å‡ºçš„å»ºè®®ï¼Œè¯·åŠ¡å¿…åœ¨ç®€å†ä¸­ä½“ç°ï¼
{keyword_section}
{review_guidance}

---

ã€é£æ ¼è¦æ±‚ã€‘ï¼š{style_guide.get(template_style, style_guide['professional'])}
ã€è¯­è¨€è¦æ±‚ã€‘ï¼šå¿…é¡»ä½¿ç”¨ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰æ’°å†™ã€‚

## è¾“å‡ºç»“æ„ï¼ˆè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼Œå†…å®¹ç²¾ç‚¼æœ‰åŠ›ï¼‰ï¼š

# [å§“å]
> [æ€§åˆ«] | [å¹´é¾„] | [è”ç³»æ–¹å¼]
[æ±‚èŒæ„å‘] | [æœŸæœ›è–ªèµ„] | [æœŸæœ›åŸå¸‚]

## ä¸ªäººç®€ä»‹
ï¼ˆ2-3å¥è¯ï¼Œç²¾ç‚¼æ¦‚æ‹¬æ ¸å¿ƒç«äº‰åŠ›ï¼ŒæŠ“ä½ä»¥ä¸‹é‡ç‚¹ï¼šâ‘ æ ¸å¿ƒæŠ€æœ¯/ä¸“ä¸šä¼˜åŠ¿ â‘¡æœ€çªå‡ºçš„æˆæœæˆ–äº®ç‚¹ â‘¢ä¸ç›®æ ‡å²—ä½çš„åŒ¹é…åº¦ã€‚åˆ‡å¿Œå†—é•¿å †ç Œï¼Œæ¯å¥è¯éƒ½è¦æœ‰ä¿¡æ¯é‡ï¼ï¼‰
- ä¼˜å…ˆæŠŠæ ¸å¿ƒæŠ€æœ¯/ä¸“ä¸šä¼˜åŠ¿å†™åœ¨å‰é¢

## å·¥ä½œç»å†
### [å…¬å¸åç§°] | [èŒä½] | [æ—¶é—´æ®µ]
- ç”¨ç²¾ç‚¼çš„è¯­è¨€æè¿°æ ¸å¿ƒèŒè´£å’Œæˆæœ
- ä¼˜å…ˆå±•ç¤ºé‡åŒ–æˆæœï¼ˆæ•°æ®ã€è§„æ¨¡ã€æå‡æ¯”ä¾‹ï¼‰
- çªå‡ºä¸ç›®æ ‡èŒä½ç›¸å…³çš„ç»å†
ï¼ˆæ¯æ®µç»å†2-4ä¸ªæœ€æœ‰ä»·å€¼çš„è¦ç‚¹å³å¯ï¼Œé¿å…å †ç Œï¼‰

## é¡¹ç›®ç»å†
### [é¡¹ç›®åç§°] | [è§’è‰²] | [æ—¶é—´æ®µ]
- ä¸€å¥è¯è¯´æ˜é¡¹ç›®èƒŒæ™¯å’Œä½ çš„è§’è‰²
- é‡ç‚¹æè¿°ä¸ªäººè´¡çŒ®å’Œé‡åŒ–æˆæœ
ï¼ˆæ¯ä¸ªé¡¹ç›®2-3ä¸ªæ ¸å¿ƒè¦ç‚¹ï¼Œçªå‡ºäº®ç‚¹ï¼‰

## ä¸“ä¸šæŠ€èƒ½
- **æ ¸å¿ƒæŠ€èƒ½**ï¼šä¸JDæœ€åŒ¹é…çš„æŠ€æœ¯æ ˆï¼ˆç²¾é€š/ç†Ÿç»ƒï¼‰
- **è¾…åŠ©æŠ€èƒ½**ï¼šå…¶ä»–ç›¸å…³æŠ€èƒ½ç®€è¦åˆ—å‡º
ï¼ˆæŠ€èƒ½æ¨¡å—ç²¾ç®€ä¸ºä¸€çº§åˆ—è¡¨ï¼Œçªå‡ºä¸JDåŒ¹é…çš„æ ¸å¿ƒèƒ½åŠ›ï¼‰

## æ•™è‚²èƒŒæ™¯
### [å­¦æ ¡åç§°] | [ä¸“ä¸š] | [å­¦å†] | [æ—¶é—´æ®µ]
- ä»…ä¿ç•™ä¸èŒä½ç›¸å…³çš„äº®ç‚¹ï¼ˆé«˜GPAã€ç›¸å…³è¯¾ç¨‹ã€è£èª‰ï¼‰

---

**è¾“å‡ºè§„èŒƒ**ï¼š
1. ç›´æ¥è¾“å‡º Markdown å†…å®¹ï¼Œä¸è¦ç”¨ä»£ç å—åŒ…è£¹ï¼Œç¦æ­¢ä½¿ç”¨emojiè¡¨æƒ…
2. **ç²¾ç‚¼ä¼˜å…ˆ**ï¼šæ¯ä¸ªè¦ç‚¹éƒ½è¦æœ‰ä¿¡æ¯é‡ï¼Œåˆ é™¤ç©ºæ´æè¿°
3. **çªå‡ºé‡ç‚¹**ï¼šä¼˜å…ˆå±•ç¤ºä¸ç›®æ ‡èŒä½æœ€ç›¸å…³çš„å†…å®¹
"""
    
    llm = llms.get_llm_for_request(api_config, channel="content_writer")
    
    try:
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        draft = response.content.strip()
        
        # æ¸…ç†å¯èƒ½çš„ä»£ç å—åŒ…è£¹
        draft = _clean_markdown_response(draft)
        
        logger.info(f"åˆç¨¿ç”Ÿæˆå®Œæˆ (å«é€‚åº¦åŒ…è£…): {len(draft)} å­—ç¬¦")
        return {"draft_content": draft}
    except Exception as e:
        logger.error(f"åˆç¨¿ç”ŸæˆèŠ‚ç‚¹å¤±è´¥: {e}")
        return {"draft_content": f"ç”Ÿæˆå¤±è´¥: {str(e)}"}


async def node_optimize_draft(state: ResumeGenerationState) -> dict:
    """
    åˆç¨¿ä¼˜åŒ–èŠ‚ç‚¹ï¼ˆæ–°å¢ï¼‰ï¼šæ£€æŸ¥ä¿¡æ¯é—æ¼å¹¶æŒ‰å¤šç»´åº¦ä¼˜åŒ–
    """
    resume_content = state.get("resume_content", "")
    draft_content = state.get("draft_content", "")
    job_description = state.get("job_description", "")
    user_answers = state.get("user_answers", {})
    api_config = state.get("api_config")
    
    user_inputs = json.dumps(user_answers, ensure_ascii=False) if user_answers else "æ— "

    # è·å–ä¼˜åŒ–å»ºè®®
    optimization_result = state.get("optimization_result", {})
    key_improvements = optimization_result.get('key_improvements', [])
    keyword_analysis = optimization_result.get('keyword_analysis', {})
    jd_keywords = keyword_analysis.get('jd_keywords', [])
    missing_keywords = keyword_analysis.get('missing', [])

    prompt = f"""ä½ æ˜¯ä¸€ä½ã€Œç®€å†è´¨é‡ä¼˜åŒ–ä¸“å®¶ã€ã€‚è¯·å¯¹æ¯”ã€åŸå§‹èµ„æ–™ã€‘å’Œã€åˆç¨¿ã€‘ï¼Œè¿›è¡Œæ·±åº¦ä¼˜åŒ–ã€‚

## è¾“å…¥ä¿¡æ¯

ã€åŸå§‹ç®€å†ã€‘ï¼š
{resume_content}

ã€ç”¨æˆ·è¡¥å……ä¿¡æ¯ã€‘ï¼š
{user_inputs}

ã€ç›®æ ‡èŒä½ã€‘ï¼š
{job_description}

ã€å½“å‰åˆç¨¿ã€‘ï¼š
{draft_content}

---

## å¿…é¡»æ‰§è¡Œçš„ä¼˜åŒ–å»ºè®®

ã€å…³é”®æ”¹è¿›ç‚¹ã€‘ï¼ˆæ¥è‡ªä¸“å®¶åˆ†æï¼Œå¿…é¡»è½å®ï¼‰ï¼š
{json.dumps(key_improvements[:5], ensure_ascii=False, indent=2)}

ã€å…³é”®è¯è¦æ±‚ã€‘ï¼š
- JDæ ¸å¿ƒå…³é”®è¯ï¼š{json.dumps(jd_keywords[:10], ensure_ascii=False)}
- ç¼ºå¤±çš„å…³é”®è¯ï¼ˆå¿…é¡»è¡¥å……ï¼‰ï¼š{json.dumps(missing_keywords[:8], ensure_ascii=False)}

---

## ä¼˜åŒ–ä»»åŠ¡

### 1. ä¿¡æ¯å®Œæ•´æ€§æ£€æŸ¥
å¯¹æ¯”ã€åŸå§‹ç®€å†ã€‘å’Œã€å½“å‰åˆç¨¿ã€‘ï¼š
- å…³é”®å·¥ä½œç»å†æ˜¯å¦è¢«é—æ¼ï¼Ÿâ†’ å¿…é¡»ä¿ç•™æ ¸å¿ƒç»å†
- é‡è¦é¡¹ç›®æ˜¯å¦è¢«é—æ¼ï¼Ÿâ†’ å¿…é¡»ä¿ç•™æœ‰ä»·å€¼çš„é¡¹ç›®
- é¡¹ç›®æ—¥æœŸæ˜¯å¦å‡†ç¡®ï¼Ÿâ†’ å¿…é¡»ä¸åŸç®€å†ä¸€è‡´

### 2. ç²¾ç‚¼åº¦ä¼˜åŒ–ï¼ˆé‡ç‚¹ï¼ï¼‰
**ç®€å†è¦ç²¾ç‚¼æœ‰åŠ›ï¼Œæ¯ä¸ªè¦ç‚¹éƒ½è¦æœ‰ä¿¡æ¯é‡**ï¼š
- ä¸ªäººç®€ä»‹ï¼šæ§åˆ¶åœ¨2-3å¥è¯ï¼ŒæŠ“ä½æ ¸å¿ƒç«äº‰åŠ›å’Œä¸å²—ä½åŒ¹é…åº¦
- å·¥ä½œ/é¡¹ç›®ç»å†ï¼šæ¯æ®µ2-4ä¸ªæœ€æœ‰ä»·å€¼çš„è¦ç‚¹ï¼Œåˆ é™¤ç©ºæ´æè¿°
- ä¸“ä¸šæŠ€èƒ½ï¼šç²¾ç®€ä¸ºä¸JDæœ€ç›¸å…³çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œé¿å…ç½—åˆ—è¿‡å¤š

### 3. è‡ªæˆ‘ä»‹ç»ä¼˜åŒ–ï¼ˆå…³é”®ï¼ï¼‰
ä¸ªäººç®€ä»‹å¿…é¡»åšåˆ°ï¼š
- **ç²¾ç‚¼**ï¼šæ§åˆ¶åœ¨2-3å¥è¯ï¼Œä¸è¶…è¿‡100å­—
- **èšç„¦**ï¼šåªçªå‡ºâ‘ æ ¸å¿ƒæŠ€æœ¯ä¼˜åŠ¿ â‘¡æœ€çªå‡ºæˆæœ â‘¢ä¸å²—ä½åŒ¹é…åº¦
- **æœ‰ä¿¡æ¯é‡**ï¼šæ¯å¥è¯éƒ½æœ‰å®è´¨å†…å®¹ï¼Œåˆ é™¤"åŠªåŠ›"ã€"çƒ­çˆ±"ç­‰ç©ºæ´æè¿°

### 4. å…³é”®è¯èå…¥
æ£€æŸ¥ã€ç¼ºå¤±çš„å…³é”®è¯ã€‘æ˜¯å¦å·²è‡ªç„¶åœ°èå…¥ç®€å†ä¸­ï¼š
- åœ¨å·¥ä½œèŒè´£ã€é¡¹ç›®æè¿°ã€æŠ€èƒ½åˆ—è¡¨ä¸­ä½“ç°
- ç¡®ä¿å…³é”®è¯è¦†ç›–ç‡è¾¾åˆ°80%ä»¥ä¸Š

### 5. é‡åŒ–ä¸æˆæœ
- ä¿ç•™æœ‰è¯´æœåŠ›çš„é‡åŒ–æˆæœ
- åˆ é™¤æ¨¡ç³Šçš„ã€æ²¡æœ‰ä¿¡æ¯é‡çš„æè¿°

### 6. å…³é”®æ”¹è¿›ç‚¹è½å®æ£€æŸ¥
é€æ¡æ£€æŸ¥ã€å…³é”®æ”¹è¿›ç‚¹ã€‘æ˜¯å¦å·²åœ¨ç®€å†ä¸­ä½“ç°ï¼Œæœªä½“ç°çš„å¿…é¡»è¡¥å……ã€‚

---

## è¾“å‡ºè¦æ±‚

è¯·è¾“å‡º JSON æ ¼å¼ï¼ˆä¸è¦ä½¿ç”¨ markdown ä»£ç å—ï¼Œæ³¨æ„ JSON ç»“æ„æ¶‰åŠçš„æ ‡ç‚¹å¿…é¡»æ˜¯è‹±æ–‡ï¼‰ï¼š
{{
    "optimized_content": "ä¼˜åŒ–åçš„å®Œæ•´ Markdown ç®€å†ï¼ˆç²¾ç‚¼æœ‰åŠ›ï¼‰...",
    "optimization_summary": {{
        "missing_info_fixed": ["è¡¥å……äº†XXé¡¹ç›®ç»å†", "ä¿ç•™äº†å…³é”®ä¿¡æ¯..."],
        "content_refined": ["ç²¾ç®€äº†å†—ä½™æè¿°", "ä¼˜åŒ–äº†ä¸ªäººç®€ä»‹..."],
        "skills_focused": ["èšç„¦æ ¸å¿ƒæŠ€èƒ½", "çªå‡ºJDåŒ¹é…æŠ€èƒ½..."],
        "keywords_added": ["èå…¥äº†å…³é”®è¯XX", "è¡¥å……äº†æŠ€èƒ½å…³é”®è¯XX..."],
        "improvements_applied": ["è½å®äº†æ”¹è¿›ç‚¹1", "è½å®äº†æ”¹è¿›ç‚¹2..."]
    }},
    "quality_scores": {{
        "completeness": 85,
        "conciseness": 85,
        "focus": 90,
        "keyword_coverage": 90,
        "jd_match": 82
    }}
}}

é‡è¦æé†’ï¼š
- optimized_content å¿…é¡»æ˜¯å®Œæ•´çš„ Markdown ç®€å†ï¼Œç¦æ­¢ä½¿ç”¨emojiè¡¨æƒ…
- **ç²¾ç‚¼ä¼˜å…ˆ**ï¼šåˆ é™¤ç©ºæ´æè¿°ï¼Œæ¯ä¸ªè¦ç‚¹éƒ½è¦æœ‰ä¿¡æ¯é‡
- **ä¸ªäººç®€ä»‹å¿…é¡»ç²¾ç‚¼**ï¼š2-3å¥è¯æŠ“ä½é‡ç‚¹ï¼Œåˆ‡å¿Œå†—é•¿
- **å…³é”®è¯å’Œæ”¹è¿›ç‚¹å¿…é¡»è½å®**
"""
    
    llm = llms.get_llm_for_request(api_config, channel="content_writer")
    
    try:
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        content = _clean_json_response(response.content)
        result = json.loads(content)
        
        optimized_draft = result.get("optimized_content", draft_content)
        optimized_draft = _clean_markdown_response(optimized_draft)
        
        optimization_summary = result.get("optimization_summary", {})
        quality_scores = result.get("quality_scores", {})
        
        logger.info(f"åˆç¨¿ä¼˜åŒ–å®Œæˆ: è¡¥å……äº† {len(optimization_summary.get('missing_info_fixed', []))} é¡¹é—æ¼, é•¿åº¦ {len(optimized_draft)} å­—ç¬¦, è´¨é‡è¯„åˆ† completeness={quality_scores.get('completeness', 'N/A')}")
        
        return {
            "optimized_draft": optimized_draft,
            "optimization_notes": {
                "summary": optimization_summary,
                "scores": quality_scores
            }
        }
    except Exception as e:
        logger.error(f"åˆç¨¿ä¼˜åŒ–èŠ‚ç‚¹å¤±è´¥: {e}")
        # å¤±è´¥æ—¶ä½¿ç”¨åŸåˆç¨¿
        return {
            "optimized_draft": draft_content,
            "optimization_notes": {"error": str(e)}
        }


async def node_fact_check(state: ResumeGenerationState) -> dict:
    """
    åŒ…è£…é€‚åº¦æ€§æ ¸æŸ¥èŠ‚ç‚¹ï¼šåŒºåˆ†"é€‚åº¦åŒ…è£…"å’Œ"è¿‡åº¦é€ å‡"
    """
    resume_content = state.get("resume_content", "")
    # ä½¿ç”¨ä¼˜åŒ–åçš„åˆç¨¿è¿›è¡Œæ ¸æŸ¥
    draft_content = state.get("optimized_draft", "") or state.get("draft_content", "")
    user_answers = state.get("user_answers", {})
    api_config = state.get("api_config")
    
    user_inputs = json.dumps(user_answers, ensure_ascii=False) if user_answers else "æ— "

    prompt = f"""ä½ æ˜¯ä¸€ä½ã€Œç®€å†é£æ§ä¸“å®¶ã€ã€‚è¯·å¯¹æ¯”ã€åŸå§‹èµ„æ–™ã€‘å’Œã€ç”Ÿæˆç®€å†ã€‘ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨**è¿‡åº¦åŒ…è£…æˆ–æ¶æ„é€ å‡**ã€‚

ã€åˆ¤å®šæ ‡å‡†ã€‘ï¼š
- ğŸŸ¢ **å®‰å…¨ï¼ˆé€‚åº¦åŒ…è£…ï¼‰**ï¼šè¯­è¨€æ¶¦è‰²ã€åˆç†çš„æ¨æ–­ã€åŸºäºè¡Œä¸šæ ‡å‡†ä¼°ç®—çš„æ•°æ®ã€çªæ˜¾äº®ç‚¹ã€‚ -> **æ— éœ€æŠ¥å‘Š**
- ğŸ”´ **å±é™©ï¼ˆæ¶æ„é€ å‡ï¼‰**ï¼š
    1. ç¼–é€ ä¸å­˜åœ¨çš„å…¬å¸æˆ–å·²ç¡®è®¤ä¸å­˜åœ¨çš„èŒä½ã€‚
    2. ç¼–é€ å€™é€‰äººæ˜¾ç„¶ä¸å…·å¤‡çš„æ ¸å¿ƒç¡¬æŠ€èƒ½ï¼ˆå¦‚æ–‡å‘˜ç¼–é€ ä¼šå†™æ“ä½œç³»ç»Ÿå†…æ ¸ï¼‰ã€‚
    3. æ•°æ®æåº¦å¤¸å¼ ã€è¿åå¸¸ç†ï¼ˆå¦‚å®ä¹ ç”Ÿç‹¬ç«‹å¸¦æ¥ä¸Šäº¿è¥æ”¶ï¼‰ã€‚

ã€åŸå§‹èµ„æ–™ã€‘ï¼š
{resume_content}
ç”¨æˆ·è¡¥å……: {user_inputs}

ã€ç”Ÿæˆç®€å†ã€‘ï¼š
{draft_content}

---

è¯·åªæŠ¥å‘ŠğŸ”´**å±é™©**çº§åˆ«çš„é€ å‡ã€‚å¦‚æœåªæ˜¯ğŸŸ¢é€‚åº¦åŒ…è£…ï¼ˆåŒ…æ‹¬åŸºäºç»éªŒçš„åˆç†æ¨æ–­ã€è¯­è¨€ä¸Šçš„ä¸“ä¸šåŒ–æ¶¦è‰²ï¼‰ï¼Œè¯·åŠ¡å¿…**æ”¾è¡Œ**ï¼ˆis_excessive=falseï¼‰ã€‚

**åªæœ‰åœ¨ç¡®å®å‡ºç°"æ— ä¸­ç”Ÿæœ‰"çš„æ ¸å¿ƒç¡¬æŠ€èƒ½æˆ–ç»å†æ—¶ï¼Œæ‰æ ‡è®°ä¸ºè¿‡åº¦é€ å‡ã€‚**

è¯·è¾“å‡º JSON æ ¼å¼ï¼ˆä¸è¦ä½¿ç”¨ markdown ä»£ç å—ã€æ³¨æ„ JSON ç»“æ„æ¶‰åŠçš„æ ‡ç‚¹å¿…é¡»æ˜¯è‹±æ–‡ï¼‰ï¼š
{{
    "is_excessive": true/false,  // æ˜¯å¦è¿‡åº¦é€ å‡
    "risk_details": [
        {{
            "type": "excessive_fabrication",
            "location": "å…·ä½“ä½ç½®ï¼ˆå¦‚ï¼šå·¥ä½œç»å†-XXå…¬å¸ã€é¡¹ç›®ç»å†-XXé¡¹ç›®ã€ä¸“ä¸šæŠ€èƒ½ç­‰ï¼‰",
            "original": "åŸå§‹ç®€å†ä¸­çš„ç›¸å…³å†…å®¹ï¼ˆå¦‚æ— åˆ™å¡«'æ— ç›¸å…³æè¿°'ï¼‰",
            "fabricated": "ç”Ÿæˆç®€å†ä¸­è¢«é€ å‡/è¿‡åº¦å¤¸å¤§çš„å…·ä½“å†…å®¹",
            "reason": "åˆ¤å®šä¸ºé€ å‡çš„ç†ç”±ï¼ˆå¦‚ï¼šåŸç®€å†æ— æ­¤æŠ€èƒ½ã€æ•°æ®è¿åå¸¸ç†ç­‰ï¼‰"
        }}
    ]
}}
"""
    
    llm = llms.get_llm_for_request(api_config, channel="general")
    
    try:
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        content = _clean_json_response(response.content)
        result = json.loads(content)
        
        is_excessive = result.get("is_excessive", False)
        logger.info(f"é£æ§æ ¸æŸ¥å®Œæˆ: is_excessive={is_excessive}")
        return {"fact_check_result": result}
    except Exception as e:
        logger.error(f"é£æ§æ ¸æŸ¥èŠ‚ç‚¹å¤±è´¥: {e}")
        return {"fact_check_result": {"is_excessive": False, "risk_details": []}}


async def node_finalize_and_review(state: ResumeGenerationState) -> dict:
    """
    æ¶¦è‰²ä¸å®¡æŸ¥èŠ‚ç‚¹ï¼šåŸºäºé€‚åº¦åŒ…è£…åŸåˆ™è¿›è¡Œæœ€ç»ˆç¡®è®¤
    """
    # ä½¿ç”¨ä¼˜åŒ–åçš„åˆç¨¿
    draft_content = state.get("optimized_draft", "") or state.get("draft_content", "")
    fact_check_result = state.get("fact_check_result", {})
    optimization_result = state.get("optimization_result", {})
    api_config = state.get("api_config")
    
    # è·å– JD å…³é”®è¯
    jd_keywords = optimization_result.get("keyword_analysis", {}).get("jd_keywords", [])[:10]
    
    # æ„å»ºè­¦å‘Š
    warning = ""
    if fact_check_result.get("is_excessive"):
        details = fact_check_result.get("risk_details", [])
        # æ„å»ºæ›´æ¸…æ™°çš„ä¿®æ­£æŒ‡å¯¼
        fix_instructions = []
        for i, detail in enumerate(details, 1):
            location = detail.get("location", "æœªçŸ¥ä½ç½®")
            original = detail.get("original", "æ— ç›¸å…³æè¿°")
            fabricated = detail.get("fabricated", "æœªçŸ¥å†…å®¹")
            reason = detail.get("reason", "æœªè¯´æ˜")
            fix_instructions.append(
                f"  {i}. ã€{location}ã€‘\n"
                f"     - åŸå§‹å†…å®¹ï¼š{original}\n"
                f"     - é€ å‡å†…å®¹ï¼š{fabricated}\n"
                f"     - é€ å‡åŸå› ï¼š{reason}"
            )
        
        warning = f"""
**é£æ§è­¦å‘Šï¼šæ£€æµ‹åˆ°è¿‡åº¦é€ å‡ï¼Œå¿…é¡»ä¿®æ­£ä»¥ä¸‹å†…å®¹**ï¼š

{chr(10).join(fix_instructions)}

**ä¿®æ­£åŸåˆ™**ï¼š
- å¯¹äºã€é€ å‡å†…å®¹ã€‘éƒ¨åˆ†ï¼Œè¯·æ ¹æ®ã€åŸå§‹å†…å®¹ã€‘è¿›è¡Œä¿®æ­£æˆ–å¼±åŒ–è¡¨è¿°
- å°†"è¿‡äºå¤¸å¼ çš„æ•°æ®"ä¿®æ”¹ä¸º"åˆç†ä¼°ç®—çš„æ•°æ®"
- å°†"æ— ä¸­ç”Ÿæœ‰"çš„æŠ€èƒ½ä¿®æ”¹ä¸º"äº†è§£/ç†Ÿæ‚‰"æˆ–åˆ é™¤è¯¥å…·ä½“æŠ€èƒ½ç‚¹ï¼ˆä¿ç•™å…¶ä»–çœŸå®æŠ€èƒ½ï¼‰
- **ä¸è¦åˆ é™¤æ•´æ®µç»å†ï¼Œä¹Ÿä¸è¦å¤§å¹…ç¼©å‡ç®€å†ç¯‡å¹…**
"""

    prompt = f"""ä½ æ˜¯ä¸€ä½ã€Œç®€å†ç»ˆå®¡ä¸“å®¶ã€ã€‚è¯·å¯¹ä»¥ä¸‹ç®€å†è¿›è¡Œæœ€ç»ˆæ¶¦è‰²ã€‚

ã€ç®€å†è‰ç¨¿ã€‘ï¼š
{draft_content}

ã€ç›®æ ‡èŒä½å…³é”®è¯ã€‘ï¼š
{json.dumps(jd_keywords, ensure_ascii=False)}

{warning}

è¯·æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š
1. **ä¿®æ­£è¿‡åº¦é€ å‡**ï¼šå¦‚æœæœ‰é£æ§è­¦å‘Šï¼Œå¿…é¡»ä¿®æ­£ã€‚
2. **æ¶¦è‰²è¯­è¨€**ï¼šè®©æªè¾æ›´åŠ ä¸“ä¸šã€è‡ªä¿¡ï¼ˆå…è®¸é€‚åº¦åŒ…è£…ï¼‰ã€‚
3. **æ ¼å¼æ£€æŸ¥**ï¼šç¡®ä¿ Markdown æ ¼å¼æ ‡å‡†ã€ç¾è§‚ã€‚
4. **é•¿åº¦ä¿æŒ**ï¼š**ä¸¥ç¦å¤§å¹…åˆ å‡å†…å®¹ï¼** ä¿®æ­£åçš„ç®€å†é•¿åº¦åº”ä¸è‰ç¨¿åŸºæœ¬ä¿æŒä¸€è‡´ï¼ˆå…è®¸+/- 10%æ³¢åŠ¨ï¼‰ã€‚å¦‚æœä¸æ¶‰åŠé€ å‡çš„éƒ¨åˆ†ï¼Œè¯·åŸæ ·ä¿ç•™æˆ–ä»…åšæ¶¦è‰²ã€‚
5. **æœ€ç»ˆæ‰“ç£¨**ï¼šç¡®ä¿ç®€å†è¯»èµ·æ¥æµç•…ã€ä¸“ä¸šã€‚

è¯·è¾“å‡º JSON æ ¼å¼ï¼ˆä¸è¦ä½¿ç”¨ markdown ä»£ç å—ï¼Œæ³¨æ„ JSON ç»“æ„æ¶‰åŠçš„æ ‡ç‚¹å¿…é¡»æ˜¯è‹±æ–‡ï¼‰ï¼š
{{
    "final_content": "æœ€ç»ˆä¿®è®¢åçš„å®Œæ•´ Markdown ç®€å†...",
    "review_passed": true/false,
    "modification_notes": ["ä¿®æ­£äº†ä¸¥é‡å¤¸å¤§çš„æ•°æ®", "ä¼˜åŒ–äº†é¡¹ç›®æè¿°..."],
    "title": "å§“å-ç›®æ ‡èŒä½"
}}
æ³¨æ„ï¼š
- optimized_content å¿…é¡»æ˜¯å®Œæ•´çš„ Markdown ç®€å†ï¼Œç¦æ­¢ä½¿ç”¨emojiè¡¨æƒ…
- å†…å®¹è¦ä¸°å¯Œï¼Œä¸è¦å†™å¾—å¤ªç®€æ´ï¼æ¯ä¸ªæ¨¡å—éƒ½è¦æœ‰å®è´¨å†…å®¹
- ä¸“ä¸šæŠ€èƒ½è¦è¯¦ç»†ï¼Œä½“ç°æ·±åº¦å’Œä¸å²—ä½çš„åŒ¹é…
- ç¦æ­¢ä½¿ç”¨emojiè¡¨æƒ…
- ç¦æ­¢ä¿®æ”¹é¡¹ç›®æ—¥æœŸ
"""
    
    llm = llms.get_llm_for_request(api_config, channel="hr_reviewer")
    
    try:
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        content = _clean_json_response(response.content)
        result = json.loads(content)
        
        final_markdown = result.get("final_content", draft_content)
        passed = result.get("review_passed", True)
        title = result.get("title", "æ–°ç®€å†")
        
        final_markdown = _clean_markdown_response(final_markdown)
        
        logger.info(f"æ¶¦è‰²å®¡æŸ¥å®Œæˆ: passed={passed}")
        
        return {
            "final_markdown": final_markdown,
            "review_result": {
                "passed": passed, 
                "issues": fact_check_result.get("risk_details", [])
            },
            "title": title
        }
    except Exception as e:
        logger.error(f"æ¶¦è‰²å®¡æŸ¥èŠ‚ç‚¹å¤±è´¥: {e}")
        return {
            "final_markdown": draft_content,
            "review_result": {"passed": True, "error": str(e)},
            "title": "æ–°ç®€å†"
        }


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def _clean_json_response(content: str) -> str:
    """æ¸…ç† LLM å“åº”ä¸­çš„ markdown æ ‡è®°"""
    content = content.strip()
    if content.startswith("```json"):
        content = content[7:]
    elif content.startswith("```"):
        content = content[3:]
    if content.endswith("```"):
        content = content[:-3]
    return content.strip()

def _clean_markdown_response(content: str) -> str:
    """æ¸…ç† Markdown å“åº”ä¸­çš„ä»£ç å—åŒ…è£¹"""
    content = content.strip()
    if content.startswith("```markdown"):
        content = content[11:]
    elif content.startswith("```"):
        content = content[3:]
    if content.endswith("```"):
        content = content[:-3]
    return content.strip()


# ============================================================================
# ä¸»æµç¨‹å‡½æ•°
# ============================================================================

async def init_generation_session(
    resume_content: str,
    job_description: str,
    optimization_result: dict,
    user_id: str,
    template_style: str = "professional",
    api_config: Optional[dict] = None
) -> Dict[str, Any]:
    """
    åˆå§‹åŒ–ç®€å†ç”Ÿæˆä¼šè¯
    """
    session_id = str(uuid.uuid4())
    
    # åˆ›å»ºå†…å­˜ä¼šè¯
    session = session_store.create(
        session_id=session_id,
        user_id=user_id,
        resume_content=resume_content,
        job_description=job_description,
        optimization_result=optimization_result,
        template_style=template_style
    )
    
    # åˆå§‹åŒ–çŠ¶æ€
    state: ResumeGenerationState = {
        "resume_content": resume_content,
        "job_description": job_description,
        "optimization_result": optimization_result,
        "template_style": template_style,
        "api_config": api_config,
        "user_id": user_id,
        "missing_info_analysis": None,
        "questions": [],
        "user_answers": {},
        "draft_content": "",
        "optimized_draft": "",
        "optimization_notes": None,
        "fact_check_result": None,
        "review_result": None,
        "iteration_count": 0,
        "final_markdown": "",
        "title": ""
    }
    
    # æ‰§è¡Œéœ€æ±‚åˆ†æ
    logger.info(f"å¼€å§‹ç”Ÿæˆä¼šè¯: {session_id}")
    analysis_result = await node_analyze_needs(state)
    state.update(analysis_result)
    
    questions = state.get("questions", [])
    has_gaps = state.get("missing_info_analysis", {}).get("has_gaps", False)
    
    if has_gaps and questions:
        # éœ€è¦ç”¨æˆ·è¾“å…¥
        session_store.update(
            session_id,
            status="awaiting_input",
            questions=questions
        )
        return {
            "session_id": session_id,
            "needs_input": True,
            "questions": questions
        }
    else:
        # ç›´æ¥ç”Ÿæˆ
        result = await _complete_generation(session_id, state, api_config)
        return {
            "session_id": session_id,
            "needs_input": False,
            "result": result
        }


async def submit_user_answers(
    session_id: str,
    answers: Dict[str, str],
    api_config: Optional[dict] = None
) -> Dict[str, Any]:
    """
    æäº¤ç”¨æˆ·å›ç­”å¹¶ç»§ç»­ç”Ÿæˆ
    """
    session = session_store.get(session_id)
    if not session:
        raise ValueError(f"ä¼šè¯ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ: {session_id}")
    
    # æ›´æ–°ä¼šè¯
    session_store.update(
        session_id,
        user_answers=answers,
        status="generating"
    )
    
    # é‡å»ºçŠ¶æ€
    state: ResumeGenerationState = {
        "resume_content": session.resume_content,
        "job_description": session.job_description,
        "optimization_result": session.optimization_result,
        "template_style": session.template_style,
        "api_config": api_config,
        "user_id": session.user_id,
        "missing_info_analysis": None,
        "questions": session.questions,
        "user_answers": answers,
        "draft_content": "",
        "optimized_draft": "",
        "optimization_notes": None,
        "fact_check_result": None,
        "review_result": None,
        "iteration_count": 0,
        "final_markdown": "",
        "title": ""
    }
    
    result = await _complete_generation(session_id, state, api_config)
    return result



async def _complete_generation(
    session_id: str,
    state: ResumeGenerationState,
    api_config: Optional[dict]
) -> Dict[str, Any]:
    """
    å®Œæˆç”Ÿæˆæµç¨‹ï¼ˆå†…éƒ¨å‡½æ•°ï¼‰
    æµç¨‹ï¼šåˆç¨¿ç”Ÿæˆ -> åˆç¨¿ä¼˜åŒ– -> é£æ§æ ¸æŸ¥ -> æ¶¦è‰²å®¡æŸ¥
    """
    session_store.update(session_id, status="generating")
    
    max_iterations = 2
    
    while state["iteration_count"] < max_iterations:
        state["iteration_count"] += 1
        current_iter = state["iteration_count"]
        
        logger.info(f"å¼€å§‹ç”Ÿæˆå¾ªç¯: iteration={current_iter}")
        
        # 1. ç”Ÿæˆåˆç¨¿ï¼ˆå«é€‚åº¦åŒ…è£…ï¼‰
        draft_result = await node_generate_draft(state)
        state.update(draft_result)
        
        # 2. åˆç¨¿ä¼˜åŒ–ï¼ˆæ£€æŸ¥é—æ¼ã€å¤šç»´åº¦ä¼˜åŒ–ï¼‰ã€æ–°å¢ã€‘
        optimize_result = await node_optimize_draft(state)
        state.update(optimize_result)
        
        # 3. é£æ§æ ¸æŸ¥ï¼ˆåªæŸ¥ä¸¥é‡é€ å‡ï¼‰
        check_result = await node_fact_check(state)
        state.update(check_result)
        
        # 4. æ¶¦è‰²ä¸ç»ˆå®¡
        finalize_result = await node_finalize_and_review(state)
        state.update(finalize_result)
        
        # æ£€æŸ¥æ˜¯å¦é€šè¿‡
        if state.get("review_result", {}).get("passed", False):
            logger.info("å®¡æŸ¥é€šè¿‡ï¼Œç”Ÿæˆç»“æŸ")
            break
        else:
            logger.info("å®¡æŸ¥æœªå®Œå…¨é€šè¿‡ï¼Œå°è¯•ä¸‹ä¸€è½®ä¼˜åŒ–ï¼ˆå¦‚æœ‰ï¼‰")
    
    if not state.get("final_markdown"):
        logger.warning("è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ä»æœªé€šè¿‡å®¡æŸ¥ï¼Œä½¿ç”¨æœ€åä¸€æ¬¡è‰ç¨¿")
        state["final_markdown"] = state.get("optimized_draft", "") or state.get("draft_content", "") or "# ç”Ÿæˆå¤±è´¥\nè¯·ç¨åé‡è¯•"
        state["title"] = "æ–°ç®€å†"
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    service = get_generation_service()
    session = session_store.get(session_id)
    
    resume_id = await service.save_generated_resume(
        user_id=session.user_id if session else state["user_id"],
        title=state["title"],
        content=state["final_markdown"],
        job_description=state.get("job_description")
    )
    
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    session_store.update(
        session_id,
        status="completed",
        final_markdown=state["final_markdown"]
    )
    
    logger.info(f"ç”Ÿæˆæµç¨‹å…¨éƒ¨å®Œæˆ: resume_id={resume_id}, title={state['title']}")
    
    return {
        "resume_id": resume_id,
        "title": state["title"],
        "content": state["final_markdown"],
        "review_result": state.get("review_result"),
        "optimization_notes": state.get("optimization_notes")  # è¿”å›ä¼˜åŒ–ä¿¡æ¯
    }


async def get_session_status(session_id: str) -> Optional[Dict[str, Any]]:
    """
    è·å–ä¼šè¯çŠ¶æ€
    """
    session = session_store.get(session_id)
    if not session:
        return None
    
    return {
        "session_id": session_id,
        "status": session.status,
        "questions": session.questions if session.status == "awaiting_input" else [],
        "user_answers": session.user_answers,
        "final_markdown": session.final_markdown if session.status == "completed" else None
    }
