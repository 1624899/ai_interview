"""
è¯­éŸ³é¢è¯•æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
é‡‡ç”¨ç±»ä¼¼ graph.py çš„æ¶æ„è®¾è®¡ï¼šçŠ¶æ€å®šä¹‰ + èŠ‚ç‚¹å‡½æ•° + è·¯ç”±é€»è¾‘
æ”¯æŒ SSE æµå¼è¾“å‡º
"""

import logging
import base64
import json
import struct
import asyncio
from typing import Optional, List, Dict, Any, Literal, TypedDict, AsyncGenerator

from app.core import llms
from app.core.llms import get_async_omni_client
from app.database.session_service import SessionService

logger = logging.getLogger(__name__)


# ============================================================================
# æ•°æ®ç»“æ„å®šä¹‰
# ============================================================================

class VoiceInterviewState(TypedDict):
    """
    è¯­éŸ³é¢è¯•çŠ¶æ€å®šä¹‰ - ç»Ÿä¸€çš„çŠ¶æ€ç»“æ„
    """
    # åŸºç¡€ä¿¡æ¯
    session_id: str
    api_config: Dict[str, Any]
    
    # é¢è¯•è§„åˆ’
    interview_plan: List[Dict[str, str]]
    system_prompt: str
    
    # å¯¹è¯å†å²
    history: List[Dict[str, Any]]
    
    # å½“å‰é˜¶æ®µ
    current_phase: Literal["planning", "greeting", "conversation", "complete"]
    current_q_idx: int  # å½“å‰è®¡åˆ’ä¸­çš„é¢˜ç›®ç´¢å¼•
    follow_up_count: int  # å¯¹å½“å‰é¢˜ç›®çš„è¿½é—®æ¬¡æ•°
    
    # å½“å‰è¾“å…¥ï¼ˆç”¨äºå¯¹è¯é˜¶æ®µï¼‰
    audio_base64: Optional[str]
    text_message: Optional[str]
    audio_id: Optional[str]  # æµè§ˆå™¨ç«¯ IndexedDB å­˜å‚¨çš„éŸ³é¢‘ ID


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def pcm_to_wav(pcm_data: bytes, sample_rate=24000, num_channels=1, bits_per_sample=16) -> bytes:
    """å°†åŸå§‹ PCM æ•°æ®è½¬æ¢ä¸º WAV æ ¼å¼"""
    byte_rate = sample_rate * num_channels * bits_per_sample // 8
    block_align = num_channels * bits_per_sample // 8
    data_size = len(pcm_data)
    
    wav_header = struct.pack('<4sI4s4sIHHIIHH4sI',
        b'RIFF',
        36 + data_size,
        b'WAVE',
        b'fmt ',
        16,
        1,
        num_channels,
        sample_rate,
        byte_rate,
        block_align,
        bits_per_sample,
        b'data',
        data_size
    )
    return wav_header + pcm_data


async def save_message_async(session_id: str, role: str, content: str, question_index: int = 0, audio_url: Optional[str] = None):
    """å¼‚æ­¥ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“"""
    if not content and not audio_url:
        return
        
    try:
        service = SessionService()
        await service.add_message(session_id, role, content or "", question_index=question_index, audio_url=audio_url)
        logger.info(f"[Voice] æ¶ˆæ¯å·²ä¿å­˜: {session_id} - {role} (q={question_index})")
    except Exception as e:
        logger.error(f"[Voice] ä¿å­˜æ¶ˆæ¯å¤±è´¥: {e}")


def _get_omni_client(api_config: Dict[str, Any]):
    """è·å– Omni å®¢æˆ·ç«¯ï¼ˆå†…éƒ¨å·¥å…·å‡½æ•°ï¼‰"""
    voice_config = api_config.get("voice")
    if not voice_config:
        voice_config = api_config.get("fast")
    return get_async_omni_client(voice_config)


# ============================================================================
# é¢è¯•è§„åˆ’èŠ‚ç‚¹
# ============================================================================


async def node_planner(
    resume: str,
    job_description: str,
    company_info: str,
    max_questions: int,
    api_config: Dict[str, Any],
    session_id: Optional[str] = None  # æ–°å¢ï¼šç”¨äºå¤šè½®é¢è¯•æ”¯æŒ
) -> Dict[str, Any]:
    """
    è§„åˆ’èŠ‚ç‚¹ï¼šç”Ÿæˆé¢è¯•è®¡åˆ’
    ä½¿ç”¨ç»Ÿä¸€çš„ interview_planner æ¨¡å—ï¼Œæ”¯æŒå¤šè½®é¢è¯•
    
    Args:
        resume: ç®€å†å†…å®¹
        job_description: å²—ä½æè¿°
        company_info: å…¬å¸ä¿¡æ¯
        max_questions: æœ€å¤§é—®é¢˜æ•°
        api_config: API é…ç½®
        session_id: ä¼šè¯ IDï¼ˆç”¨äºè·å–è½®æ¬¡ä¿¡æ¯ï¼‰
        
    Returns:
        åŒ…å« interview_plan å’Œ system_prompt çš„çŠ¶æ€æ›´æ–°
    """
    from . import interview_planner
    
    # è·å–è½®æ¬¡ä¿¡æ¯ï¼ˆå¤šè½®é¢è¯•æ”¯æŒï¼‰
    round_index = 1
    round_type = "voice_default"  # è¯­éŸ³é¢è¯•é»˜è®¤ç­–ç•¥
    previous_profile = None
    previous_questions = []
    
    if session_id:
        try:
            service = SessionService()
            session = await service.get_session(session_id)
            if session and session.metadata:
                # è·å–è½®æ¬¡ä¿¡æ¯
                round_index = getattr(session.metadata, 'round_index', 1) or 1
                stored_round_type = getattr(session.metadata, 'round_type', None)
                
                # è¯­éŸ³é¢è¯•ä½¿ç”¨ç‰¹å®šçš„è½®æ¬¡ç­–ç•¥æ˜ å°„
                if stored_round_type:
                    voice_round_type_map = {
                        "tech_initial": "voice_default",
                        "tech_deep": "tech_deep",  # æ·±åº¦è¿½é—®ä¿æŒåŸç­–ç•¥
                        "hr_comprehensive": "hr_comprehensive",  # HR ç»¼åˆé¢è¯•ä¿æŒåŸç­–ç•¥
                    }
                    round_type = voice_round_type_map.get(stored_round_type, "voice_default")
                
                # è·å–ä¸Šä¸€è½®ç”»åƒå’Œé—®é¢˜ï¼ˆå¦‚æœæ˜¯ç¬¬äºŒè½®åŠä»¥åï¼‰
                parent_session_id = getattr(session.metadata, 'parent_session_id', None)
                if round_index > 1 and parent_session_id:
                    previous_profile = await service.get_profile(parent_session_id)
                    parent_plan = await service.get_interview_plan(parent_session_id)
                    if parent_plan:
                        previous_questions = [q.get("content", q.get("topic", "")) for q in parent_plan]
                    logger.info(f"[Voice] å¤šè½®é¢è¯•ç¬¬ {round_index} è½®ï¼Œä¸Šä¸€è½®é—®é¢˜æ•°: {len(previous_questions)}")
                        
        except Exception as e:
            logger.error(f"[Voice] è·å–è½®æ¬¡ä¿¡æ¯å¤±è´¥: {e}")
    
    # ä½¿ç”¨ç»Ÿä¸€çš„è§„åˆ’æ¨¡å—
    interview_plan = await interview_planner.generate_interview_plan(
        resume=resume,
        job_description=job_description,
        company_info=company_info,
        max_questions=max_questions,
        api_config=api_config,
        round_type=round_type,
        round_index=round_index,
        previous_profile=previous_profile,
        previous_questions=previous_questions,
        output_format="simple",  # è¯­éŸ³é¢è¯•ä½¿ç”¨ç®€å•æ ¼å¼ï¼šåªæœ‰ topic å’Œ content
        session_id=session_id,
        save_to_db=True if session_id else False  # å¦‚æœæœ‰ session_id åˆ™ä¿å­˜åˆ°æ•°æ®åº“
    )
    
    # æ„å»º system_prompt
    system_prompt = _build_system_prompt(interview_plan)
    
    # è·å–å¼€åœºç™½æ–‡æœ¬ï¼ˆæ ¹æ®è½®æ¬¡è°ƒæ•´ï¼‰
    first_question = interview_plan[0].get("content") if interview_plan else None
    opening_message = _get_opening_message(first_question, round_index)
    
    return {
        "interview_plan": interview_plan,
        "system_prompt": system_prompt,
        "opening_message": opening_message,
        "current_phase": "greeting",
        "round_index": round_index,
        "round_type": round_type
    }


def calculate_interview_progress(history: List[Dict[str, Any]], plan: List[Dict[str, Any]], initial_q_idx: int = 0) -> Dict[str, Any]:
    """
    é€šè¿‡åˆ†æå†å²å¯¹è¯ï¼Œæ¨æ–­å½“å‰çš„é¢è¯•è¿›åº¦ã€‚
    """
    current_q_idx = initial_q_idx
    follow_up_count = 0
    last_q_text = ""
    last_planned_q_found = False

    if not plan:
        return {"current_q_idx": 0, "follow_up_count": 0, "last_q_text": "", "is_complete": False}

    import re

    def is_match(ai_content: str, q_topic: str, q_content: str, q_idx: int) -> bool:
        """å¤šç»´åº¦åŒ¹é…é€»è¾‘"""
        # é¢„å¤„ç† AI å†…å®¹ï¼šå»é™¤æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼ï¼Œç»Ÿä¸€åŒ¹é…å£å¾„
        clean_ai = re.sub(r'[^\w\u4e00-\u9fa5]', '', ai_content)
        
        # 1. é¢˜å·åŒ¹é… (å¦‚ "ç¬¬ä¸€ä¸ªé—®é¢˜", "ç¬¬äºŒé¢˜", "1.", "2)", æ”¯æŒä¸­æ–‡æ•°å­—)
        chinese_nums = ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å"]
        num_patterns = [
            f"ç¬¬{q_idx+1}[ä¸ªé¢˜é—®è¯]", 
            f"ç¬¬{q_idx+1}é˜¶æ®µ",
            f"^({q_idx+1}[.ã€])",
            f"({q_idx+1}[.ã€])"
        ]
        # æ·»åŠ ä¸­æ–‡æ•°å­—åŒ¹é… (å¦‚ "ç¬¬ä¸€é¢˜")
        if q_idx < len(chinese_nums):
            num_patterns.append(f"ç¬¬{chinese_nums[q_idx]}[ä¸ªé¢˜é—®è¯]")
            num_patterns.append(f"ç¬¬{chinese_nums[q_idx]}é˜¶æ®µ")
        
        # å¢åŠ å¯¹â€œæœ€åä¸€é¢˜â€çš„è¯†åˆ«
        if q_idx == len(plan) - 1:
            num_patterns.append("æœ€åä¸€é¢˜")
            num_patterns.append("æœ€åä¸€ä¸ªé—®é¢˜")
            num_patterns.append("ç»“æŸé¢è¯•")
            
        if any(re.search(p, ai_content) for p in num_patterns):
            return True

        # 2. Topic æ¨¡ç³ŠåŒ¹é…
        if q_topic:
            clean_topic = re.sub(r'[^\w\u4e00-\u9fa5]', '', q_topic)
            # å¼ºåŒ–åŒ¹é…è¦æ±‚ï¼šå°‘äº4ä¸ªå­—çš„ Topic å¿…é¡»å®Œå…¨åŒ…å«ä¸”ä¸æ˜¯è¢«åŒ…å«åœ¨æ›´é•¿çš„è¯ä¸­ï¼Œæˆ–è€…è¦æ±‚ AI æ˜ç¡®æåŠ
            if len(clean_topic) >= 2:
                # æ’é™¤æå…¶å¸¸è§çš„å¹²æ‰°è¯ï¼ˆå¦‚"é¡¹ç›®", "ç»éªŒ"ç­‰ï¼Œé™¤éå®ƒä»¬æ˜¯ Topic çš„æ ¸å¿ƒï¼‰
                common_filters = ["é¡¹ç›®", "ç»éªŒ", "æŠ€æœ¯", "åŸºç¡€", "äº†è§£", "é¢è¯•", "é—®é¢˜"]
                if clean_topic in clean_ai:
                    # å¦‚æœ Topic åªæœ‰ 2 ä¸ªå­—ä¸”æ˜¯å¸¸è§è¯ï¼Œè¦æ±‚å‘¨å›´æœ‰æ›´æ˜ç¡®çš„æç¤ºè¯ï¼Œæˆ–è€…ä¸ä»…æ˜¯åŒ…å«
                    if len(clean_topic) <= 2 and clean_topic in common_filters:
                        # æ£€æŸ¥æ˜¯å¦æœ‰â€œç¬¬Xä¸ªâ€æˆ–â€œå…³äºâ€ç­‰å‰åºè¯
                        if re.search(f"ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d][ä¸ªç¯èŠ‚é¢˜é—®è¯].*{clean_topic}", ai_content) or f"å…³äº{clean_topic}" in ai_content:
                            return True
                    else:
                        return True

        # 3. Content æ ¸å¿ƒæˆåˆ†åŒ¹é… (æ»‘åŠ¨çª—å£åŒ¹é…)
        core_text = re.sub(r'[^\w\u4e00-\u9fa5]', '', q_content[:40])
        if len(core_text) >= 12:
            # å¢åŠ åŒ¹é…é•¿åº¦è¦æ±‚åˆ° 10 ä¸ªè¿ç»­å­—ç¬¦ï¼Œå‡å°‘è¯¯åˆ¤
            for j in range(len(core_text) - 9):
                if core_text[j:j+10] in clean_ai:
                    return True
        elif core_text and len(core_text) > 4 and core_text in clean_ai:
            return True

        return False

    # éå†å†å²è®°å½•
    # ç­–ç•¥ï¼šæˆ‘ä»¬åªéœ€è¦çœ‹åŠ©æ‰‹çš„æ¯å¥è¯ï¼Œçœ‹å®ƒæ˜¯å¦å¼•å¯¼åˆ°äº†æ–°çš„ä¸€é¢˜
    for msg in history:
        if msg.get("role") == "assistant":
            content = msg.get("content", "").strip()
            if not content: continue
            
            # 1. å°è¯•åŒ¹é…ä¸‹ä¸€é¢˜ (current_q_idx + 1)
            # åªæœ‰å½“åŒ¹é…åˆ°ä¸‹ä¸€é¢˜æˆ–æ›´åçš„é¢˜ç›®æ—¶ï¼Œæ‰æ¨è¿›ç´¢å¼•
            found_next = False
            for i in range(current_q_idx + 1, len(plan)):
                p = plan[i]
                if is_match(content, p.get("topic", ""), p.get("content", ""), i):
                    current_q_idx = i
                    follow_up_count = 0
                    last_q_text = p.get("content", "")
                    last_planned_q_found = True
                    found_next = True
                    logger.debug(f"[Progress] åŒ¹é…åˆ°æ–°é¢˜ç›®ç´¢å¼•: {i}")
                    break
            
            if not found_next:
                # 2. å¦‚æœæ²¡åŒ¹é…åˆ°ä¸‹ä¸€é¢˜ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯åœ¨è¯´å½“å‰é¢˜
                curr_p = plan[current_q_idx]
                if is_match(content, curr_p.get("topic", ""), curr_p.get("content", ""), current_q_idx):
                    if not last_planned_q_found:
                        # ç¬¬ä¸€æ¬¡æ˜ç¡®åŒ¹é…åˆ°å½“å‰é¢˜
                        last_planned_q_found = True
                        last_q_text = curr_p.get("content", "")
                    else:
                        # å·²ç»åœ¨è¿™ä¸€é¢˜äº†ï¼Œç°åœ¨çš„å¯¹è¯ç®—è¿½é—®
                        follow_up_count += 1
                        last_q_text = content
                elif last_planned_q_found:
                    # æ—¢ä¸æ˜¯ä¸‹ä¸€é¢˜ï¼Œä¹Ÿä¸æ˜¯å½“å‰é¢˜çš„å…³é”®è¯åŒ¹é…ï¼Œä½† AI åœ¨è¯´è¯ï¼Œé€šå¸¸æ˜¯è‡ªç„¶è¯­è¨€è¿½é—®
                    # å¦‚æœä¸æ˜¯éå¸¸çŸ­çš„å¥å­ï¼ˆå¦‚â€œå¥½çš„â€ï¼‰ï¼Œè®¡ä¸ºè¿½é—®
                    if len(content) > 10:
                        follow_up_count += 1
                        last_q_text = content

    # è®¡ç®—æ˜¯å¦å®Œæˆé¢è¯•
    is_complete = False
    last_ai_msg = ""
    for msg in reversed(history):
        if msg.get("role") == "assistant":
            last_ai_msg = msg.get("content", "").lower()
            break
    
    # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾è®¡åˆ’æœ«å°¾
    if current_q_idx >= len(plan) - 1:
        closing_keywords = ["é¢è¯•ç»“æŸ", "å†è§", "è°¢è°¢ä½ çš„å‚åŠ ", "ç¥ä½ ç”Ÿæ´»æ„‰å¿«", "ä»Šå¤©çš„é¢è¯•å°±åˆ°è¿™é‡Œ", "è¾›è‹¦äº†", "æ‹œæ‹œ", "æœŸå¾…ä½ çš„åŠ å…¥"]
        if any(kw in last_ai_msg for kw in closing_keywords):
            is_complete = True
        elif follow_up_count >= 3:
            is_complete = True

    return {
        "current_q_idx": current_q_idx,
        "follow_up_count": follow_up_count,
        "last_q_text": last_q_text,
        "is_complete": is_complete
    }


def _build_system_prompt(
    interview_plan: List[Dict[str, Any]], 
    current_q_idx: int = 0, 
    follow_up_count: int = 0,
    last_q_text: str = ""
) -> str:
    """
    æ ¹æ®é¢è¯•è®¡åˆ’å’Œå½“å‰çŠ¶æ€æ„å»º Omni çš„ System Prompt
    """
    questions_text = "\n".join([
        f"{i+1}. [{q.get('topic')}] {q.get('content')}" 
        for i, q in enumerate(interview_plan)
    ])
    
    current_plan_q = interview_plan[current_q_idx].get('content') if current_q_idx < len(interview_plan) else "é¢è¯•ç»“æŸ"
    next_plan_q = interview_plan[current_q_idx + 1].get('content') if current_q_idx + 1 < len(interview_plan) else "é¢è¯•ç»“æŸ"
    
    # åŠ¨æ€å»ºè®® - è¿½é—®é™åˆ¶ 2 æ¬¡
    MAX_FOLLOW_UP = 2
    follow_up_advice = ""
    is_last_question = current_q_idx >= len(interview_plan) - 1
    
    if follow_up_count >= MAX_FOLLOW_UP:
        if is_last_question:
            follow_up_advice = """ã€ğŸ¯ é¢è¯•ç»“é¡¹æŒ‡ä»¤ã€‘ï¼š
1. ä½ å·²å®Œæˆæ‰€æœ‰è€ƒå¯Ÿã€‚è¯·è¿›è¡Œç®€çŸ­ä¸€å¥è¯çœŸå®è¯„ä»·ï¼Œå¹¶å‹å¥½åœ°å‘Šåˆ«ã€‚
2. å¿…é¡»åŒ…å«å…³é”®è¯ï¼š'é¢è¯•ç»“æŸ'ã€‚"""
        else:
            follow_up_advice = f"""ã€â­ï¸ å¼ºåˆ¶åˆ‡æ¢è¯é¢˜ã€‘ï¼šå½“å‰è¯é¢˜è¿½é—®æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œè¯·ç«‹å³åˆ‡æ¢åˆ°ä¸‹ä¸€é¢˜ã€‚
**è§„åˆ™**ï¼šä½ å¿…é¡»åœ¨å›å¤ä¸­æ˜ç¡®æåˆ°â€œä¸‹ä¸€é¢˜â€æˆ–â€œç¬¬ {current_q_idx + 2} ä¸ªé—®é¢˜â€ï¼Œå¹¶å¿µå‡ºé¢˜ç›®å†…å®¹ã€‚
ä¸‹ä¸€é¢˜ï¼š"{next_plan_q}"
è¿‡æ¸¡ç¤ºä¾‹ï¼š"å¥½çš„ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬è¿›å…¥ç¬¬ {current_q_idx + 2} ä¸ªé—®é¢˜ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹..." + ä¸‹ä¸€é¢˜å†…å®¹"""
    elif is_last_question:
        follow_up_advice = """ã€ğŸ’¡ æœ€åä¸€é¢˜ã€‘ï¼šè¿™æ˜¯æœ€åä¸€ä¸ªç¯èŠ‚ã€‚
- å¦‚æœå€™é€‰äººå›ç­”å·²è¦†ç›–æ ¸å¿ƒè¦ç‚¹ï¼Œæ— éœ€è¿½é—®ï¼Œè¯·ç›´æ¥ç»“æŸé¢è¯•ï¼ˆå¿…é¡»åŒ…å«"é¢è¯•ç»“æŸ"ï¼‰ã€‚
- ä»…åœ¨å›ç­”æåº¦ä¸å®Œæ•´æ—¶ï¼Œæ‰è¿›è¡Œæœ€å¤š 1 æ¬¡è¡¥å……è¿½é—®ã€‚"""
    elif follow_up_count > 0:
        follow_up_advice = "ã€ğŸ“ å½“å‰è¿›åº¦ã€‘ï¼šå·²è¿›è¡Œè¿‡è¿½é—®ã€‚å¦‚æœå€™é€‰äººç°åœ¨çš„è¡¥å……å·²ç»æ¸…æ™°ï¼Œ**ä¸¥ç¦å†æ¬¡è¿½é—®**ï¼Œè¯·ç«‹å³åˆ‡æ¢åˆ°ä¸‹ä¸€é¢˜ã€‚"
    else:
        follow_up_advice = f"ã€ğŸ“ å½“å‰è¿›åº¦ã€‘ï¼šè¿™æ˜¯ç¬¬ {current_q_idx + 1} é¢˜çš„é¦–æ¬¡æé—®ã€‚å¦‚æœå€™é€‰äººå›ç­”å¾—ä¸é”™ï¼Œè¯·**ä¸è¦è¿½é—®**ï¼Œç›´æ¥è¿›å…¥ä¸‹ä¸€é¢˜ã€‚ä»…åœ¨å›ç­”æ¯”è¾ƒç¬¼ç»Ÿæ—¶æ‰è¿›è¡Œ 1 æ¬¡å¯å‘å¼æé—®ã€‚"

    return f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šã€è€å¿ƒã€å–„äºå¼•å¯¼çš„æŠ€æœ¯é¢è¯•å®˜ã€‚
ä½ æ­£åœ¨é€šè¿‡è¯­éŸ³ä¸å€™é€‰äººè¿›è¡Œä¸€å¯¹ä¸€é¢è¯•ã€‚

ã€é¢è¯•è®¡åˆ’ã€‘ï¼š
{questions_text}

ã€å½“å‰çŠ¶æ€ã€‘ï¼š
- å½“å‰æ­¥éª¤ï¼šç¬¬ {current_q_idx + 1} é¢˜ â€”â€” "{current_plan_q}"
- å·²è¿½é—®æ¬¡æ•°ï¼š{follow_up_count} / {MAX_FOLLOW_UP}
- ä¸‹ä¸€æ­¥éª¤ï¼š"{next_plan_q}"

{follow_up_advice}

ã€æ ¸å¿ƒè¡Œä¸ºå‡†åˆ™ã€‘ï¼š

1. **è¯†åˆ«æ— æ•ˆ/ç®€çŸ­å›ç­”**ï¼š
   - å€™é€‰äººåªè¯´"ä½ å¥½"ã€"å¥½çš„"ã€"å—¯"ç­‰ä¸æ˜¯æœ‰æ•ˆå›ç­”ã€‚
   - æ­¤æ—¶è¦å‹å¥½å¼•å¯¼ï¼Œä¾‹å¦‚ï¼š"ä½ å¥½ï¼é‚£æˆ‘ä»¬æ­£å¼å¼€å§‹ï¼Œè¯·å…ˆä»‹ç»ä¸€ä¸‹ä½ æœ€è¿‘åšè¿‡çš„ä¸€ä¸ªé¡¹ç›®å§ã€‚"
   
2. **è¿½é—®ç­–ç•¥**ï¼š
   - ä¿æŒé«˜æ•ˆç‡ã€‚å¦‚æœå€™é€‰äººå›ç­”å·²è¾¾åˆ°è€ƒå¯Ÿç›®çš„ï¼Œ**ä¸¥ç¦æ— æ„ä¹‰çš„è¿½é—®**ã€‚
   - åªæœ‰åœ¨å›ç­”ç¡®å®ç”±äºå¹²æ‰°æˆ–ç®€ç•¥å¯¼è‡´æ— æ³•è¯„ä¼°æ—¶ï¼Œæ‰è¿›è¡Œ 1 æ¬¡ç²¾å‡†è¿½é—®ã€‚
   
3. **è‡ªç„¶åˆ‡é¢˜**ï¼š
   - ä¼˜å…ˆå‘ä¸‹æ¨è¿›é¢è¯•è®¡åˆ’ã€‚ä¸€æ—¦å¾—åˆ°æœ‰æ•ˆå›ç­”ï¼Œç«‹å³è¿›å…¥ä¸‹ä¸€é¢˜ã€‚
   - åˆ‡æ¢æ—¶è¯·æ¸…æ™°è¯´å‡ºâ€œä¸‹ä¸€é¢˜â€æˆ–â€œç¬¬ X é¢˜â€ã€‚

4. **è¯­éŸ³å¯¹è¯è§„èŒƒ**ï¼š
   - ç”¨å£è¯­åŒ–ã€å¹³æ˜“è¿‘äººçš„è¯­æ°”ã€‚
   - ç¦æ­¢ä½¿ç”¨ Markdown ç¬¦å·ï¼ˆå¦‚ #, *, -, >ï¼‰ã€æ‹¬å·æ³¨é‡Šæˆ–ç‰¹æ®Šæ ¼å¼ã€‚
   - ç»™å‡ºæ­£é¢åé¦ˆåç«‹å³æé—®/è¿½é—®ã€‚

å…¨ç¨‹ä½¿ç”¨ä¸­æ–‡å¯¹è¯ã€‚"""


def _get_opening_message(first_question: str = None, round_index: int = 1) -> str:
    """
    è·å–é¢è¯•å¼€åœºç™½ï¼ˆå†…éƒ¨å‡½æ•°ï¼‰
    
    Args:
        first_question: ç¬¬ä¸€ä¸ªé—®é¢˜çš„å†…å®¹
        round_index: å½“å‰è½®æ¬¡ï¼ˆç”¨äºç”Ÿæˆä¸åŒçš„å¼€åœºç™½ï¼‰
    """
    # æ ¹æ®è½®æ¬¡ç”Ÿæˆä¸åŒçš„å¼€åœºç™½
    if round_index == 1:
        greeting = "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„é¢è¯•å®˜ã€‚"
    elif round_index == 2:
        greeting = "æ¬¢è¿æ¥åˆ°ç¬¬äºŒè½®é¢è¯•ï¼Œæˆ‘æ˜¯æœ¬è½®çš„é¢è¯•å®˜ã€‚"
    else:
        greeting = f"æ¬¢è¿æ¥åˆ°ç¬¬ {round_index} è½®é¢è¯•ï¼Œæˆ‘å°†ç»§ç»­æ‹…ä»»ä½ çš„é¢è¯•å®˜ã€‚"
    
    if first_question:
        return f"{greeting}\n\n{first_question}"
    else:
        return f"{greeting} è¯·å…ˆåšä¸€ä¸ªç®€çŸ­çš„è‡ªæˆ‘ä»‹ç»ã€‚"


# ============================================================================
# å¼€åœºç™½èŠ‚ç‚¹ (SSE æµå¼è¾“å‡º)
# ============================================================================

async def node_greeting(state: VoiceInterviewState) -> AsyncGenerator[str, None]:
    """
    å¼€åœºç™½èŠ‚ç‚¹ï¼šç”Ÿæˆå¼€åœºç™½çš„éŸ³é¢‘ï¼ˆSSE æµå¼è¾“å‡ºï¼‰
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Yields:
        SSE æ ¼å¼çš„äº‹ä»¶æ•°æ®
    """
    session_id = state.get("session_id")
    text_message = state.get("text_message")  # å¼€åœºç™½æ–‡æœ¬
    api_config = state.get("api_config", {})
    
    try:
        logger.info(f"[Voice] å¼€åœºç™½èŠ‚ç‚¹å¼€å§‹: session={session_id}, text={text_message[:50] if text_message else 'None'}...")
        
        client = _get_omni_client(api_config)
        
        # TTS ä¸“ç”¨æ¶ˆæ¯ - åªåšè¯­éŸ³åˆæˆ
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åˆæˆç³»ç»Ÿã€‚ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æä¾›çš„æ–‡å­—è½¬æ¢æˆè¯­éŸ³ã€‚è¯·åŸå°ä¸åŠ¨åœ°æœ—è¯»ç”¨æˆ·è¾“å…¥çš„æ–‡å­—ï¼Œä¸è¦æ·»åŠ ã€åˆ é™¤æˆ–ä¿®æ”¹ä»»ä½•å†…å®¹ï¼Œä¸è¦è¿›è¡Œå›å¤æˆ–å¯¹è¯ï¼Œåªéœ€è¦æœ—è¯»ã€‚"
            },
            {
                "role": "user",
                "content": f"è¯·æœ—è¯»ä»¥ä¸‹å†…å®¹ï¼š\n\n{text_message}"
            }
        ]
        
        # è°ƒç”¨ Omni æ¨¡å‹
        completion = await client.chat.completions.create(
            model="qwen3-omni-flash-2025-12-01",
            messages=messages,
            modalities=["text", "audio"],
            audio={"voice": "Cherry", "format": "wav"},
            stream=True,
            stream_options={"include_usage": True},
        )
        
        # å¤„ç†æµå¼å“åº”
        text_response = ""
        audio_chunks = []
        
        async for chunk in completion:
            if chunk.choices:
                delta = chunk.choices[0].delta
                
                # æµå¼è¾“å‡ºæ–‡æœ¬
                if hasattr(delta, 'content') and delta.content:
                    text_response += delta.content
                    yield f"data: {json.dumps({'type': 'text', 'content': delta.content}, ensure_ascii=False)}\n\n"
                
                # æµå¼è¾“å‡ºéŸ³é¢‘
                if hasattr(delta, 'audio') and delta.audio:
                    audio_data = None
                    if isinstance(delta.audio, dict):
                        audio_data = delta.audio.get("data")
                    elif hasattr(delta.audio, 'data'):
                        audio_data = delta.audio.data
                    
                    if audio_data:
                        yield f"data: {json.dumps({'type': 'audio', 'content': audio_data}, ensure_ascii=False)}\n\n"
                        audio_chunks.append(audio_data)
        
        logger.info(f"[Voice] å¼€åœºç™½èŠ‚ç‚¹å®Œæˆ: text={len(text_response)}å­—ç¬¦, audio_chunks={len(audio_chunks)}")
        
        # å‘é€å®Œæˆä¿¡å·
        yield f"data: {json.dumps({'type': 'done', 'text': text_response}, ensure_ascii=False)}\n\n"
        
        # å¼‚æ­¥ä¿å­˜å¼€åœºç™½æ¶ˆæ¯
        asyncio.create_task(save_message_async(session_id, "assistant", text_response))
        
    except Exception as e:
        logger.error(f"[Voice] å¼€åœºç™½èŠ‚ç‚¹å¤±è´¥: {e}", exc_info=True)
        yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"


# ============================================================================
# å¯¹è¯èŠ‚ç‚¹ (SSE æµå¼è¾“å‡º)
# ============================================================================

async def node_responder(state: VoiceInterviewState) -> AsyncGenerator[str, None]:
    """
    å¯¹è¯èŠ‚ç‚¹ï¼šå¤„ç†ç”¨æˆ·è¾“å…¥å¹¶ç”Ÿæˆ AI å›å¤ï¼ˆSSE æµå¼è¾“å‡ºï¼‰
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Yields:
        SSE æ ¼å¼çš„äº‹ä»¶æ•°æ®
    """
    session_id = state.get("session_id")
    history = state.get("history", [])
    audio_base64 = state.get("audio_base64")
    text_message = state.get("text_message")
    audio_id = state.get("audio_id")
    api_config = state.get("api_config", {})
    
    try:
        # 1. è·å–é¢è¯•è®¡åˆ’å’Œè¿›åº¦
        service = SessionService()
        session = await service.get_session(session_id)
        
        # ä»æ•°æ®åº“è·å–é¢è¯•è®¡åˆ’
        interview_plan = await service.get_interview_plan(session_id) or []
        # è·å–ä¸Šæ¬¡ä¿å­˜çš„è¿›åº¦ä½œä¸ºèµ·ç‚¹ (question_count å­˜å‚¨çš„æ˜¯ 0-based é¢˜ç›®ç´¢å¼•)
        initial_q_idx = getattr(session.metadata, 'question_count', 0) if hasattr(session, 'metadata') else 0
        if not isinstance(initial_q_idx, int):
            initial_q_idx = 0

        # 1. è®¡ç®—å¯¹è¯åçš„æ–°è¿›åº¦
        progress = calculate_interview_progress(history, interview_plan, initial_q_idx)
        current_q_idx = progress["current_q_idx"]
        follow_up_count = progress["follow_up_count"]
        last_q_text = progress["last_q_text"]
        
        # ã€æŒä¹…åŒ–ç”¨æˆ·æ¶ˆæ¯ã€‘ä½¿ç”¨å‡†ç¡®çš„å½“å‰é¢˜ç›®ç´¢å¼•
        user_content = text_message if text_message else "[è¯­éŸ³]"
        await save_message_async(session_id, "user", user_content, question_index=current_q_idx, audio_url=audio_id)

        # 2. é‡æ–°ç”Ÿæˆé’ˆå¯¹å½“å‰è¿›åº¦çš„ System Prompt
        system_prompt = _build_system_prompt(
            interview_plan, 
            current_q_idx, 
            follow_up_count,
            last_q_text
        )

        logger.info(f"[Voice] å¯¹è¯èŠ‚ç‚¹å¼€å§‹: session={session_id}, è¿›åº¦=é¢˜{current_q_idx+1}/è¿½é—®{follow_up_count}")
        
        client = _get_omni_client(api_config)
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        
        # System Prompt
        if system_prompt:
            messages.append({
                "role": "system",
                "content": system_prompt
            })
        
        # å†å²æ¶ˆæ¯ (æœ€è¿‘ 15 æ¡)
        for msg in history[-15:]:
            messages.append(msg)
        
        # å½“å‰ç”¨æˆ·è¾“å…¥
        if audio_base64:
            audio_data_url = f"data:audio/wav;base64,{audio_base64}"
            messages.append({
                "role": "user",
                "content": [
                    {
                        "type": "input_audio",
                        "input_audio": {
                            "data": audio_data_url,
                            "format": "wav"
                        }
                    }
                ]
            })
        elif text_message:
            messages.append({
                "role": "user",
                "content": text_message
            })
        
        logger.info(f"[Voice] å‘é€ Omni è¯·æ±‚: session={session_id}, msgs_len={len(messages)}")
        
        # è°ƒç”¨ Omni æ¨¡å‹
        completion = await client.chat.completions.create(
            model="qwen3-omni-flash-2025-12-01",
            messages=messages,
            modalities=["text", "audio"],
            audio={"voice": "Cherry", "format": "wav"},
            stream=True,
            stream_options={"include_usage": True},
        )
        
        # å¤„ç†æµå¼å“åº”
        text_response = ""
        audio_chunks = []
        chunk_count = 0
        
        async for chunk in completion:
            chunk_count += 1
            if chunk.choices:
                delta = chunk.choices[0].delta
                
                # æµå¼è¾“å‡ºæ–‡æœ¬
                if hasattr(delta, 'content') and delta.content:
                    text_response += delta.content
                    yield f"data: {json.dumps({'type': 'text', 'content': delta.content}, ensure_ascii=False)}\n\n"
                
                # æµå¼è¾“å‡ºéŸ³é¢‘
                if hasattr(delta, 'audio') and delta.audio:
                    audio_data = None
                    if isinstance(delta.audio, dict):
                        audio_data = delta.audio.get("data")
                    elif hasattr(delta.audio, 'data'):
                        audio_data = delta.audio.data
                    
                    if audio_data:
                        yield f"data: {json.dumps({'type': 'audio', 'content': audio_data}, ensure_ascii=False)}\n\n"
                        audio_chunks.append(audio_data)
        
        logger.info(f"[Voice] å¯¹è¯èŠ‚ç‚¹å®Œæˆ: chunks={chunk_count}, text={len(text_response)}å­—ç¬¦, audio_chunks={len(audio_chunks)}")
        
        # å†æ¬¡è®¡ç®—è¿›åº¦ï¼Œä»¥åŒ…å« AI åˆšåˆšç»™å‡ºçš„å›å¤ï¼ˆåˆ¤æ–­ AI æ˜¯å¦å·²ç»è¿›å…¥äº†ä¸‹ä¸€é¢˜ï¼‰
        user_content = text_message if text_message else "[è¯­éŸ³]"
        new_history = history + [
            {"role": "user", "content": user_content},
            {"role": "assistant", "content": text_response}
        ]
        new_progress = calculate_interview_progress(new_history, interview_plan, initial_q_idx=current_q_idx)
        new_q_idx = new_progress["current_q_idx"]
        is_complete = new_progress.get("is_complete", False)
        
        # 1. å‘é€è¿›åº¦æ›´æ–°
        yield f"data: {json.dumps({'type': 'progress', 'current': new_q_idx + 1}, ensure_ascii=False)}\n\n"
        
        # å¦‚æœé¢è¯•å·²å®Œæˆï¼Œå‘é€å¯¹åº”æ ‡å¿—å¹¶æ›´æ–°çŠ¶æ€ï¼ˆç”»åƒåˆ†æåœ¨æ€»ç»“èŠ‚ç‚¹æˆ–æ‰‹åŠ¨è°ƒç”¨æ—¶ç»Ÿä¸€è§¦å‘ï¼‰
        if is_complete:
            from . import interview_analysis
            yield f"data: {json.dumps({'type': 'complete'}, ensure_ascii=False)}\n\n"
            # åªæ›´æ–°çŠ¶æ€ï¼Œä¸è§¦å‘ç”»åƒåˆ†æï¼ˆé¿å…é‡å¤è§¦å‘ï¼Œç”±æ€»ç»“æ¥å£ç»Ÿä¸€å¤„ç†ï¼‰
            asyncio.create_task(interview_analysis.handle_interview_complete(
                session_id=session_id,
                api_config=api_config,
                trigger_analysis=False  # ç”»åƒåˆ†æç”± /api/voice/summary ç»Ÿä¸€è§¦å‘
            ))

        # 2. å‘é€å®Œæˆä¿¡å·
        yield f"data: {json.dumps({'type': 'done', 'text': text_response}, ensure_ascii=False)}\n\n"
        
        # 3. åŒæ­¥æŒä¹…åŒ–è¿›åº¦ï¼ˆquestion_count å­˜å‚¨ 0-based ç´¢å¼•ï¼Œç”¨äºæ ‡è¯†å½“å‰è¿›å±•é¢˜å·ï¼‰
        await service.update_session_question_count(session_id, new_q_idx)
        # æ³¨æ„ï¼šuser æ¶ˆæ¯å·²ç»åœ¨å¼€å¤´å­˜è¿‡äº†ï¼Œè¿™é‡Œåªå­˜ assistant
        await save_message_async(session_id, "assistant", text_response, question_index=new_q_idx)
        
    except Exception as e:
        logger.error(f"[Voice] å¯¹è¯èŠ‚ç‚¹å¤±è´¥: {e}", exc_info=True)
        yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"


async def node_summary(state: VoiceInterviewState) -> AsyncGenerator[str, None]:
    """
    æ€»ç»“èŠ‚ç‚¹ï¼šåœ¨é¢è¯•ç»“æŸåç”Ÿæˆé¢è¯•åé¦ˆæ€»ç»“ï¼ˆSSE æµå¼è¾“å‡ºï¼‰
    """
    from . import interview_analysis
    
    session_id = state.get("session_id")
    api_config = state.get("api_config", {})
    history = state.get("history", [])
    
    try:
        logger.info(f"[Voice] æ€»ç»“èŠ‚ç‚¹å¼€å§‹: session={session_id}")
        
        # ä½¿ç”¨ç»Ÿä¸€å¤„ç†æµç¨‹
        summary = await interview_analysis.process_interview_summary(
            session_id=session_id,
            messages=history,
            mode="mock",
            api_config=api_config,
            trigger_analysis=True
        )
        
        # æµå¼è¾“å‡ºæ€»ç»“ï¼ˆæ¨¡æ‹Ÿé€å­—è¾“å‡ºæ•ˆæœï¼‰
        chunk_size = 20
        for i in range(0, len(summary), chunk_size):
            chunk = summary[i:i+chunk_size]
            yield f"data: {json.dumps({'type': 'summary_text', 'content': chunk}, ensure_ascii=False)}\n\n"
        
        # å‘é€å®Œæˆä¿¡å·
        yield f"data: {json.dumps({'type': 'summary_done', 'text': summary}, ensure_ascii=False)}\n\n"
        
        # ä¿å­˜æ€»ç»“åˆ°å¯¹è¯è®°å½•
        await save_message_async(session_id, "assistant", f"ã€é¢è¯•æ€»ç»“ã€‘\n\n{summary}")
        
        logger.info(f"[Voice] æ€»ç»“èŠ‚ç‚¹å®Œæˆ: session={session_id}")
        
    except Exception as e:
        logger.error(f"[Voice] æ€»ç»“èŠ‚ç‚¹å¤±è´¥: {e}", exc_info=True)
        yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"


async def generate_voice_summary(
    session_id: str,
    api_config: Dict[str, Any]
) -> AsyncGenerator[str, None]:
    """
    ç”Ÿæˆè¯­éŸ³é¢è¯•æ€»ç»“ï¼ˆå¯¹å¤–æ¥å£ï¼ŒSSE æµå¼è¾“å‡ºï¼‰
    """
    from . import interview_analysis
    
    try:
        logger.info(f"[Voice] å¼€å§‹ç”Ÿæˆé¢è¯•æ€»ç»“: session={session_id}")
        
        # è·å–ä¼šè¯å†å²
        service = SessionService()
        session = await service.get_session(session_id)
        
        if not session:
            yield f"data: {json.dumps({'type': 'error', 'message': 'ä¼šè¯ä¸å­˜åœ¨'})}\n\n"
            return
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        history = []
        if session.messages:
            for msg in session.messages:
                if msg.role != "system" and msg.content:
                    history.append({"role": msg.role, "content": msg.content})
        
        # ä½¿ç”¨ç»Ÿä¸€å¤„ç†æµç¨‹
        summary = await interview_analysis.process_interview_summary(
            session_id=session_id,
            messages=history,
            mode="mock",
            api_config=api_config,
            trigger_analysis=True
        )
        
        # æµå¼è¾“å‡ºæ€»ç»“
        chunk_size = 20
        for i in range(0, len(summary), chunk_size):
            chunk = summary[i:i+chunk_size]
            yield f"data: {json.dumps({'type': 'summary_text', 'content': chunk}, ensure_ascii=False)}\n\n"
        
        # å‘é€å®Œæˆä¿¡å·
        yield f"data: {json.dumps({'type': 'summary_done', 'text': summary}, ensure_ascii=False)}\n\n"
        
        # ä¿å­˜
        await save_message_async(session_id, "assistant", f"ã€é¢è¯•æ€»ç»“ã€‘\n\n{summary}")
        
    except Exception as e:
        logger.error(f"[Voice] ç”Ÿæˆé¢è¯•æ€»ç»“å¤±è´¥: {e}", exc_info=True)
        yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"


# ============================================================================
# è·¯ç”±é€»è¾‘
# ============================================================================

def route_voice_entry(state: VoiceInterviewState) -> str:
    """
    å…¥å£è·¯ç”±ï¼šæ ¹æ®å½“å‰çŠ¶æ€å†³å®šè¿›å…¥å“ªä¸ªèŠ‚ç‚¹
    
    Args:
        state: å½“å‰çŠ¶æ€
        
    Returns:
        èŠ‚ç‚¹åç§°: "planner", "greeting", "responder"
    """
    current_phase = state.get("current_phase", "planning")
    interview_plan = state.get("interview_plan", [])
    
    # å¦‚æœæ²¡æœ‰é¢è¯•è®¡åˆ’ï¼Œè¿›å…¥è§„åˆ’èŠ‚ç‚¹
    if not interview_plan:
        return "planner"
    
    # å¦‚æœæ˜¯å¼€åœºç™½é˜¶æ®µ
    if current_phase == "greeting":
        return "greeting"
    
    # å¦‚æœé¢è¯•å·²å®Œæˆ
    if current_phase == "complete":
        return "summary"
    
    # é»˜è®¤è¿›å…¥å¯¹è¯èŠ‚ç‚¹
    return "responder"


# ============================================================================
# ç»Ÿä¸€å…¥å£å‡½æ•° (å…¼å®¹ç°æœ‰ API)
# ============================================================================

async def generate_interview_plan(
    resume: str,
    job_description: str,
    company_info: str,
    max_questions: int,
    api_config: Dict[str, Any],
    session_id: Optional[str] = None  # æ–°å¢ï¼šç”¨äºå¤šè½®é¢è¯•æ”¯æŒ
) -> List[Dict[str, str]]:
    """
    ç”Ÿæˆé¢è¯•è®¡åˆ’ï¼ˆå¯¹å¤–æ¥å£ï¼Œå…¼å®¹ç°æœ‰è°ƒç”¨ï¼‰
    
    Args:
        resume: ç®€å†å†…å®¹
        job_description: å²—ä½æè¿°
        company_info: å…¬å¸ä¿¡æ¯
        max_questions: æœ€å¤§é—®é¢˜æ•°
        api_config: API é…ç½®
        session_id: ä¼šè¯ IDï¼ˆç”¨äºå¤šè½®é¢è¯•çš„è½®æ¬¡ä¿¡æ¯è·å–ï¼‰
        
    Returns:
        é¢è¯•é—®é¢˜åˆ—è¡¨
    """
    result = await node_planner(resume, job_description, company_info, max_questions, api_config, session_id)
    return result.get("interview_plan", [])


def build_system_prompt(interview_plan: List[Dict[str, str]]) -> str:
    """
    æ ¹æ®é¢è¯•è®¡åˆ’æ„å»º System Promptï¼ˆå¯¹å¤–æ¥å£ï¼Œå…¼å®¹ç°æœ‰è°ƒç”¨ï¼‰
    """
    return _build_system_prompt(interview_plan)


def get_opening_message(first_question: str = None, round_index: int = 1) -> str:
    """
    è·å–é¢è¯•å¼€åœºç™½ï¼ˆå¯¹å¤–æ¥å£ï¼Œå…¼å®¹ç°æœ‰è°ƒç”¨ï¼‰
    
    Args:
        first_question: ç¬¬ä¸€ä¸ªé—®é¢˜çš„å†…å®¹
        round_index: å½“å‰è½®æ¬¡ï¼ˆç”¨äºç”Ÿæˆä¸åŒçš„å¼€åœºç™½ï¼‰
    """
    return _get_opening_message(first_question, round_index)


async def generate_greeting_audio(text: str, api_config: Dict[str, Any]) -> tuple[Optional[str], str]:
    """
    ä½¿ç”¨ Omni ç”Ÿæˆå¼€åœºç™½çš„éŸ³é¢‘ï¼ˆå¯¹å¤–æ¥å£ï¼Œå…¼å®¹ç°æœ‰è°ƒç”¨ï¼‰
    
    Args:
        text: å¼€åœºç™½æ–‡æœ¬
        api_config: API é…ç½®
        
    Returns:
        å…ƒç»„ (éŸ³é¢‘ Base64 å­—ç¬¦ä¸², TTS ç”Ÿæˆçš„æ–‡æœ¬)
    """
    try:
        client = _get_omni_client(api_config)
        
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³åˆæˆç³»ç»Ÿã€‚ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æä¾›çš„æ–‡å­—è½¬æ¢æˆè¯­éŸ³ã€‚è¯·åŸå°ä¸åŠ¨åœ°æœ—è¯»ç”¨æˆ·è¾“å…¥çš„æ–‡å­—ï¼Œä¸è¦æ·»åŠ ã€åˆ é™¤æˆ–ä¿®æ”¹ä»»ä½•å†…å®¹ï¼Œä¸è¦è¿›è¡Œå›å¤æˆ–å¯¹è¯ï¼Œåªéœ€è¦æœ—è¯»ã€‚"
            },
            {
                "role": "user",
                "content": f"è¯·æœ—è¯»ä»¥ä¸‹å†…å®¹ï¼š\n\n{text}"
            }
        ]
        
        # ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯
        completion = await client.chat.completions.create(
            model="qwen3-omni-flash-2025-12-01",
            messages=messages,
            modalities=["text", "audio"],
            audio={"voice": "", "format": "wav"},
            stream=True,
            stream_options={"include_usage": True},
        )
        
        audio_chunks = []
        text_chunks = []
        
        async for chunk in completion:
            if chunk.choices:
                delta = chunk.choices[0].delta
                if hasattr(delta, 'content') and delta.content:
                    text_chunks.append(delta.content)
                if hasattr(delta, 'audio') and delta.audio:
                    audio_data = None
                    if isinstance(delta.audio, dict):
                        audio_data = delta.audio.get("data")
                    elif hasattr(delta.audio, 'data'):
                        audio_data = delta.audio.data
                    if audio_data:
                        audio_chunks.append(audio_data)
        
        generated_text = "".join(text_chunks)
        
        if not audio_chunks:
            return None, generated_text or text
        
        combined_base64 = "".join(audio_chunks)
        try:
            pcm_data = base64.b64decode(combined_base64)
            wav_data = pcm_to_wav(pcm_data)
            result = base64.b64encode(wav_data).decode('utf-8')
            return result, generated_text or text
        except Exception as conv_err:
            logger.warning(f"[Voice] PCM è½¬ WAV å¤±è´¥: {conv_err}")
            return combined_base64, generated_text or text
             
    except Exception as e:
        logger.error(f"[Voice] ç”Ÿæˆå¼€åœºç™½éŸ³é¢‘å¤±è´¥: {e}")
        return None, text


async def process_voice_chat(
    session_id: str,
    system_prompt: str,
    history: List[Dict[str, Any]],
    audio_base64: Optional[str],
    text_message: Optional[str],
    api_config: Dict[str, Any],
    is_greeting: bool = False,
    audio_id: Optional[str] = None
) -> AsyncGenerator[str, None]:
    """
    å¤„ç†è¯­éŸ³å¯¹è¯è¯·æ±‚ï¼ˆå¯¹å¤–æ¥å£ï¼Œå…¼å®¹ç°æœ‰è°ƒç”¨ï¼‰
    
    å†…éƒ¨ä½¿ç”¨è·¯ç”±é€»è¾‘åˆ†å‘åˆ°å¯¹åº”çš„èŠ‚ç‚¹å‡½æ•°
    
    Args:
        session_id: ä¼šè¯ ID
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        history: å†å²æ¶ˆæ¯
        audio_base64: ç”¨æˆ·éŸ³é¢‘ (base64)
        text_message: ç”¨æˆ·æ–‡æœ¬æ¶ˆæ¯
        api_config: API é…ç½®
        is_greeting: æ˜¯å¦ä¸ºå¼€åœºç™½æ¨¡å¼
        audio_id: æµè§ˆå™¨ç«¯éŸ³é¢‘ ID
        
    Yields:
        SSE æ ¼å¼çš„äº‹ä»¶æ•°æ®
    """
    # æ„å»ºçŠ¶æ€
    state: VoiceInterviewState = {
        "session_id": session_id,
        "api_config": api_config,
        "interview_plan": [],  # åœ¨è¿™ä¸ªå…¥å£ä¸ä½¿ç”¨
        "system_prompt": system_prompt,
        "history": history or [],
        "current_phase": "greeting" if is_greeting else "conversation",
        "audio_base64": audio_base64,
        "text_message": text_message,
        "audio_id": audio_id
    }
    
    # å…¼å®¹å¤„ç†ï¼šä»…åœ¨ç¡®å®šä¸ºå¯åŠ¨é˜¶æ®µä¸”æ— å†å²è®°å½•æ—¶ï¼Œè‡ªåŠ¨è¯†åˆ«å¼€åœºç™½æ¨¡å¼
    if not is_greeting:
        # å¦‚æœæ—¢æ²¡æœ‰å†å²è®°å½•ï¼Œä¹Ÿæ²¡æœ‰è¯­éŸ³è¾“å…¥ï¼Œä½†æœ‰æ–‡æœ¬è¾“å…¥ï¼ˆé€šå¸¸æ˜¯é¦–å›åˆçš„ greetingTextï¼‰
        if not history and not audio_base64 and text_message:
            logger.info("[Voice] è‡ªåŠ¨è¯†åˆ«ä¸ºé¦–å›åˆå¼€åœºç™½æ¨¡å¼ (TTS)")
            state["current_phase"] = "greeting"
            is_greeting = True
    
    logger.info(f"[Voice] process_voice_chat: session={session_id}, phase={state['current_phase']}, is_greeting={is_greeting}")
    
    # è·¯ç”±åˆ°å¯¹åº”èŠ‚ç‚¹
    node_name = route_voice_entry(state)
    logger.info(f"[Voice] è·¯ç”±ç»“æœ: {node_name}")
    
    if node_name == "greeting" or is_greeting:
        async for event in node_greeting(state):
            yield event
    elif node_name == "summary":
        async for event in node_summary(state):
            yield event
    else:
        async for event in node_responder(state):
            yield event
