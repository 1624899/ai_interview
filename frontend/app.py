# -*- coding: utf-8 -*-
"""
AI é¢è¯•åŠ©æ‰‹å‰ç«¯åº”ç”¨
åŸºäº Chainlit æ¡†æ¶æ„å»ºçš„äº¤äº’å¼é¢è¯•ç³»ç»Ÿï¼Œæ”¯æŒæ¨¡æ‹Ÿé¢è¯•å’Œè¾…å¯¼ä¸¤ç§æ¨¡å¼
"""

import sys
import os
import chainlit as cl
from langchain_core.messages import HumanMessage

# ä¿®å¤æ¨¡å—å¯¼å…¥è·¯å¾„
# è·å–å½“å‰æ–‡ä»¶ (frontend/app.py) çš„ç»å¯¹è·¯å¾„
current_file_path = os.path.abspath(__file__)
# è·å– frontend ç›®å½•è·¯å¾„
frontend_dir = os.path.dirname(current_file_path)
# è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ (å³ frontend çš„ä¸Šä¸€çº§)
project_root = os.path.dirname(frontend_dir)

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° sys.path
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å°è¯•å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥æ‰“å°è°ƒè¯•ä¿¡æ¯
try:
    from app.services.file_service import file_service
    from app.core.graph import build_mock_interview_graph, build_coach_interview_graph
except ImportError as e:
    print(f"å¯¼å…¥å¤±è´¥: {e}")
    print(f"å½“å‰ sys.path: {sys.path}")
    print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    raise e

@cl.on_chat_start
async def start():
    """
    èŠå¤©å¼€å§‹æ—¶çš„åˆå§‹åŒ–æµç¨‹
    """
    # 1. å‘é€æ¬¢è¿æ¶ˆæ¯
    await cl.Message(content="ğŸ‘‹ æ¬¢è¿æ¥åˆ° AI é¢è¯•åŠ©æ‰‹ï¼æˆ‘æ˜¯æ‚¨çš„é¢è¯•å®˜ã€‚\n\nåœ¨å¼€å§‹ä¹‹å‰ï¼Œæˆ‘éœ€è¦äº†è§£ä¸€äº›ä¿¡æ¯ã€‚").send()

    # 2. è·å–ç®€å†ï¼ˆé€‰æ‹©å·²æœ‰ç®€å†æˆ–ä¸Šä¼ æ–°ç®€å†ï¼‰
    resume_text = await get_resume_text()
    if not resume_text:
        return  # ç»ˆæ­¢æµç¨‹

    # 3. è¯·æ±‚å²—ä½æè¿° (JD)
    res = await cl.AskUserMessage(content="è¯·è¾“å…¥æ‚¨è¦é¢è¯•çš„å²—ä½æè¿° (JD):", timeout=180).send()
    if res:
        jd_text = res["output"]
        cl.user_session.set("jd_text", jd_text)
    
    # 4. é€‰æ‹©é¢è¯•æ¨¡å¼
    actions = [
        cl.Action(name="mock", value="mock", label="æ¨¡æ‹Ÿé¢è¯• (Mock Interview)", payload={"value": "mock"}),
        cl.Action(name="coach", value="coach", label="è¾…å¯¼æ¨¡å¼ (Coaching Mode)", payload={"value": "coach"}),
    ]
    res = await cl.AskActionMessage(
        content="è¯·é€‰æ‹©é¢è¯•æ¨¡å¼ï¼š",
        actions=actions,
    ).send()
    
    # Chainlit çš„ AskActionMessage è¿”å›çš„æ˜¯ Action çš„ name
    mode = res.get("name") or res.get("value", "coach")  # å…œåº•é»˜è®¤ä¸º coach
    print(f"[DEBUG] Selected mode: {mode}, res: {res}")
    cl.user_session.set("mode", mode)
    await cl.Message(content=f"å·²é€‰æ‹©æ¨¡å¼: {'æ¨¡æ‹Ÿé¢è¯•' if mode == 'mock' else 'è¾…å¯¼æ¨¡å¼'}").send()

    # 5. æ ¹æ®æ¨¡å¼åˆå§‹åŒ–å¯¹åº”çš„é¢è¯•å›¾è°±
    if mode == "mock":
        graph = build_mock_interview_graph()
        print(f"[DEBUG] Built Mock Interview Graph")
    else:
        graph = build_coach_interview_graph()
        print(f"[DEBUG] Built Coach Interview Graph")
    cl.user_session.set("graph", graph)

    # åˆå§‹åŒ–çŠ¶æ€
    initial_state = {
        "messages": [],
        "resume_context": resume_text,
        "job_description": jd_text,
        "mode": mode,
        "question_count": 0,
        "max_questions": 3 
    }
    print(f"[DEBUG] initial_state mode: {initial_state['mode']}")
    cl.user_session.set("state", initial_state)

    # 6. å¼€å§‹é¢è¯• (è§¦å‘ç¬¬ä¸€ä¸ªé—®é¢˜)
    await cl.Message(content="ğŸš€ é¢è¯•å¼€å§‹ï¼æ­£åœ¨ç”Ÿæˆç¬¬ä¸€ä¸ªé—®é¢˜...").send()

    # è¿è¡Œå›¾è°± (æµå¼)
    inputs = initial_state
    print(f"[DEBUG] Starting interview with mode: {inputs['mode']}")

    # æ˜¾ç¤ºæ€è€ƒä¸­
    msg = cl.Message(content="")
    await msg.send()

    final_state = None

    # ä½¿ç”¨ astream_events è·å–æµå¼äº‹ä»¶
    # æ·»åŠ å¿…è¦çš„é…ç½®å‚æ•°ä»¥æ»¡è¶³ Checkpointer è¦æ±‚
    # ä½¿ç”¨ä¼šè¯IDä½œä¸ºthread_idä»¥ç¡®ä¿å”¯ä¸€æ€§
    import uuid
    thread_id = str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}
    cl.user_session.set("thread_id", thread_id)  # ä¿å­˜thread_idä¾›åç»­ä½¿ç”¨
    async for event in graph.astream_events(inputs, config=config, version="v1"):
        kind = event["event"]
        
        # ç›‘å¬ LLM çš„æµå¼è¾“å‡º
        if kind == "on_chat_model_stream":
            content = event["data"]["chunk"].content
            if content:
                await msg.stream_token(content)
        
        # ç›‘å¬å›¾è°±ç»“æŸäº‹ä»¶ï¼Œè·å–æœ€ç»ˆçŠ¶æ€ï¼ˆåªä¿å­˜åŒ…å«æœ‰æ•ˆ messages çš„çŠ¶æ€ï¼‰
        elif kind == "on_chain_end":
            output = event["data"].get("output")
            if output and isinstance(output, dict):
                # åªæœ‰å½“ output åŒ…å« messages ä¸”ä¸ä¸ºç©ºæ—¶æ‰æ›´æ–°
                if "messages" in output and len(output.get("messages", [])) > 0:
                    final_state = output
                    print(f"[DEBUG start] Captured valid state with keys: {final_state.keys()}")
                    print(f"[DEBUG start] Messages count: {len(final_state.get('messages', []))}")
                else:
                    print(f"[DEBUG start] Skipping state with keys: {output.keys()} (no valid messages)")
            
            # æµå¼è¾“å‡ºç»“æŸåï¼Œæ›´æ–°æ¶ˆæ¯çŠ¶æ€ä»¥é€šçŸ¥å‰ç«¯è¾“å‡ºå·²å®Œæˆ
            await msg.update()
        
            # æ›´æ–°çŠ¶æ€
    print(f"[DEBUG start] final_state is None: {final_state is None}")
    if final_state:
        # æ‰‹åŠ¨ç»´æŠ¤å®Œæ•´çš„æ¶ˆæ¯å†å²
        # final_state["messages"] å¯èƒ½åªåŒ…å« AI çš„å›å¤ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨åˆå¹¶
        current_state = cl.user_session.get("state") or initial_state
        new_state = current_state.copy()
        
        # æ›´æ–°é-messages å­—æ®µ
        for key in final_state:
            if key != "messages":
                new_state[key] = final_state[key]
        
        # æ‰‹åŠ¨åˆå¹¶ messagesï¼šåˆå§‹ messages + AI å›å¤
        if "messages" in final_state and len(final_state["messages"]) > 0:
            # åˆå§‹çŠ¶æ€çš„ messages å·²ç»ä¼ ç»™äº† graphï¼Œç°åœ¨åªéœ€è¦æ·»åŠ  AI çš„å›å¤
            ai_response = final_state["messages"][-1]  # å–æœ€åä¸€æ¡ï¼ˆAI å›å¤ï¼‰
            new_state["messages"] = inputs["messages"] + [ai_response]
        else:
            new_state["messages"] = inputs["messages"]
        
        print(f"[DEBUG start] Final merged messages count: {len(new_state.get('messages', []))}")
        cl.user_session.set("state", new_state)
    else:
        # æœªèƒ½è·å–çŠ¶æ€ï¼Œä½¿ç”¨ initial_state ä½œä¸ºå…œåº•
        print("[WARNING start] final_state is None, using initial_state")
        cl.user_session.set("state", initial_state)

@cl.on_message
async def main(message: cl.Message):
    """
    å¤„ç†ç”¨æˆ·å›å¤
    """
    graph = cl.user_session.get("graph")
    state = cl.user_session.get("state")
    
    if not graph or not state:
        await cl.Message(content="âš ï¸ ä¼šè¯å·²è¿‡æœŸï¼Œè¯·åˆ·æ–°é¡µé¢é‡æ–°å¼€å§‹ã€‚").send()
        return

    # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°çŠ¶æ€ä¸­
    user_msg = HumanMessage(content=message.content)
    
    # è·å–å½“å‰æ¶ˆæ¯å†å²
    current_messages = state.get("messages", [])
    print(f"[DEBUG main] Current messages count before adding user msg: {len(current_messages)}")
    
    inputs = {
        "messages": current_messages + [user_msg],
        "resume_context": state.get("resume_context", ""),
        "job_description": state.get("job_description", ""),
        "mode": state.get("mode", "coach"),
        "question_count": state.get("question_count", 0),
        "max_questions": state.get("max_questions", 3)
    }
    print(f"[DEBUG main] Inputs messages count: {len(inputs['messages'])}")

    # æ˜¾ç¤ºæ€è€ƒä¸­
    msg = cl.Message(content="")
    await msg.send()

    final_state = None

    # è¿è¡Œå›¾è°± (æµå¼)
    # æ·»åŠ å¿…è¦çš„é…ç½®å‚æ•°ä»¥æ»¡è¶³ Checkpointer è¦æ±‚
    # ä½¿ç”¨ä¹‹å‰ä¿å­˜çš„thread_id
    thread_id = cl.user_session.get("thread_id")
    if not thread_id:
        import uuid
        thread_id = str(uuid.uuid4())
        cl.user_session.set("thread_id", thread_id)
    config = {"configurable": {"thread_id": thread_id}}
    async for event in graph.astream_events(inputs, config=config, version="v1"):
        kind = event["event"]
        
        # ç›‘å¬ LLM çš„æµå¼è¾“å‡º
        if kind == "on_chat_model_stream":
            content = event["data"]["chunk"].content
            if content:
                await msg.stream_token(content)
        
        # ç›‘å¬å›¾è°±ç»“æŸäº‹ä»¶ï¼Œè·å–æœ€ç»ˆçŠ¶æ€ï¼ˆåªä¿å­˜åŒ…å«æœ‰æ•ˆ messages çš„çŠ¶æ€ï¼‰
        elif kind == "on_chain_end":
            output = event["data"].get("output")
            if output and isinstance(output, dict):
                # åªæœ‰å½“ output åŒ…å« messages ä¸”ä¸ä¸ºç©ºæ—¶æ‰æ›´æ–°
                if "messages" in output and len(output.get("messages", [])) > 0:
                    final_state = output
                    print(f"[DEBUG main] Captured valid state with keys: {final_state.keys()}")
                    print(f"[DEBUG main] Messages count: {len(final_state.get('messages', []))}")
                else:
                    print(f"[DEBUG main] Skipping state with keys: {output.keys()} (no valid messages)")
    
    # æµå¼è¾“å‡ºç»“æŸåï¼Œæ›´æ–°æ¶ˆæ¯çŠ¶æ€ä»¥é€šçŸ¥å‰ç«¯è¾“å‡ºå·²å®Œæˆ
    await msg.update()

    print(f"[DEBUG main] final_state is None: {final_state is None}")
    
    # æ›´æ–° session çŠ¶æ€
    if final_state:
        # æ‰‹åŠ¨ç»´æŠ¤å®Œæ•´çš„æ¶ˆæ¯å†å²
        new_state = state.copy()
        
        # æ›´æ–°é-messages å­—æ®µ
        for key in final_state:
            if key != "messages":
                new_state[key] = final_state[key]
        
        # æ‰‹åŠ¨åˆå¹¶ messagesï¼šinputs messages + AI å›å¤
        if "messages" in final_state and len(final_state["messages"]) > 0:
            ai_response = final_state["messages"][-1]  # å–æœ€åä¸€æ¡
            new_state["messages"] = inputs["messages"] + [ai_response]
        else:
            new_state["messages"] = inputs["messages"]
        
        print(f"[DEBUG main] Final merged messages count: {len(new_state.get('messages', []))}")
        cl.user_session.set("state", new_state)
        
        # ç”¨äºåç»­åˆ¤æ–­
        final_state_full = new_state
    else:
        print("[WARNING main] final_state is None, keeping old state")
        final_state_full = state

    # æ£€æŸ¥æ˜¯å¦ç»“æŸ
    if final_state_full and final_state_full.get("question_count", 0) >= final_state_full.get("max_questions", 5):
        pass


async def get_resume_text() -> str:
    """
    è·å–ç®€å†æ–‡æœ¬å†…å®¹ï¼Œæ”¯æŒé€‰æ‹©å·²æœ‰ç®€å†æˆ–ä¸Šä¼ æ–°ç®€å†
    
    Returns:
        str: ç®€å†æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    # è·å–å·²ä¿å­˜çš„ç®€å†åˆ—è¡¨
    try:
        resume_list = file_service.get_resume_list()
    except Exception as e:
        print(f"è·å–ç®€å†åˆ—è¡¨å¤±è´¥: {str(e)}")
        resume_list = []
    
    # å¦‚æœæœ‰å·²ä¿å­˜çš„ç®€å†ï¼Œæä¾›é€‰æ‹©é€‰é¡¹
    if resume_list:
        # åˆ›å»ºé€‰æ‹©å·²æœ‰ç®€å†å’Œä¸Šä¼ æ–°ç®€å†çš„é€‰é¡¹
        actions = [
            cl.Action(name="upload_new", value="upload_new", label="ä¸Šä¼ æ–°ç®€å†", payload={"value": "upload_new"}),
        ]
        
        # ä¸ºæ¯ä¸ªå·²ä¿å­˜çš„ç®€å†åˆ›å»ºé€‰æ‹©æŒ‰é’®
        for resume in resume_list:
            # æ ¼å¼åŒ–æ˜¾ç¤ºä¿¡æ¯
            display_name = resume.get("original_name", resume.get("stored_name", "æœªçŸ¥æ–‡ä»¶"))
            upload_time = resume.get("upload_time", "æœªçŸ¥æ—¶é—´")
            use_count = resume.get("use_count", 0)
            stored_name = resume.get('stored_name')
            
            # åˆ›å»ºå‹å¥½çš„æ˜¾ç¤ºåç§°
            label = f"{display_name} (ä¸Šä¼ æ—¶é—´: {upload_time}, ä½¿ç”¨æ¬¡æ•°: {use_count})"
            
            actions.append(
                cl.Action(
                    name=stored_name,
                    value=stored_name,
                    label=label,
                    payload={"value": stored_name}
                )
            )
        
        # è¯¢é—®ç”¨æˆ·é€‰æ‹©
        res = await cl.AskActionMessage(
            content="è¯·é€‰æ‹©ç®€å†æ“ä½œï¼š",
            actions=actions,
        ).send()
        
        # Chainlit çš„ AskActionMessage è¿”å›çš„æ˜¯ Action çš„ name æˆ– value
        selected_value = res.get("name") or res.get("value") if res else None
        print(f"[DEBUG] Selected resume: {selected_value}, res: {res}")
        
        # å¦‚æœé€‰æ‹©ä¸Šä¼ æ–°ç®€å†
        if selected_value == "upload_new":
            return await upload_new_resume()
        
        # å¦‚æœé€‰æ‹©å·²æœ‰ç®€å†
        elif selected_value and selected_value != "upload_new":
            return await load_existing_resume(selected_value)
        
        else:
            await cl.Message(content="âŒ æœªé€‰æ‹©ç®€å†ï¼Œè¯·é‡æ–°å¼€å§‹ã€‚").send()
            return None
    
    # å¦‚æœæ²¡æœ‰å·²ä¿å­˜çš„ç®€å†ï¼Œç›´æ¥ä¸Šä¼ æ–°ç®€å†
    else:
        return await upload_new_resume()


async def upload_new_resume() -> str:
    """
    ä¸Šä¼ æ–°ç®€å†å¹¶å¤„ç†
    
    Returns:
        str: ç®€å†æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    files = None
    while files is None:
        files = await cl.AskFileMessage(
            content="è¯·ä¸Šä¼ æ‚¨çš„ç®€å† (æ”¯æŒ PDF, Word, TXT)",
            accept=["application/pdf", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", "text/plain", ".docx"],
            max_size_mb=10,
            timeout=180,
        ).send()

    file = files[0]
    # æ˜¾ç¤ºå¤„ç†ä¸­çŠ¶æ€
    msg = cl.Message(content=f"æ­£åœ¨å¤„ç†ç®€å†: {file.name}...")
    await msg.send()

    # ä¿å­˜å¹¶è§£æç®€å†
    try:
        # ä½¿ç”¨ file_service çš„ Chainlit é€‚é…æ–¹æ³•
        resume_text = file_service.process_chainlit_file(file)
        # å­˜å…¥ session
        cl.user_session.set("resume_text", resume_text)
        msg.content = f"âœ… ç®€å†å¤„ç†æˆåŠŸï¼(æå–äº† {len(resume_text)} ä¸ªå­—ç¬¦)"
        await msg.update()
        return resume_text
    except Exception as e:
        msg.content = f"âŒ ç®€å†å¤„ç†å¤±è´¥: {str(e)}\n\nè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•é‡æ–°ä¸Šä¼ ã€‚"
        await msg.update()
        return None


async def load_existing_resume(stored_name: str) -> str:
    """
    åŠ è½½å·²å­˜åœ¨çš„ç®€å†
    
    Args:
        stored_name: å­˜å‚¨çš„æ–‡ä»¶å
        
    Returns:
        str: ç®€å†æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœå¤±è´¥è¿”å›None
    """
    try:
        # è·å–ç®€å†ä¿¡æ¯
        resume_info = file_service.get_resume_by_filename(stored_name)
        
        # æ˜¾ç¤ºå¤„ç†ä¸­çŠ¶æ€
        msg = cl.Message(content=f"æ­£åœ¨åŠ è½½ç®€å†: {resume_info.get('original_name', stored_name)}...")
        await msg.send()
        
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        file_path = os.path.join(file_service.upload_dir, stored_name)
        
        # æå–æ–‡æœ¬å†…å®¹
        resume_text = file_service.extract_text(file_path)
        
        # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
        file_service.update_usage_stats(stored_name)
        
        # å­˜å…¥ session
        cl.user_session.set("resume_text", resume_text)
        
        # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
        use_count = resume_info.get("use_count", 0) + 1
        msg.content = f"âœ… ç®€å†åŠ è½½æˆåŠŸï¼(æå–äº† {len(resume_text)} ä¸ªå­—ç¬¦)\nğŸ“Š è¿™æ˜¯ç¬¬ {use_count} æ¬¡ä½¿ç”¨æ­¤ç®€å†"
        await msg.update()
        
        return resume_text
        
    except FileNotFoundError:
        await cl.Message(content=f"âŒ æœªæ‰¾åˆ°ç®€å†æ–‡ä»¶: {stored_name}\n\nå¯èƒ½æ–‡ä»¶å·²è¢«åˆ é™¤ï¼Œè¯·å°è¯•ä¸Šä¼ æ–°ç®€å†ã€‚").send()
        return None
    except Exception as e:
        await cl.Message(content=f"âŒ ç®€å†åŠ è½½å¤±è´¥: {str(e)}\n\nè¯·å°è¯•é‡æ–°ä¸Šä¼ ç®€å†ã€‚").send()
        return None