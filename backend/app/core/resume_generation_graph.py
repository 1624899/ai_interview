"""
ç®€å†ç”Ÿæˆ Graph - äº¤äº’å¼ç®€å†ç”Ÿæˆä¸åŒ…è£…
æµç¨‹: éœ€æ±‚åˆ†æ -> (å¯é€‰é—®è¯¢) -> åˆç¨¿ç”Ÿæˆ -> åˆç¨¿ä¼˜åŒ– -> åŒ…è£…é€‚åº¦æ€§æ ¸æŸ¥ -> æ¶¦è‰²å®¡æŸ¥ -> (å¾ªç¯ä¼˜åŒ–) -> è¾“å‡º
"""

import json
import logging
import asyncio
import uuid
from typing import List, Optional, Dict, Any, TypedDict
from langchain_core.messages import HumanMessage

from app.core import llms
from app.database.resume_generation_service import session_store, get_generation_service

logger = logging.getLogger(__name__)


# ============================================================================
# çŠ¶æ€å®šä¹‰
# ============================================================================

class ResumeGenerationState(TypedDict):
    """ç®€å†ç”ŸæˆçŠ¶æ€"""
    # è¾“å…¥
    resume_content: str
    job_description: str
    optimization_result: dict
    template_style: str
    api_config: Optional[dict]
    user_id: str
    
    # ä¸­é—´çŠ¶æ€
    missing_info_analysis: Optional[dict]
    questions: List[str]
    user_answers: Dict[str, str]
    draft_content: str
    optimized_draft: str  # æ–°å¢ï¼šä¼˜åŒ–åçš„åˆç¨¿
    optimization_notes: Optional[dict]  # æ–°å¢ï¼šä¼˜åŒ–è¯´æ˜
    fact_check_result: Optional[dict]
    review_result: Optional[dict]
    iteration_count: int
    
    # è¾“å‡º
    final_markdown: str
    title: str


# ============================================================================
# èŠ‚ç‚¹å®ç°
# ============================================================================

async def node_analyze_needs(state: ResumeGenerationState) -> dict:
    """
    éœ€æ±‚åˆ†æèŠ‚ç‚¹ï¼šåˆ†æä¼˜åŒ–ç»“æœï¼Œè¯†åˆ«éœ€è¦ç”¨æˆ·ç¡®è®¤çš„ä¿¡æ¯
    """
    resume_content = state.get("resume_content", "")
    job_description = state.get("job_description", "")
    optimization_result = state.get("optimization_result", {})
    api_config = state.get("api_config")
    
    prompt = f"""ä½ æ˜¯ä¸€ä½ã€Œç®€å†ä¿¡æ¯æ ¸æŸ¥ä¸“å®¶ã€ã€‚è¯·åˆ†æä»¥ä¸‹ä¿¡æ¯ï¼Œæ‰¾å‡ºç”Ÿæˆå®Œæ•´ç®€å†å‰éœ€è¦ç”¨æˆ·ç¡®è®¤æˆ–è¡¥å……çš„å…³é”®ä¿¡æ¯ã€‚

ã€åŸå§‹ç®€å†ã€‘ï¼š
{resume_content}

ã€ç›®æ ‡èŒä½ã€‘ï¼š
{job_description}

ã€ä¼˜åŒ–å»ºè®®è¦ç‚¹ã€‘ï¼š
{json.dumps(optimization_result.get('key_improvements', [])[:5], ensure_ascii=False)}

è¯·æ£€æŸ¥ä»¥ä¸‹æ–¹é¢æ˜¯å¦æœ‰ç¼ºå¤±æˆ–éœ€è¦ç¡®è®¤ï¼š
1. é‡åŒ–æ•°æ®ï¼ˆå¦‚ä¸šç»©æ•°å­—ã€ç”¨æˆ·è§„æ¨¡ã€æå‡æ¯”ä¾‹ï¼‰- ä»…åœ¨åŸæ–‡æåˆ°ä½†æœªç»™å‡ºå…·ä½“æ•°å­—æ—¶è¯¢é—®
2. å…·ä½“æŠ€æœ¯æ ˆæˆ–å·¥å…· - ä»…åœ¨JDè¦æ±‚ä½†ç®€å†æœªæ˜ç¡®æåŠä¸”å¯èƒ½å…·å¤‡æ—¶è¯¢é—®
3. é¡¹ç›®ä¸­çš„ä¸ªäººè´¡çŒ®å’Œè§’è‰² - ä»…åœ¨æè¿°æ¨¡ç³Šæ—¶è¯¢é—®
4. ä¸ç›®æ ‡å²—ä½é«˜åº¦ç›¸å…³çš„é¡¹ç›®ç»å† - ä»…åœ¨é¡¹ç›®ç»å†æè¿°æ¨¡ç³Šæ—¶è¯¢é—®

è¯·è¾“å‡º JSON æ ¼å¼ï¼ˆä¸è¦ä½¿ç”¨ markdown ä»£ç å—ï¼‰ï¼š
{{
    "has_gaps": true/false,
    "questions": [
        "æ‚¨åœ¨é¡¹ç›®Aä¸­å¸¦æ¥çš„ç”¨æˆ·å¢é•¿å¤§çº¦æ˜¯å¤šå°‘ï¼Ÿï¼ˆå¦‚ï¼šå¢é•¿50%ï¼‰",
        ...
    ]
}}

**é‡è¦æç¤º**ï¼š

**ä»€ä¹ˆæ—¶å€™åº”è¯¥æé—®ï¼ˆhas_gaps: trueï¼‰**ï¼š
- åŸç®€å†ä¸­æ˜ç¡®æåˆ°äº†æŸé¡¹æˆæœä½†ç¼ºå°‘å…·ä½“æ•°å­—ï¼ˆå¦‚"ç”¨æˆ·å¢é•¿æ˜æ˜¾"ä½†æ²¡è¯´å¤šå°‘ï¼‰
- JD ä¸­æœ‰æ˜ç¡®çš„ç¡¬æ€§è¦æ±‚ï¼Œä½†ç®€å†ä¸­å®Œå…¨æ²¡æåŠï¼ˆéœ€ç¡®è®¤æ˜¯å¦å…·å¤‡ï¼‰
- å…³é”®é¡¹ç›®çš„ä¸ªäººè§’è‰²/è´¡çŒ®æè¿°éå¸¸æ¨¡ç³Šï¼Œæ— æ³•åˆ¤æ–­

**ä»€ä¹ˆæ—¶å€™ä¸åº”è¯¥æé—®ï¼ˆhas_gaps: falseï¼‰**ï¼š
- ä¿¡æ¯å·²ç»è¶³å¤Ÿç”Ÿæˆä¸€ä»½å®Œæ•´çš„ç®€å†
- ç¼ºå¤±çš„ä¿¡æ¯å¯ä»¥é€šè¿‡åˆç†æ¨æ–­æˆ–é€‚åº¦åŒ…è£…æ¥å¼¥è¡¥
- é—®é¢˜å¤ªçç¢æˆ–å¯¹ç®€å†è´¨é‡å½±å“ä¸å¤§

**æé—®åŸåˆ™**ï¼š
- æœ€å¤šåªé—® 1-3 ä¸ªæœ€å…³é”®çš„é—®é¢˜
- é—®é¢˜å¿…é¡»å…·ä½“ã€å®¹æ˜“å›ç­”ï¼ˆç»™å‡ºç¤ºä¾‹æ ¼å¼ï¼‰
- ä¼˜å…ˆé—®èƒ½å¸¦æ¥é‡åŒ–æ•°æ®çš„é—®é¢˜
- å¯¹äºé¡¹ç›®ç»å†ç¼ºå¤±ï¼Œè¯·å¼•å¯¼ç”¨æˆ·é‡‡ç”¨ STAR æ³•åˆ™è¡¥å……ï¼ˆå¦‚ï¼šèƒŒæ™¯ã€ä»»åŠ¡ã€è¡ŒåŠ¨ã€ç»“æœï¼‰
"""
    
    llm = llms.get_llm_for_request(api_config, channel="general")
    
    try:
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        content = _clean_json_response(response.content)
        analysis = json.loads(content)
        
        questions = analysis.get("questions", [])[:3]
        has_gaps = analysis.get("has_gaps", False) and len(questions) > 0
        
        logger.info(f"éœ€æ±‚åˆ†æå®Œæˆ: has_gaps={has_gaps}, questions={len(questions)}")
        
        return {
            "missing_info_analysis": {"has_gaps": has_gaps},
            "questions": questions
        }
    except Exception as e:
        logger.error(f"éœ€æ±‚åˆ†æèŠ‚ç‚¹å¤±è´¥: {e}")
        return {
            "missing_info_analysis": {"has_gaps": False, "error": str(e)},
            "questions": []
        }


async def node_generate_draft(state: ResumeGenerationState) -> dict:
    """
    åˆç¨¿ç”ŸæˆèŠ‚ç‚¹ï¼šæ ¹æ®æ‰€æœ‰ä¿¡æ¯ç”Ÿæˆç®€å†åˆç¨¿
    å…è®¸é€‚åº¦åŒ…è£…ï¼ˆEnhancementï¼‰ï¼Œä½†ä¸èƒ½è¿›è¡Œæ¶æ„é€ å‡
    """
    resume_content = state.get("resume_content", "")
    job_description = state.get("job_description", "")
    optimization_result = state.get("optimization_result", {})
    user_answers = state.get("user_answers", {})
    review_result = state.get("review_result")
    template_style = state.get("template_style", "professional")
    api_config = state.get("api_config")
    
    # æ„å»ºç”¨æˆ·è¡¥å……ä¿¡æ¯
    user_info_section = ""
    if user_answers:
        answers_text = "\n".join([f"- {q}: {a}" for q, a in user_answers.items()])
        user_info_section = f"\n\nã€ç”¨æˆ·è¡¥å……ä¿¡æ¯ã€‘ï¼š\n{answers_text}"
    
    # å¦‚æœæœ‰å®¡æŸ¥åé¦ˆï¼ŒåŠ å…¥æ”¹è¿›æŒ‡å¯¼
    review_guidance = ""
    if review_result and not review_result.get("passed", True):
        issues = review_result.get("issues", [])
        factual_notes = [i['detail'] for i in issues if i.get('type') == 'excessive_fabrication']
        if factual_notes:
            review_guidance = f"\n\nã€é‡è¦ä¿®æ­£è¦æ±‚ã€‘ä¸Šæ¬¡ç”Ÿæˆå­˜åœ¨è¿‡åº¦åŒ…è£…æˆ–é€»è¾‘æ¼æ´ï¼Œè¯·ä¿®æ­£ï¼š\n" + "\n".join(factual_notes)
    
    style_guide = {
        "professional": "ä¸“ä¸šç®€æ´ï¼Œçªå‡ºçœŸå®æˆå°±å’Œæ•°æ®ï¼Œé€‚åˆä¼ä¸šåº”è˜",
        "academic": "å­¦æœ¯é£æ ¼ï¼Œå¼ºè°ƒç ”ç©¶æˆæœå’Œå‘è¡¨ï¼Œé€‚åˆå­¦æœ¯å²—ä½",
        "creative": "åˆ›æ„è®¾è®¡ï¼Œå¯ä»¥æœ‰ä¸ªæ€§åŒ–è¡¨è¾¾ï¼Œé€‚åˆåˆ›æ„è¡Œä¸š"
    }
    
    # æå–å…³é”®è¯åˆ†æ
    keyword_analysis = optimization_result.get('keyword_analysis', {})
    jd_keywords = keyword_analysis.get('jd_keywords', [])
    missing_keywords = keyword_analysis.get('missing', [])
    keyword_recommendations = keyword_analysis.get('recommendations', [])
    
    # æ„å»ºå…³é”®è¯æŒ‡å¯¼
    keyword_section = ""
    if jd_keywords or missing_keywords or keyword_recommendations:
        keyword_section = f"""

ã€å…³é”®è¯åˆ†æ - é‡ç‚¹æ‰§è¡Œã€‘ï¼š
- JDæ ¸å¿ƒå…³é”®è¯ï¼š{json.dumps(jd_keywords[:10], ensure_ascii=False)}
- ç®€å†ä¸­ç¼ºå¤±çš„å…³é”®è¯ï¼š{json.dumps(missing_keywords[:8], ensure_ascii=False)}
- å»ºè®®æ·»åŠ çš„å…³é”®è¯ï¼š{json.dumps(keyword_recommendations[:8], ensure_ascii=False)}

è¯·åŠ¡å¿…åœ¨ç®€å†ä¸­è‡ªç„¶åœ°èå…¥ä¸Šè¿°å…³é”®è¯ï¼Œç‰¹åˆ«æ˜¯ç¼ºå¤±çš„å…³é”®è¯ï¼
"""

    prompt = f"""ä½ æ˜¯ä¸€ä½ã€Œèµ„æ·±ç®€å†åŒ…è£…ä¸“å®¶ã€ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ï¼Œä¸ºå€™é€‰äººæ‰“é€ ä¸€ä»½**å†…å®¹ä¸°å¯Œã€å…·æœ‰ç«äº‰åŠ›**çš„ç®€å†ã€‚

**æ ¸å¿ƒåŸåˆ™**ï¼š
1. **å†…å®¹è¦ä¸°å¯Œé¥±æ»¡**ï¼šä¸è¦å†™å¾—å¤ªç®€æ´ï¼æ¯æ®µç»å†è‡³å°‘3-6ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ªè¦ç‚¹è¦æœ‰å®è´¨å†…å®¹ã€‚
2. **å…è®¸é€‚åº¦åŒ…è£…**ï¼šå°†å¹³æ·¡æè¿°å‡çº§ä¸ºä¸“ä¸šè¡¨è¾¾ï¼Œè¡¥å……åˆç†çš„ç»†èŠ‚å’Œæˆæœã€‚
3. **ä¸¥ç¦æ¶æ„é€ å‡**ï¼šä¸èƒ½ç¼–é€ ä¸å­˜åœ¨çš„å…¬å¸ã€èŒä½æˆ–å®Œå…¨ä¸å…·å¤‡çš„ç¡¬æŠ€èƒ½ã€‚

ã€åŒ…è£…æŠ€å·§ã€‘ï¼š
- è¯­è¨€å‡ç»´ï¼š"ä¿®äº†bug" â†’ "ä¿®å¤æ ¸å¿ƒæ¨¡å—å†…å­˜æ³„æ¼é—®é¢˜ï¼Œæå‡ç³»ç»Ÿç¨³å®šæ€§"
- åˆç†æ¨æ–­ï¼šå¼€å‘äº†åå° â†’ "è®¾è®¡å¹¶å®ç°ä¼ä¸šçº§åå°ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æ’‘ä¸šåŠ¡éƒ¨é—¨é«˜æ•ˆè¿è¥"
- ä¼°ç®—æ•°æ®ï¼šç”¨"çº¦"ã€"è¶…"ã€"è¿‘"ç­‰ä¿®é¥°è¯ï¼Œå¦‚"ç”¨æˆ·å¢é•¿çº¦20%"ï¼ˆå¦‚æœè¿™åœ¨è¡Œä¸šæ ‡å‡†èŒƒå›´å†…ï¼‰

---

ã€åŸå§‹ç®€å†ã€‘ï¼š
{resume_content}

{user_info_section}

ã€ç›®æ ‡èŒä½ã€‘ï¼š
{job_description}

ã€å…³é”®æ”¹è¿›ç‚¹ - é‡ç‚¹æ‰§è¡Œã€‘ï¼š
{json.dumps(optimization_result.get('key_improvements', [])[:5], ensure_ascii=False, indent=2)}

ä¸Šè¿°æ”¹è¿›ç‚¹æ˜¯ä¸“å®¶åˆ†æåç»™å‡ºçš„å»ºè®®ï¼Œè¯·åŠ¡å¿…åœ¨ç®€å†ä¸­ä½“ç°ï¼
{keyword_section}
{review_guidance}

---

ã€é£æ ¼è¦æ±‚ã€‘ï¼š{style_guide.get(template_style, style_guide['professional'])}
ã€è¯­è¨€è¦æ±‚ã€‘ï¼šå¿…é¡»ä½¿ç”¨ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰æ’°å†™ã€‚

## è¾“å‡ºç»“æ„ï¼ˆè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼Œå†…å®¹è¦ä¸°å¯Œï¼‰ï¼š

# [å§“å]
> [è”ç³»æ–¹å¼]
[æ±‚èŒæ„å‘] | [æœŸæœ›è–ªèµ„] | [æœŸæœ›åŸå¸‚]

## ä¸ªäººç®€ä»‹
ï¼ˆ3-5å¥è¯ï¼Œåˆ†ç‚¹æè¿°ï¼Œçªå‡ºæ ¸å¿ƒç«äº‰åŠ›ä¸ç›®æ ‡èŒä½çš„åŒ¹é…åº¦ï¼Œè¦æœ‰è¯´æœåŠ›ï¼Œå¯ä»¥é€‚åº¦åŒ…è£…ï¼‰

## å·¥ä½œç»å†
### [å…¬å¸åç§°] | [èŒä½] | [æ—¶é—´æ®µ]
- **å·¥ä½œèŒè´£**ï¼šè¯¦ç»†æè¿°æ ¸å¿ƒèŒè´£ï¼ˆä¸è¦ä¸€ç¬”å¸¦è¿‡ï¼‰
- **é¡¹ç›®å‚ä¸**ï¼šå‚ä¸çš„é‡è¦é¡¹ç›®åŠè§’è‰²
- **æ ¸å¿ƒæˆæœ**ï¼šä½¿ç”¨STARæ³•åˆ™ï¼Œé‡åŒ–æè¿°æˆæœ
- **æŠ€æœ¯åº”ç”¨**ï¼šä½¿ç”¨çš„æŠ€æœ¯æ ˆå’Œå·¥å…·
ï¼ˆæ¯æ®µå·¥ä½œç»å†è‡³å°‘4-6ä¸ªè¦ç‚¹ï¼Œå†…å®¹è¦é¥±æ»¡ï¼‰

## é¡¹ç›®ç»å†
### [é¡¹ç›®åç§°] | [è§’è‰²] | [æ—¶é—´æ®µ]
- **é¡¹ç›®èƒŒæ™¯**ï¼šé¡¹ç›®çš„ä¸šåŠ¡èƒŒæ™¯å’Œç›®æ ‡
- **æŠ€æœ¯æ¶æ„**ï¼šä½¿ç”¨çš„æŠ€æœ¯æ ˆ
- **ä¸ªäººèŒè´£**ï¼šå…·ä½“è´Ÿè´£çš„æ¨¡å—å’Œä»»åŠ¡
- **æ ¸å¿ƒæˆæœ**ï¼šé‡åŒ–çš„é¡¹ç›®æˆæœ
ï¼ˆæ¯ä¸ªé¡¹ç›®è‡³å°‘4ä¸ªè¦ç‚¹ï¼‰

## ä¸“ä¸šæŠ€èƒ½
### æ ¸å¿ƒæŠ€èƒ½
- **[æŠ€èƒ½ç±»åˆ«1]**ï¼šå…·ä½“æŠ€èƒ½åˆ—è¡¨ï¼Œæ ‡æ³¨ç†Ÿç»ƒç¨‹åº¦ï¼ˆç²¾é€š/ç†Ÿç»ƒ/æŒæ¡ï¼‰
- **[æŠ€èƒ½ç±»åˆ«2]**ï¼š...

### å·¥å…·ä¸æ¡†æ¶
- **å¼€å‘å·¥å…·**ï¼šIDEã€ç‰ˆæœ¬æ§åˆ¶ã€åä½œå·¥å…·ç­‰
- **æŠ€æœ¯æ¡†æ¶**ï¼šä½¿ç”¨è¿‡çš„æ¡†æ¶å’Œåº“

### è½¯æŠ€èƒ½
- é¡¹ç›®ç®¡ç†ã€å›¢é˜Ÿåä½œã€æ²Ÿé€šèƒ½åŠ›ç­‰

ï¼ˆæŠ€èƒ½æ¨¡å—è¦ä½“ç°ï¼šä¸“ä¸šæ·±åº¦ + æŠ€æœ¯å¹¿åº¦ + ä¸JDçš„åŒ¹é…åº¦ï¼‰

## æ•™è‚²èƒŒæ™¯
### [å­¦æ ¡åç§°] | [ä¸“ä¸š] | [å­¦å†] | [æ—¶é—´æ®µ]
- ç›¸å…³è¯¾ç¨‹ã€GPAã€è£èª‰å¥–é¡¹ç­‰

---

**è¾“å‡ºè§„èŒƒ**ï¼š
1. ç›´æ¥è¾“å‡º Markdown å†…å®¹ï¼Œä¸è¦ç”¨ä»£ç å—åŒ…è£¹ï¼Œç¦æ­¢ä½¿ç”¨emojiè¡¨æƒ…
2. å†…å®¹è¦ä¸°å¯Œï¼Œä¸è¦å†™å¾—å¤ªç®€æ´ï¼æ¯ä¸ªæ¨¡å—éƒ½è¦æœ‰å®è´¨å†…å®¹
3. ä¸“ä¸šæŠ€èƒ½è¦è¯¦ç»†ï¼Œä½“ç°æ·±åº¦å’Œä¸å²—ä½çš„åŒ¹é…
"""
    
    llm = llms.get_llm_for_request(api_config, channel="content_writer")
    
    try:
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        draft = response.content.strip()
        
        # æ¸…ç†å¯èƒ½çš„ä»£ç å—åŒ…è£¹
        draft = _clean_markdown_response(draft)
        
        logger.info(f"åˆç¨¿ç”Ÿæˆå®Œæˆ (å«é€‚åº¦åŒ…è£…): {len(draft)} å­—ç¬¦")
        return {"draft_content": draft}
    except Exception as e:
        logger.error(f"åˆç¨¿ç”ŸæˆèŠ‚ç‚¹å¤±è´¥: {e}")
        return {"draft_content": f"ç”Ÿæˆå¤±è´¥: {str(e)}"}


async def node_optimize_draft(state: ResumeGenerationState) -> dict:
    """
    åˆç¨¿ä¼˜åŒ–èŠ‚ç‚¹ï¼ˆæ–°å¢ï¼‰ï¼šæ£€æŸ¥ä¿¡æ¯é—æ¼å¹¶æŒ‰å¤šç»´åº¦ä¼˜åŒ–
    """
    resume_content = state.get("resume_content", "")
    draft_content = state.get("draft_content", "")
    job_description = state.get("job_description", "")
    user_answers = state.get("user_answers", {})
    api_config = state.get("api_config")
    
    user_inputs = json.dumps(user_answers, ensure_ascii=False) if user_answers else "æ— "

    # è·å–ä¼˜åŒ–å»ºè®®
    optimization_result = state.get("optimization_result", {})
    key_improvements = optimization_result.get('key_improvements', [])
    keyword_analysis = optimization_result.get('keyword_analysis', {})
    jd_keywords = keyword_analysis.get('jd_keywords', [])
    missing_keywords = keyword_analysis.get('missing', [])

    prompt = f"""ä½ æ˜¯ä¸€ä½ã€Œç®€å†è´¨é‡ä¼˜åŒ–ä¸“å®¶ã€ã€‚è¯·å¯¹æ¯”ã€åŸå§‹èµ„æ–™ã€‘å’Œã€åˆç¨¿ã€‘ï¼Œè¿›è¡Œæ·±åº¦ä¼˜åŒ–ã€‚

## è¾“å…¥ä¿¡æ¯

ã€åŸå§‹ç®€å†ã€‘ï¼š
{resume_content}

ã€ç”¨æˆ·è¡¥å……ä¿¡æ¯ã€‘ï¼š
{user_inputs}

ã€ç›®æ ‡èŒä½ã€‘ï¼š
{job_description}

ã€å½“å‰åˆç¨¿ã€‘ï¼š
{draft_content}

---

## å¿…é¡»æ‰§è¡Œçš„ä¼˜åŒ–å»ºè®®

ã€å…³é”®æ”¹è¿›ç‚¹ã€‘ï¼ˆæ¥è‡ªä¸“å®¶åˆ†æï¼Œå¿…é¡»è½å®ï¼‰ï¼š
{json.dumps(key_improvements[:5], ensure_ascii=False, indent=2)}

ã€å…³é”®è¯è¦æ±‚ã€‘ï¼š
- JDæ ¸å¿ƒå…³é”®è¯ï¼š{json.dumps(jd_keywords[:10], ensure_ascii=False)}
- ç¼ºå¤±çš„å…³é”®è¯ï¼ˆå¿…é¡»è¡¥å……ï¼‰ï¼š{json.dumps(missing_keywords[:8], ensure_ascii=False)}

---

## ä¼˜åŒ–ä»»åŠ¡

### 1. ä¿¡æ¯é—æ¼æ£€æŸ¥ï¼ˆä¸¥æ ¼æ‰§è¡Œï¼‰
å¯¹æ¯”ã€åŸå§‹ç®€å†ã€‘å’Œã€å½“å‰åˆç¨¿ã€‘ï¼š
- æ˜¯å¦æœ‰å·¥ä½œç»å†è¢«é—æ¼æˆ–è¿‡åº¦ç®€åŒ–ï¼Ÿâ†’ å¿…é¡»è¡¥å……å®Œæ•´
- æ˜¯å¦æœ‰é¡¹ç›®ç»å†è¢«é—æ¼ï¼Ÿâ†’ å¿…é¡»è¡¥å……
- æŠ€èƒ½æ¸…å•æ˜¯å¦å®Œæ•´ï¼Ÿâ†’ å¿…é¡»å±•å¼€è¯¦ç»†æè¿°
- æ•™è‚²èƒŒæ™¯æ˜¯å¦å®Œæ•´ï¼Ÿâ†’ å¿…é¡»ä¿ç•™

### 2. å†…å®¹ä¸°å¯Œåº¦æ£€æŸ¥ï¼ˆé‡ç‚¹ï¼ï¼‰
**ç®€å†ä¸èƒ½å¤ªç®€æ´ï¼** æ¯ä¸ªæ¨¡å—éƒ½è¦æœ‰è¶³å¤Ÿçš„å†…å®¹ï¼š
- æ¯æ®µå·¥ä½œç»å†ï¼šè‡³å°‘4-6ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ªè¦ç‚¹è¦æœ‰å®è´¨æè¿°
- æ¯ä¸ªé¡¹ç›®ç»å†ï¼šè‡³å°‘4ä¸ªè¦ç‚¹ï¼ˆèƒŒæ™¯ã€èŒè´£ã€æŠ€æœ¯ã€æˆæœï¼‰
- ä¸“ä¸šæŠ€èƒ½ï¼šå¿…é¡»åˆ†ç±»è¯¦ç»†å±•å¼€ï¼Œä½“ç°æ·±åº¦

### 3. ä¸“ä¸šæŠ€èƒ½æ¨¡å—ä¼˜åŒ–ï¼ˆé‡è¦ï¼‰
æŠ€èƒ½æ¨¡å—å¿…é¡»åšåˆ°ï¼š
- **åˆ†ç±»æ¸…æ™°**ï¼šæŒ‰ç±»åˆ«ç»„ç»‡ï¼ˆå¦‚ï¼šç¼–ç¨‹è¯­è¨€ã€æ¡†æ¶å·¥å…·ã€ä¸“ä¸šæŠ€èƒ½ã€è½¯æŠ€èƒ½ï¼‰
- **ä½“ç°æ·±åº¦**ï¼šæ ‡æ³¨ç†Ÿç»ƒç¨‹åº¦ï¼ˆç²¾é€š/ç†Ÿç»ƒ/æŒæ¡ï¼‰ï¼Œè¯´æ˜ä½¿ç”¨åœºæ™¯
- **åŒ¹é…JD**ï¼šçªå‡ºä¸ç›®æ ‡èŒä½åŒ¹é…çš„æŠ€èƒ½
- **ä¸èƒ½è¿‡äºç®€ç•¥**ï¼šæ¯ä¸ªç±»åˆ«è‡³å°‘3-5é¡¹å…·ä½“æŠ€èƒ½

### 4. å…³é”®è¯èå…¥
æ£€æŸ¥ã€ç¼ºå¤±çš„å…³é”®è¯ã€‘æ˜¯å¦å·²è‡ªç„¶åœ°èå…¥ç®€å†ä¸­ï¼š
- åœ¨å·¥ä½œèŒè´£ã€é¡¹ç›®æè¿°ã€æŠ€èƒ½åˆ—è¡¨ä¸­ä½“ç°
- ç¡®ä¿å…³é”®è¯è¦†ç›–ç‡è¾¾åˆ°80%ä»¥ä¸Š

### 5. é‡åŒ–ä¸æˆæœ
- æ¯æ®µç»å†æ˜¯å¦éƒ½æœ‰é‡åŒ–æˆæœï¼Ÿ
- æ•°æ®æ˜¯å¦åˆç†ï¼ˆä½¿ç”¨"çº¦"ã€"è¶…"ç­‰ä¿®é¥°è¯ï¼‰ï¼Ÿ

### 6. å…³é”®æ”¹è¿›ç‚¹è½å®æ£€æŸ¥
é€æ¡æ£€æŸ¥ã€å…³é”®æ”¹è¿›ç‚¹ã€‘æ˜¯å¦å·²åœ¨ç®€å†ä¸­ä½“ç°ï¼Œæœªä½“ç°çš„å¿…é¡»è¡¥å……ã€‚

---

## è¾“å‡ºè¦æ±‚

è¯·è¾“å‡º JSON æ ¼å¼ï¼ˆä¸è¦ä½¿ç”¨ markdown ä»£ç å—ï¼Œæ‰€æœ‰å­—ç¬¦ä¸²ä½¿ç”¨è‹±æ–‡åŒå¼•å·ï¼‰ï¼š
{{
    "optimized_content": "ä¼˜åŒ–åçš„å®Œæ•´ Markdown ç®€å†ï¼ˆå†…å®¹è¦ä¸°å¯Œé¥±æ»¡ï¼‰...",
    "optimization_summary": {{
        "missing_info_fixed": ["è¡¥å……äº†XXé¡¹ç›®ç»å†", "è¡¥å…¨äº†æŠ€èƒ½æ¸…å•..."],
        "content_enriched": ["ä¸°å¯Œäº†å·¥ä½œç»å†æè¿°", "æ‰©å±•äº†é¡¹ç›®ç»†èŠ‚..."],
        "skills_enhanced": ["æŠ€èƒ½åˆ†ç±»æ›´æ¸…æ™°", "å¢åŠ äº†XXæŠ€èƒ½æ·±åº¦æè¿°..."],
        "keywords_added": ["èå…¥äº†å…³é”®è¯XX", "è¡¥å……äº†æŠ€èƒ½å…³é”®è¯XX..."],
        "improvements_applied": ["è½å®äº†æ”¹è¿›ç‚¹1", "è½å®äº†æ”¹è¿›ç‚¹2..."]
    }},
    "quality_scores": {{
        "completeness": 85,
        "content_richness": 80,
        "skill_depth": 85,
        "keyword_coverage": 90,
        "jd_match": 82
    }}
}}

é‡è¦æé†’ï¼š
- optimized_content å¿…é¡»æ˜¯å®Œæ•´çš„ Markdown ç®€å†ï¼Œç¦æ­¢ä½¿ç”¨emojiè¡¨æƒ…
- **å†…å®¹å¿…é¡»ä¸°å¯Œ**ï¼Œä¸èƒ½æ¯”åˆç¨¿æ›´ç®€æ´
- **ä¸“ä¸šæŠ€èƒ½å¿…é¡»è¯¦ç»†å±•å¼€**ï¼Œä½“ç°ä¸“ä¸šæ·±åº¦
- **å…³é”®è¯å’Œæ”¹è¿›ç‚¹å¿…é¡»è½å®**
"""
    
    llm = llms.get_llm_for_request(api_config, channel="content_writer")
    
    try:
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        content = _clean_json_response(response.content)
        result = json.loads(content)
        
        optimized_draft = result.get("optimized_content", draft_content)
        optimized_draft = _clean_markdown_response(optimized_draft)
        
        optimization_summary = result.get("optimization_summary", {})
        quality_scores = result.get("quality_scores", {})
        
        logger.info(f"åˆç¨¿ä¼˜åŒ–å®Œæˆ: è¡¥å……äº† {len(optimization_summary.get('missing_info_fixed', []))} é¡¹é—æ¼, é•¿åº¦ {len(optimized_draft)} å­—ç¬¦, è´¨é‡è¯„åˆ† completeness={quality_scores.get('completeness', 'N/A')}")
        
        return {
            "optimized_draft": optimized_draft,
            "optimization_notes": {
                "summary": optimization_summary,
                "scores": quality_scores
            }
        }
    except Exception as e:
        logger.error(f"åˆç¨¿ä¼˜åŒ–èŠ‚ç‚¹å¤±è´¥: {e}")
        # å¤±è´¥æ—¶ä½¿ç”¨åŸåˆç¨¿
        return {
            "optimized_draft": draft_content,
            "optimization_notes": {"error": str(e)}
        }


async def node_fact_check(state: ResumeGenerationState) -> dict:
    """
    åŒ…è£…é€‚åº¦æ€§æ ¸æŸ¥èŠ‚ç‚¹ï¼šåŒºåˆ†"é€‚åº¦åŒ…è£…"å’Œ"è¿‡åº¦é€ å‡"
    """
    resume_content = state.get("resume_content", "")
    # ä½¿ç”¨ä¼˜åŒ–åçš„åˆç¨¿è¿›è¡Œæ ¸æŸ¥
    draft_content = state.get("optimized_draft", "") or state.get("draft_content", "")
    user_answers = state.get("user_answers", {})
    api_config = state.get("api_config")
    
    user_inputs = json.dumps(user_answers, ensure_ascii=False) if user_answers else "æ— "

    prompt = f"""ä½ æ˜¯ä¸€ä½ã€Œç®€å†é£æ§ä¸“å®¶ã€ã€‚è¯·å¯¹æ¯”ã€åŸå§‹èµ„æ–™ã€‘å’Œã€ç”Ÿæˆç®€å†ã€‘ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨**è¿‡åº¦åŒ…è£…æˆ–æ¶æ„é€ å‡**ã€‚

ã€åˆ¤å®šæ ‡å‡†ã€‘ï¼š
- ğŸŸ¢ **å®‰å…¨ï¼ˆé€‚åº¦åŒ…è£…ï¼‰**ï¼šè¯­è¨€æ¶¦è‰²ã€åˆç†çš„æ¨æ–­ã€åŸºäºè¡Œä¸šæ ‡å‡†ä¼°ç®—çš„æ•°æ®ã€çªæ˜¾äº®ç‚¹ã€‚ -> **æ— éœ€æŠ¥å‘Š**
- ğŸ”´ **å±é™©ï¼ˆæ¶æ„é€ å‡ï¼‰**ï¼š
    1. ç¼–é€ ä¸å­˜åœ¨çš„å…¬å¸æˆ–å·²ç¡®è®¤ä¸å­˜åœ¨çš„èŒä½ã€‚
    2. ç¼–é€ å€™é€‰äººæ˜¾ç„¶ä¸å…·å¤‡çš„æ ¸å¿ƒç¡¬æŠ€èƒ½ï¼ˆå¦‚æ–‡å‘˜ç¼–é€ ä¼šå†™æ“ä½œç³»ç»Ÿå†…æ ¸ï¼‰ã€‚
    3. æ•°æ®æåº¦å¤¸å¼ ã€è¿åå¸¸ç†ï¼ˆå¦‚å®ä¹ ç”Ÿç‹¬ç«‹å¸¦æ¥ä¸Šäº¿è¥æ”¶ï¼‰ã€‚

ã€åŸå§‹èµ„æ–™ã€‘ï¼š
{resume_content}
ç”¨æˆ·è¡¥å……: {user_inputs}

ã€ç”Ÿæˆç®€å†ã€‘ï¼š
{draft_content}

---

è¯·åªæŠ¥å‘ŠğŸ”´**å±é™©**çº§åˆ«çš„é€ å‡ã€‚å¦‚æœåªæ˜¯ğŸŸ¢é€‚åº¦åŒ…è£…ï¼ˆåŒ…æ‹¬åŸºäºç»éªŒçš„åˆç†æ¨æ–­ã€è¯­è¨€ä¸Šçš„ä¸“ä¸šåŒ–æ¶¦è‰²ï¼‰ï¼Œè¯·åŠ¡å¿…**æ”¾è¡Œ**ï¼ˆis_excessive=falseï¼‰ã€‚

**åªæœ‰åœ¨ç¡®å®å‡ºç°"æ— ä¸­ç”Ÿæœ‰"çš„æ ¸å¿ƒç¡¬æŠ€èƒ½æˆ–ç»å†æ—¶ï¼Œæ‰æ ‡è®°ä¸ºè¿‡åº¦é€ å‡ã€‚**

è¯·è¾“å‡º JSON æ ¼å¼ï¼ˆä¸è¦ä½¿ç”¨ markdown ä»£ç å—ã€emojiè¡¨æƒ…ï¼‰ï¼š
{{
    "is_excessive": true/false,  // æ˜¯å¦è¿‡åº¦é€ å‡
    "risk_details": [
        {{
            "type": "excessive_fabrication",
            "description": "æ£€æµ‹åˆ°ä¸¥é‡é€ å‡ï¼šç”Ÿæˆç®€å†ä¸­..."
        }}
    ]
}}
"""
    
    llm = llms.get_llm_for_request(api_config, channel="general")
    
    try:
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        content = _clean_json_response(response.content)
        result = json.loads(content)
        
        is_excessive = result.get("is_excessive", False)
        logger.info(f"é£æ§æ ¸æŸ¥å®Œæˆ: is_excessive={is_excessive}")
        return {"fact_check_result": result}
    except Exception as e:
        logger.error(f"é£æ§æ ¸æŸ¥èŠ‚ç‚¹å¤±è´¥: {e}")
        return {"fact_check_result": {"is_excessive": False, "risk_details": []}}


async def node_finalize_and_review(state: ResumeGenerationState) -> dict:
    """
    æ¶¦è‰²ä¸å®¡æŸ¥èŠ‚ç‚¹ï¼šåŸºäºé€‚åº¦åŒ…è£…åŸåˆ™è¿›è¡Œæœ€ç»ˆç¡®è®¤
    """
    # ä½¿ç”¨ä¼˜åŒ–åçš„åˆç¨¿
    draft_content = state.get("optimized_draft", "") or state.get("draft_content", "")
    fact_check_result = state.get("fact_check_result", {})
    optimization_result = state.get("optimization_result", {})
    api_config = state.get("api_config")
    
    # è·å– JD å…³é”®è¯
    jd_keywords = optimization_result.get("keyword_analysis", {}).get("jd_keywords", [])[:10]
    
    # æ„å»ºè­¦å‘Š
    warning = ""
    if fact_check_result.get("is_excessive"):
        details = fact_check_result.get("risk_details", [])
        warning = f"""
**é£æ§è­¦å‘Šï¼šæ£€æµ‹åˆ°è¿‡åº¦é€ å‡ï¼Œå¿…é¡»ä¿®æ­£**ï¼š
{json.dumps(details, ensure_ascii=False, indent=2)}

è¯·å¯¹ç›¸å…³å†…å®¹è¿›è¡Œ**ä¿®æ­£æˆ–å¼±åŒ–è¡¨è¿°**ï¼Œä½¿å…¶ç¬¦åˆå®¢è§‚äº‹å®ï¼Œ**ä½†ä¸è¦åˆ é™¤æ•´æ®µç»å†ï¼Œä¹Ÿä¸è¦å¤§å¹…ç¼©å‡ç®€å†ç¯‡å¹…**ã€‚
ä¿®æ­£åŸåˆ™ï¼šå°†"è¿‡äºå¤¸å¼ çš„æ•°æ®"ä¿®æ”¹ä¸º"åˆç†ä¼°ç®—çš„æ•°æ®"ï¼Œå°†"æ— ä¸­ç”Ÿæœ‰"çš„æŠ€èƒ½ä¿®æ”¹ä¸º"äº†è§£/ç†Ÿæ‚‰"æˆ–åˆ é™¤è¯¥å…·ä½“æŠ€èƒ½ç‚¹ï¼ˆä¿ç•™å…¶ä»–çœŸå®æŠ€èƒ½ï¼‰ã€‚
"""

    prompt = f"""ä½ æ˜¯ä¸€ä½ã€Œç®€å†ç»ˆå®¡ä¸“å®¶ã€ã€‚è¯·å¯¹ä»¥ä¸‹ç®€å†è¿›è¡Œæœ€ç»ˆæ¶¦è‰²ã€‚

ã€ç®€å†è‰ç¨¿ã€‘ï¼š
{draft_content}

ã€ç›®æ ‡èŒä½å…³é”®è¯ã€‘ï¼š
{json.dumps(jd_keywords, ensure_ascii=False)}

{warning}

è¯·æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š
1. **ä¿®æ­£è¿‡åº¦é€ å‡**ï¼šå¦‚æœæœ‰é£æ§è­¦å‘Šï¼Œå¿…é¡»ä¿®æ­£ã€‚
2. **æ¶¦è‰²è¯­è¨€**ï¼šè®©æªè¾æ›´åŠ ä¸“ä¸šã€è‡ªä¿¡ï¼ˆå…è®¸é€‚åº¦åŒ…è£…ï¼‰ã€‚
3. **æ ¼å¼æ£€æŸ¥**ï¼šç¡®ä¿ Markdown æ ¼å¼æ ‡å‡†ã€ç¾è§‚ã€‚
4. **é•¿åº¦ä¿æŒ**ï¼š**ä¸¥ç¦å¤§å¹…åˆ å‡å†…å®¹ï¼** ä¿®æ­£åçš„ç®€å†é•¿åº¦åº”ä¸è‰ç¨¿åŸºæœ¬ä¿æŒä¸€è‡´ï¼ˆå…è®¸+/- 10%æ³¢åŠ¨ï¼‰ã€‚å¦‚æœä¸æ¶‰åŠé€ å‡çš„éƒ¨åˆ†ï¼Œè¯·åŸæ ·ä¿ç•™æˆ–ä»…åšæ¶¦è‰²ã€‚
5. **æœ€ç»ˆæ‰“ç£¨**ï¼šç¡®ä¿ç®€å†è¯»èµ·æ¥æµç•…ã€ä¸“ä¸šã€‚

è¯·è¾“å‡º JSON æ ¼å¼ï¼š
{{
    "final_content": "æœ€ç»ˆä¿®è®¢åçš„å®Œæ•´ Markdown ç®€å†...",
    "review_passed": true/false,
    "modification_notes": ["ä¿®æ­£äº†ä¸¥é‡å¤¸å¤§çš„æ•°æ®", "ä¼˜åŒ–äº†é¡¹ç›®æè¿°..."],
    "title": "å§“å-ç›®æ ‡èŒä½"
}}
æ³¨æ„ï¼š
- optimized_content å¿…é¡»æ˜¯å®Œæ•´çš„ Markdown ç®€å†ï¼Œç¦æ­¢ä½¿ç”¨emojiè¡¨æƒ…
- å†…å®¹è¦ä¸°å¯Œï¼Œä¸è¦å†™å¾—å¤ªç®€æ´ï¼æ¯ä¸ªæ¨¡å—éƒ½è¦æœ‰å®è´¨å†…å®¹
- ä¸“ä¸šæŠ€èƒ½è¦è¯¦ç»†ï¼Œä½“ç°æ·±åº¦å’Œä¸å²—ä½çš„åŒ¹é…
- ç¦æ­¢ä½¿ç”¨emojiè¡¨æƒ…
"""
    
    llm = llms.get_llm_for_request(api_config, channel="hr_reviewer")
    
    try:
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        content = _clean_json_response(response.content)
        result = json.loads(content)
        
        final_markdown = result.get("final_content", draft_content)
        passed = result.get("review_passed", True)
        title = result.get("title", "æ–°ç®€å†")
        
        final_markdown = _clean_markdown_response(final_markdown)
        
        logger.info(f"æ¶¦è‰²å®¡æŸ¥å®Œæˆ: passed={passed}")
        
        return {
            "final_markdown": final_markdown,
            "review_result": {
                "passed": passed, 
                "issues": fact_check_result.get("risk_details", [])
            },
            "title": title
        }
    except Exception as e:
        logger.error(f"æ¶¦è‰²å®¡æŸ¥èŠ‚ç‚¹å¤±è´¥: {e}")
        return {
            "final_markdown": draft_content,
            "review_result": {"passed": True, "error": str(e)},
            "title": "æ–°ç®€å†"
        }


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def _clean_json_response(content: str) -> str:
    """æ¸…ç† LLM å“åº”ä¸­çš„ markdown æ ‡è®°"""
    content = content.strip()
    if content.startswith("```json"):
        content = content[7:]
    elif content.startswith("```"):
        content = content[3:]
    if content.endswith("```"):
        content = content[:-3]
    return content.strip()

def _clean_markdown_response(content: str) -> str:
    """æ¸…ç† Markdown å“åº”ä¸­çš„ä»£ç å—åŒ…è£¹"""
    content = content.strip()
    if content.startswith("```markdown"):
        content = content[11:]
    elif content.startswith("```"):
        content = content[3:]
    if content.endswith("```"):
        content = content[:-3]
    return content.strip()


# ============================================================================
# ä¸»æµç¨‹å‡½æ•°
# ============================================================================

async def init_generation_session(
    resume_content: str,
    job_description: str,
    optimization_result: dict,
    user_id: str,
    template_style: str = "professional",
    api_config: Optional[dict] = None
) -> Dict[str, Any]:
    """
    åˆå§‹åŒ–ç®€å†ç”Ÿæˆä¼šè¯
    """
    session_id = str(uuid.uuid4())
    
    # åˆ›å»ºå†…å­˜ä¼šè¯
    session = session_store.create(
        session_id=session_id,
        user_id=user_id,
        resume_content=resume_content,
        job_description=job_description,
        optimization_result=optimization_result,
        template_style=template_style
    )
    
    # åˆå§‹åŒ–çŠ¶æ€
    state: ResumeGenerationState = {
        "resume_content": resume_content,
        "job_description": job_description,
        "optimization_result": optimization_result,
        "template_style": template_style,
        "api_config": api_config,
        "user_id": user_id,
        "missing_info_analysis": None,
        "questions": [],
        "user_answers": {},
        "draft_content": "",
        "optimized_draft": "",
        "optimization_notes": None,
        "fact_check_result": None,
        "review_result": None,
        "iteration_count": 0,
        "final_markdown": "",
        "title": ""
    }
    
    # æ‰§è¡Œéœ€æ±‚åˆ†æ
    logger.info(f"å¼€å§‹ç”Ÿæˆä¼šè¯: {session_id}")
    analysis_result = await node_analyze_needs(state)
    state.update(analysis_result)
    
    questions = state.get("questions", [])
    has_gaps = state.get("missing_info_analysis", {}).get("has_gaps", False)
    
    if has_gaps and questions:
        # éœ€è¦ç”¨æˆ·è¾“å…¥
        session_store.update(
            session_id,
            status="awaiting_input",
            questions=questions
        )
        return {
            "session_id": session_id,
            "needs_input": True,
            "questions": questions
        }
    else:
        # ç›´æ¥ç”Ÿæˆ
        result = await _complete_generation(session_id, state, api_config)
        return {
            "session_id": session_id,
            "needs_input": False,
            "result": result
        }


async def submit_user_answers(
    session_id: str,
    answers: Dict[str, str],
    api_config: Optional[dict] = None
) -> Dict[str, Any]:
    """
    æäº¤ç”¨æˆ·å›ç­”å¹¶ç»§ç»­ç”Ÿæˆ
    """
    session = session_store.get(session_id)
    if not session:
        raise ValueError(f"ä¼šè¯ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ: {session_id}")
    
    # æ›´æ–°ä¼šè¯
    session_store.update(
        session_id,
        user_answers=answers,
        status="generating"
    )
    
    # é‡å»ºçŠ¶æ€
    state: ResumeGenerationState = {
        "resume_content": session.resume_content,
        "job_description": session.job_description,
        "optimization_result": session.optimization_result,
        "template_style": session.template_style,
        "api_config": api_config,
        "user_id": session.user_id,
        "missing_info_analysis": None,
        "questions": session.questions,
        "user_answers": answers,
        "draft_content": "",
        "optimized_draft": "",
        "optimization_notes": None,
        "fact_check_result": None,
        "review_result": None,
        "iteration_count": 0,
        "final_markdown": "",
        "title": ""
    }
    
    result = await _complete_generation(session_id, state, api_config)
    return result



async def _complete_generation(
    session_id: str,
    state: ResumeGenerationState,
    api_config: Optional[dict]
) -> Dict[str, Any]:
    """
    å®Œæˆç”Ÿæˆæµç¨‹ï¼ˆå†…éƒ¨å‡½æ•°ï¼‰
    æµç¨‹ï¼šåˆç¨¿ç”Ÿæˆ -> åˆç¨¿ä¼˜åŒ– -> é£æ§æ ¸æŸ¥ -> æ¶¦è‰²å®¡æŸ¥
    """
    session_store.update(session_id, status="generating")
    
    max_iterations = 2
    
    while state["iteration_count"] < max_iterations:
        state["iteration_count"] += 1
        current_iter = state["iteration_count"]
        
        logger.info(f"å¼€å§‹ç”Ÿæˆå¾ªç¯: iteration={current_iter}")
        
        # 1. ç”Ÿæˆåˆç¨¿ï¼ˆå«é€‚åº¦åŒ…è£…ï¼‰
        draft_result = await node_generate_draft(state)
        state.update(draft_result)
        
        # 2. åˆç¨¿ä¼˜åŒ–ï¼ˆæ£€æŸ¥é—æ¼ã€å¤šç»´åº¦ä¼˜åŒ–ï¼‰ã€æ–°å¢ã€‘
        optimize_result = await node_optimize_draft(state)
        state.update(optimize_result)
        
        # 3. é£æ§æ ¸æŸ¥ï¼ˆåªæŸ¥ä¸¥é‡é€ å‡ï¼‰
        check_result = await node_fact_check(state)
        state.update(check_result)
        
        # 4. æ¶¦è‰²ä¸ç»ˆå®¡
        finalize_result = await node_finalize_and_review(state)
        state.update(finalize_result)
        
        # æ£€æŸ¥æ˜¯å¦é€šè¿‡
        if state.get("review_result", {}).get("passed", False):
            logger.info("å®¡æŸ¥é€šè¿‡ï¼Œç”Ÿæˆç»“æŸ")
            break
        else:
            logger.info("å®¡æŸ¥æœªå®Œå…¨é€šè¿‡ï¼Œå°è¯•ä¸‹ä¸€è½®ä¼˜åŒ–ï¼ˆå¦‚æœ‰ï¼‰")
    
    if not state.get("final_markdown"):
        logger.warning("è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ä»æœªé€šè¿‡å®¡æŸ¥ï¼Œä½¿ç”¨æœ€åä¸€æ¬¡è‰ç¨¿")
        state["final_markdown"] = state.get("optimized_draft", "") or state.get("draft_content", "") or "# ç”Ÿæˆå¤±è´¥\nè¯·ç¨åé‡è¯•"
        state["title"] = "æ–°ç®€å†"
    
    # ä¿å­˜åˆ°æ•°æ®åº“
    service = get_generation_service()
    session = session_store.get(session_id)
    
    resume_id = await service.save_generated_resume(
        user_id=session.user_id if session else state["user_id"],
        title=state["title"],
        content=state["final_markdown"],
        job_description=state.get("job_description")
    )
    
    # æ›´æ–°ä¼šè¯çŠ¶æ€
    session_store.update(
        session_id,
        status="completed",
        final_markdown=state["final_markdown"]
    )
    
    logger.info(f"ç”Ÿæˆæµç¨‹å…¨éƒ¨å®Œæˆ: resume_id={resume_id}, title={state['title']}")
    
    return {
        "resume_id": resume_id,
        "title": state["title"],
        "content": state["final_markdown"],
        "review_result": state.get("review_result"),
        "optimization_notes": state.get("optimization_notes")  # è¿”å›ä¼˜åŒ–ä¿¡æ¯
    }


async def get_session_status(session_id: str) -> Optional[Dict[str, Any]]:
    """
    è·å–ä¼šè¯çŠ¶æ€
    """
    session = session_store.get(session_id)
    if not session:
        return None
    
    return {
        "session_id": session_id,
        "status": session.status,
        "questions": session.questions if session.status == "awaiting_input" else [],
        "user_answers": session.user_answers,
        "final_markdown": session.final_markdown if session.status == "completed" else None
    }
